[  
    {
    "name": "TypeScript Array Methods with Promises (Beginner Quiz)",
    "image": "https://images.unsplash.com/photo-1612838320302-4b3b3b3b3b3b",
    "questions": [
        {
            "question": "You have an array of user IDs: `[101, 102, 103]`. You also have an asynchronous function `fetchUserName(id: number): Promise<string>` that returns a Promise resolving to a user's name. How can you create an array where each element is a Promise that will resolve to the username for the corresponding ID?",
            "answers": [
                {"answer": "userIds.forEach(id => fetchUserName(id));"},
                {"answer": "userIds.map(id => fetchUserName(id));"},
                {"answer": "userIds.filter(id => fetchUserName(id));"},
                {"answer": "userIds.find(id => fetchUserName(id));"}
            ],
            "answer": "userIds.map(id => fetchUserName(id));",
            "explanation": "The `map()` method is perfect for this! \n\n* **What `map()` does:** It creates a **new array** by calling a function for each element in the original array. The return value of that function becomes an element in the new array.\n* **In this case:** The function `id => fetchUserName(id)` is called for each `id`. Since `fetchUserName(id)` returns a `Promise<string>`, the `map()` method will collect these Promises into a new array.\n\nSo, `userIds.map(id => fetchUserName(id))` will result in an array like `[Promise<string>, Promise<string>, Promise<string>]`.\n\n**To get the actual user names** (the resolved values of the Promises), you would typically use `Promise.all()` like this:\n```typescript\nasync function getUserNames(userIds: number[]): Promise<string[]> {\n  const userNamePromises = userIds.map(id => fetchUserName(id));\n  // userNamePromises is [Promise for id 101, Promise for id 102, ...]\n\n  const names = await Promise.all(userNamePromises);\n  // names will be [\"Name for 101\", \"Name for 102\", ...]\n  return names;\n}\n```\n* `forEach()` just executes a function for each item but doesn't create a new array of results.\n* `filter()` is used to select items based on a condition, not transform them.\n* `find()` returns the first item that matches a condition."
        },
        {
            "question": "If you use `async/await` inside a `forEach` loop to process items (e.g., `items.forEach(async item => { await asyncOperation(item); })`), what is important to remember about how `forEach` handles these asynchronous operations?",
            "answers": [
                {"answer": "`forEach` will pause and wait for each `asyncOperation` to complete before starting the next one."},
                {"answer": "`forEach` will execute all `asyncOperation` calls concurrently and wait for all of them to finish before the `forEach` loop itself completes."},
                {"answer": "`forEach` will start all `asyncOperation` calls, but it will NOT wait for them to complete. The `forEach` loop will finish before the async operations inside it are necessarily done."},
                {"answer": "Using `async/await` inside `forEach` is not allowed in TypeScript and will cause a compile error."}
            ],
            "answer": "`forEach` will start all `asyncOperation` calls, but it will NOT wait for them to complete. The `forEach` loop will finish before the async operations inside it are necessarily done.",
            "explanation": "This is a common point of confusion for beginners! 🤔\n\n* The `forEach` method itself is **synchronous**. It iterates through the array and calls the provided callback function for each item.\n* If your callback function is `async` (e.g., `async item => { await asyncOperation(item); }`), `forEach` will *call* this async function for each item, but it **does not wait** for the `Promise` returned by the `async` function to resolve.\n* This means `forEach` will typically finish executing very quickly, having launched all the asynchronous operations, but those operations will continue running in the background.\n\n**In simpler terms:** `forEach` says \"Okay, start this task!\" for each item and immediately moves to the next, without waiting for the current task to finish.\n\n**If you need to wait for each async operation to complete in sequence, you should use a standard `for...of` loop:**\n```typescript\nasync function processAllItemsSequentially<T>(items: T[], asyncOperation: (item: T) => Promise<void>) {\n  console.log(\"Starting sequential processing...\");\n  for (const item of items) {\n    console.log(`Processing item: ${item}`);\n    await asyncOperation(item); // The loop PAUSES here until this operation completes\n    console.log(`Finished processing item: ${item}`);\n  }\n  console.log(\"All items processed sequentially.\");\n}\n```\n\n**If you want to run them concurrently and wait for all to finish, use `map` with `Promise.all()` (as shown in the previous question's explanation).**"
        },
        {
            "question": "You have an array of product IDs: `[1, 2, 3, 4]`. You want to filter this array to get only the IDs of products that are currently in stock. You have an async function `isProductInStock(id: number): Promise<boolean>`. Why can't you directly use `productIds.filter(async id => await isProductInStock(id))` to get the correct result?",
            "answers": [
                {"answer": "Because `filter` cannot be used with `async/await` syntax at all."},
                {"answer": "Because `filter` expects its callback function to return a direct `boolean` value, but an `async` function returns a `Promise<boolean>`."},
                {"answer": "Because `isProductInStock` might throw an error, and `filter` doesn't handle Promise rejections."},
                {"answer": "Because `filter` modifies the original array, which is not safe with asynchronous operations."}
            ],
            "answer": "Because `filter` expects its callback function to return a direct `boolean` value, but an `async` function returns a `Promise<boolean>`.",
            "explanation": "The `filter()` method works by calling a callback function (often called a 'predicate') for each element in the array. \n* If the callback returns `true` (synchronously), the element is included in the new filtered array.\n* If the callback returns `false` (synchronously), the element is excluded.\n\nCrucially, this callback function **must return a synchronous boolean value** (`true` or `false`).\n\nWhen you write `async id => await isProductInStock(id)`, this `async` function *always* returns a `Promise`. Even if `isProductInStock(id)` resolves to `true` or `false`, the `async` function itself wraps that in a `Promise<boolean>`.\n\nIn JavaScript (and TypeScript), a `Promise` object, when evaluated in a boolean context (like what `filter` expects), is considered **'truthy'**. So, `productIds.filter(async id => await isProductInStock(id))` would likely include *all* product IDs in the result, because every call returns a Promise, and every Promise is truthy.\n\n**How to correctly filter with an async predicate:**\nYou need a multi-step process:\n1.  **Map to Promises of checks:** Use `map` to call your async predicate for each item. It's often useful to map to an object containing the original item and the boolean result of the check.\n    ```typescript\n    const stockCheckPromises = productIds.map(async (id) => {\n      const isInStock = await isProductInStock(id);\n      return { id: id, inStock: isInStock };\n    });\n    ```\n2.  **Wait for all Promises:** Use `Promise.all()` to wait for all these Promises to resolve.\n    ```typescript\n    const stockStatusesWithIds = await Promise.all(stockCheckPromises);\n    // Example: [{id: 1, inStock: true}, {id: 2, inStock: false}, ...]\n    ```\n3.  **Filter based on resolved booleans:** Now you can filter these results and then extract the original items.\n    ```typescript\n    const inStockProductsInfo = stockStatusesWithIds.filter(itemStatus => itemStatus.inStock);\n    const inStockProductIds = inStockProductsInfo.map(info => info.id);\n    // Example: [1, 3, 4]\n    ```\nThis is a common pattern when dealing with asynchronous filtering conditions."
        },
        {
            "question": "You have an array of tasks, where each task is a function that returns a Promise: `type Task = () => Promise<void>; const tasks: Task[] = [asyncTask1, asyncTask2, asyncTask3];`. How can you execute these tasks one after another (sequentially), waiting for each task to complete before starting the next, using an array method?",
            "answers": [
                {"answer": "tasks.forEach(async task => await task());"},
                {"answer": "Promise.all(tasks.map(task => task()));"},
                {"answer": "tasks.reduce(async (promiseChain, currentTask) => { await promiseChain; return currentTask(); }, Promise.resolve());"},
                {"answer": "for (const task of tasks) { task(); } // This doesn't wait"}
            ],
            "answer": "tasks.reduce(async (promiseChain, currentTask) => { await promiseChain; return currentTask(); }, Promise.resolve());",
            "explanation": "To execute asynchronous tasks sequentially from an array, the `reduce()` method is a powerful tool. ⚙️\n\n* **What `reduce()` does:** It iterates over an array and 'reduces' it to a single accumulated value. In this case, our accumulated value is a chain of Promises, ensuring one finishes before the next begins.\n* **How it works for sequential Promises:**\n    * The `reduce` method takes two main arguments: \n        1. A callback function: `async (accumulator, currentTask) => { /* ... */ }`\n        2. An initial value for the accumulator: `Promise.resolve()` (an already resolved Promise to start the chain smoothly).\n    * In each step of the `reduce` callback:\n        * `accumulator` (which we called `promiseChain` for clarity): This is the Promise from the *previous* step (or the initial `Promise.resolve()`).\n        * `currentTask`: This is the current task function from the `tasks` array.\n        * `await promiseChain;`: We first **wait** for the previous task in the chain to complete.\n        * `return currentTask();`: Then, we execute the `currentTask()` and return the Promise it generates. This new Promise becomes the `promiseChain` (accumulator) for the next iteration.\n\n**The callback function passed to `reduce` must be `async` to allow the use of `await` inside it.**\n\n**Full Example:**\n```typescript\nasync function runTasksSequentially(tasks: Array<() => Promise<any>>) {\n  console.log(\"Starting tasks sequentially...\");\n  await tasks.reduce(async (previousPromise, nextTask) => {\n    await previousPromise; // Wait for the previous task to complete\n    console.log(\"Executing next task...\");\n    return nextTask();    // Execute current task and return its promise\n  }, Promise.resolve()); // Start with an empty, resolved promise\n  console.log(\"All tasks completed.\");\n}\n\n// Example usage:\nconst delay = (ms: number, id: string) => new Promise(resolve => setTimeout(() => {\n  console.log(`Task ${id} finished after ${ms}ms`);\n  resolve(undefined);\n}, ms));\n\nconst myTasks: Array<() => Promise<any>> = [\n  () => delay(1000, \"A\"),\n  () => delay(500, \"B\"),\n  () => delay(800, \"C\"),\n];\n\n// runTasksSequentially(myTasks);\n// Output would show A finishing, then B, then C.\n```\nThis ensures that Task A finishes before Task B starts, and Task B finishes before Task C starts.\n\n**Why other options are not ideal for this specific *sequential* requirement:**\n* `tasks.forEach(async task => await task());`: As explained before, `forEach` doesn't wait for the `await` inside its callback. It would start all tasks nearly at the same time (concurrently).\n* `Promise.all(tasks.map(task => task()));`: This executes all tasks concurrently (in parallel) and waits for all of them to finish. It does not run them one after another.\n* `for (const task of tasks) { task(); }`: This also starts all tasks but doesn't use `await`, so they run concurrently without waiting for completion."
        },
        {
            "question": "You have an array of items and an async function `checkCondition(item): Promise<boolean>`. You want to find the **first item** in the array that satisfies the asynchronous condition. Which approach is most suitable for this, ensuring you stop processing unnecessary items once a match is found?",
            "answers": [
                {"answer": "Use `items.map(async item => ({ item, matches: await checkCondition(item) }))`, then `Promise.all()`, then `find()` on the results. This is efficient."},
                {"answer": "Use a `for...of` loop and `await checkCondition(item)` inside. If the condition is met, return the item immediately. This stops processing unnecessary items."},
                {"answer": "Use `items.find(async item => await checkCondition(item))`. This works directly and is efficient."},
                {"answer": "Use `Promise.race(items.map(async item => { if (await checkCondition(item)) return item; else throw new Error('No match'); }))`."}
            ],
            "answer": "Use a `for...of` loop and `await checkCondition(item)` inside. If the condition is met, return the item immediately. This stops processing unnecessary items.",
            "explanation": "When you want to find the *first* item satisfying an async condition, efficiency is key – you want to stop checking as soon as you find a match. 🕵️‍♀️\n\n**The `for...of` loop with `await` is the most suitable and straightforward approach here:**\n```typescript\nasync function findFirstMatchingItem<T>(\n  items: T[], \n  asyncPredicate: (item: T) => Promise<boolean>\n): Promise<T | undefined> {\n  for (const item of items) {\n    // Wait for the current item's condition to be checked\n    if (await asyncPredicate(item)) {\n      return item; // Found it! Return immediately and stop the loop.\n    }\n  }\n  return undefined; // No item matched after checking all items\n}\n\n// Example usage:\n// async function isLargeFile(filePath: string): Promise<boolean> { /* ... */ }\n// const files = [\"file1.txt\", \"file2.txt\", \"largeFile.dat\", \"another.txt\"];\n// const firstLargeFile = await findFirstMatchingItem(files, isLargeFile);\n// If 'largeFile.dat' is the first large file, 'another.txt' won't be checked.\n```\n* **Why it's good:** The loop `await`s each `asyncPredicate` call *sequentially*. As soon as one `asyncPredicate(item)` resolves to `true`, the function immediately returns that `item` and stops iterating through the rest of the array. This is efficient because it avoids unnecessary asynchronous operations on the remaining items.\n\n**Why other options are less ideal for this specific \"find first and stop\" scenario:**\n* **Option A (map, Promise.all, then find):** This approach will run `checkCondition` for *all* items in the array (likely concurrently via `Promise.all(map(...))`). Only after all checks are done would you `find()` the first match. If the first item in the array matches, you still waited for all other asynchronous checks to complete. This is not efficient if you only need the first match quickly.\n* **Option C (`items.find(async item => await checkCondition(item))`):** Similar to `filter`, the `find` method's predicate expects a synchronous `boolean`. An `async` function (like `async item => await checkCondition(item)`) always returns a `Promise<boolean>`. In a boolean context, any `Promise` object is 'truthy'. So, `items.find(async ...)` would likely just return the very first item of the array, regardless of whether `checkCondition(item)` resolved to `true` or `false`.\n* **Option D (`Promise.race`):** `Promise.race` settles as soon as *any* promise in the iterable settles (either resolves or rejects). While you could theoretically construct a set of promises where the first one to match a condition resolves with the item and others are made to pend or reject, this is significantly more complex to set up correctly and less readable for a beginner than a simple `for...of` loop for this use case. Handling rejections and ensuring only the *correct* item resolves first would be tricky."
        },
        {
            "question": "In concurrent programming, what is a 'lock convoy' and what are its primary implications?",
            "answers": [
                {"answer": "A pattern where threads efficiently pass a lock among themselves, minimizing contention."},
                {"answer": "A performance degradation issue where multiple threads queue up for a frequently contended lock, leading to excessive context switching and underutilization of the CPU."},
                {"answer": "A security mechanism that ensures locks are acquired in a predefined, authorized sequence."},
                {"answer": "A debugging technique to trace the history of lock acquisitions and releases within a system."}
            ],
            "answer": "A performance degradation issue where multiple threads queue up for a frequently contended lock, leading to excessive context switching and underutilization of the CPU.",
            "explanation": "A **lock convoy** occurs when a lock is heavily contended, and the scheduling policy for acquiring the lock (often FIFO) causes threads to queue up. When a thread releases the lock, it might be immediately reacquired by the next thread in the queue, which might then execute for a very short time before releasing it. This can lead to a situation where the CPU spends a significant amount of time on context switching threads in and out, rather than performing useful work. The system becomes less responsive because threads that hold the lock often do so for short critical sections, and the overhead of managing the convoy (waking threads, context switches) dominates. This is a known performance problem, especially in older operating systems or synchronization primitives that strictly enforce fairness in lock acquisition without considering the broader system throughput."
        },
        {
            "question": "Which of the following statements best describes the primary advantage of using a Bloom filter?",
            "answers": [
                {"answer": "Guarantees no false negatives and provides exact set membership testing with optimal space complexity."},
                {"answer": "Allows for highly space-efficient probabilistic set membership testing, tolerating false positives but guaranteeing no false negatives."},
                {"answer": "Enables efficient retrieval of elements in a sorted order from a large dataset."},
                {"answer": "Provides strong cryptographic hashing for secure data storage and verification."}
            ],
            "answer": "Allows for highly space-efficient probabilistic set membership testing, tolerating false positives but guaranteeing no false negatives.",
            "explanation": "A **Bloom filter** is a probabilistic data structure that is highly space-efficient for testing whether an element is a member of a set. \n\nKey characteristics:\n1.  **False Positives Possible**: It can tell you that an element *might* be in the set (a positive result), but this could be a false positive. The probability of false positives can be tuned by adjusting the size of the filter and the number of hash functions.\n2.  **No False Negatives**: If the Bloom filter says an element is *not* in the set (a negative result), it is definitively not in the set. There are no false negatives.\n3.  **Space Efficiency**: They use significantly less memory than other data structures like hash tables or balanced trees for storing large sets, especially when only membership testing is required and the actual elements don't need to be stored.\n4.  **No Element Deletion (Standard Bloom Filter)**: Standard Bloom filters do not support element deletion, as removing bits could lead to false negatives for other elements.\n\nIt's ideal for scenarios like checking if a username is already taken (where a false positive means an extra database check, which is acceptable) or if a URL has been visited by a web crawler to avoid reprocessing (again, a rare false positive might mean missing a re-crawl, but no false negatives means you won't mistakenly think you haven't visited a URL you have)."
        },
        {
            "question": "According to the CAP theorem, a distributed data store can simultaneously provide at most two out of which three guarantees in the presence of a network partition?",
            "answers": [
                {"answer": "Atomicity, Consistency, Isolation"},
                {"answer": "Consistency, Availability, Partition Tolerance"},
                {"answer": "Durability, Scalability, Performance"},
                {"answer": "Confidentiality, Integrity, Availability"}
            ],
            "answer": "Consistency, Availability, Partition Tolerance",
            "explanation": "The **CAP theorem**, also known as Brewer's theorem, states that it is impossible for a distributed data store to simultaneously provide more than two out of the following three guarantees:\n\n1.  **Consistency (C)**: Every read receives the most recent write or an error. In a consistent system, all nodes see the same data at the same time. If data is written to one node, a subsequent read from any other node should reflect that write.\n2.  **Availability (A)**: Every request receives a (non-error) response, without the guarantee that it contains the most recent write. The system remains operational and responsive even if some nodes are down or unreachable.\n3.  **Partition Tolerance (P)**: The system continues to operate despite an arbitrary number of messages being dropped (or delayed) by the network between nodes (i.e., a network partition). In a distributed system, network partitions are a fact of life, so partition tolerance is usually a must-have.\n\nGiven that network partitions (P) are generally unavoidable in distributed systems, the theorem implies that designers must often choose between strong consistency (CP systems like traditional RDBMS) and high availability (AP systems like some NoSQL databases). For example, during a partition, a CP system might return an error or timeout for some requests to ensure consistency, thus sacrificing availability. An AP system might return stale data to ensure availability, thus sacrificing strong consistency."
        },
        {
            "question": "In the context of garbage collection (GC), what is the primary function of a 'write barrier'?",
            "answers": [
                {"answer": "To enforce memory safety by preventing out-of-bounds writes to arrays and buffers."},
                {"answer": "To log all memory write operations for debugging and auditing purposes."},
                {"answer": "To notify the garbage collector about pointer modifications, allowing it to maintain its invariants, especially in incremental, concurrent, or generational GCs."},
                {"answer": "A hardware mechanism that protects read-only memory segments from being overwritten."}
            ],
            "answer": "To notify the garbage collector about pointer modifications, allowing it to maintain its invariants, especially in incremental, concurrent, or generational GCs.",
            "explanation": "A **write barrier** is a small piece of code inserted by the compiler or interpreter just before a pointer (reference) write operation (e.g., `obj.field = some_other_obj`). Its primary purpose is to inform the garbage collector (GC) about this mutation to the object graph. This is crucial for certain types of GCs:\n\n1.  **Generational GCs**: These GCs divide memory into generations (e.g., young and old). Objects are typically allocated in the young generation and promoted to the old generation if they survive long enough. Generational GCs collect the young generation more frequently because most objects die young. A write barrier is needed to track pointers from the old generation to the young generation. Without it, a young generation collection might mistakenly reclaim young objects that are still referenced by old objects, as scanning the entire old generation for such pointers on every young collection would be inefficient.\n2.  **Incremental/Concurrent GCs**: These GCs perform collection work in small increments or concurrently with the application threads to reduce pause times. They need write barriers to keep track of changes the application makes to the object graph while the GC is running. For example, if the GC has already scanned an object and the application then modifies it to point to an unscanned object, the write barrier ensures the GC becomes aware of this new reference so the pointed-to object isn't prematurely reclaimed.\n\nEssentially, write barriers help the GC maintain its internal data structures (like 'remembered sets' which store inter-region or inter-generational pointers) correctly, ensuring the liveness of objects without needing to stop the world for extended periods or re-scan everything constantly."
        },
        {
            "question": "What is the primary difference in how `select()`, `poll()`, and `epoll()` (or `kqueue()`) handle I/O multiplexing, particularly concerning performance with a large number of file descriptors?",
            "answers": [
                {"answer": "`select()` and `poll()` scale linearly with the number of file descriptors, while `epoll()` offers O(1) performance for checking readiness regardless of the number of monitored descriptors."},
                {"answer": "`epoll()` uses a callback mechanism, whereas `select()` and `poll()` require active polling of each file descriptor."},
                {"answer": "`select()` is limited by `FD_SETSIZE`, `poll()` has no hard limit but performance degrades, and `epoll()` involves copying the entire set of descriptors to kernel space on each call, similar to `select()`."},
                {"answer": "`select()` and `poll()` require the kernel to iterate through all monitored file descriptors to find ready ones, while `epoll()` maintains a list of ready descriptors in the kernel, allowing user space to retrieve only the active ones."}
            ],
            "answer": "`select()` and `poll()` require the kernel to iterate through all monitored file descriptors to find ready ones, while `epoll()` maintains a list of ready descriptors in the kernel, allowing user space to retrieve only the active ones.",
            "explanation": "The core difference lies in how they identify ready file descriptors (FDs) and how this scales:\n\n1.  **`select()`**: \n    * It uses fixed-size bitmasks (`fd_set`) to represent the set of FDs to monitor. This has a hard limit, `FD_SETSIZE` (often 1024 or 2048).\n    * On each call, these bitmasks are passed from user space to kernel space. The kernel modifies them to indicate readiness.\n    * The kernel must iterate through all FDs in the set (up to the highest numbered FD) to check their status. User space then also typically iterates through the masks to find the ready FDs.\n    * Performance degrades linearly (O(N)) with the highest FD number, not just the count of FDs being monitored.\n\n2.  **`poll()`**: \n    * It improves upon `select()` by not having a fixed limit like `FD_SETSIZE`. It takes an array of `struct pollfd`, where each structure specifies an FD and the events to monitor for it.\n    * Like `select()`, the entire array of `struct pollfd` is passed to the kernel, and the kernel iterates through this array to check the status of each FD.\n    * Performance degrades linearly (O(N)) with the number of FDs being monitored.\n\n3.  **`epoll()` (Linux specific; `kqueue()` is its BSD/macOS equivalent)**:\n    * It uses a more advanced mechanism. First, an `epoll` instance is created in the kernel (`epoll_create`).\n    * FDs are added (`epoll_ctl` with `EPOLL_CTL_ADD`), modified (`EPOLL_CTL_MOD`), or removed (`EPOLL_CTL_DEL`) from this instance. This interest list is maintained within the kernel.\n    * When `epoll_wait()` is called, the kernel only needs to check the FDs that have actually become ready (often using an internal ready list or callback-like mechanisms triggered by device drivers when I/O completes).\n    * `epoll_wait()` returns only the FDs that are ready.\n    * The key performance benefit is that the cost of `epoll_wait()` is typically proportional to the number of *ready* FDs, not the total number of FDs being monitored. This provides much better scalability (often referred to as O(1) for checking readiness or O(M) where M is the number of ready FDs) when dealing with thousands or tens of thousands of connections, where only a small fraction are active at any given time.\n\nTherefore, `epoll()` (and `kqueue()`) are significantly more efficient for applications handling a very large number of concurrent connections, such as high-performance network servers."
        }
    ]
},
     {
    "name": "Advanced TypeScript Features Quiz - Set 2",
    "image": "https://images.unsplash.com/photo-1612838320302-4b3b3b3b3b3b",
    "questions": [
        {
            "question": "How can you define a TypeScript utility type `OmitStrict<T, K extends keyof T>` that behaves like `Omit<T, K>` but ensures that `K` must actually be a key of `T`, failing at compile time if a non-key is provided?",
            "answers": [
                {"answer": "type OmitStrict<T, K extends keyof T> = Pick<T, Exclude<keyof T, K>>;" },
                {"answer": "type OmitStrict<T, K> = K extends keyof T ? Omit<T, K> : never;"},
                {"answer": "type OmitStrict<T, K extends string> = { [P in Exclude<keyof T, K>]: T[P] };"},
                {"answer": "type OmitStrict<T, K extends keyof T> = Omit<T, K>;"}
            ],
            "answer": "type OmitStrict<T, K extends keyof T> = Pick<T, Exclude<keyof T, K>>;",
            "explanation": "The standard `Omit<T, K>` utility type is defined as `type Omit<T, K extends keyof any> = Pick<T, Exclude<keyof T, K>>;`. Notice `K extends keyof any` (which is `string | number | symbol`). This means if you pass a key `K` to `Omit` that is not actually a key of `T`, it doesn't error out for `K` itself, but `Exclude<keyof T, K>` will simply not exclude anything if `K` isn't in `keyof T`.\n\nThe request is to make `K` strictly a key of `T`. The constraint `K extends keyof T` already does this at the type parameter level.\n\nLet's analyze the proposed correct answer: `type OmitStrict<T, K extends keyof T> = Pick<T, Exclude<keyof T, K>>;`\n\n1.  **`K extends keyof T`**: This generic constraint already ensures that `K` must be a union of keys present in `T`. If you try to call `OmitStrict<MyType, 'nonExistentKey'>`, TypeScript will give an error because `'nonExistentKey'` does not extend `keyof MyType`.\n2.  **`Exclude<keyof T, K>`**: This utility type correctly computes the set of keys from `T` that are *not* in `K`.\n3.  **`Pick<T, Exclude<keyof T, K>>`**: This then picks only those remaining keys from `T`.\n\nThis definition itself is identical to the standard `Omit` but the constraint on `K` is what makes the usage site 'strict'. The question is about defining `OmitStrict` such that providing a non-key to `K` is an error. The constraint `K extends keyof T` on the type parameter itself achieves this strictness when `OmitStrict` is *used*.\n\n**Example Usage:**\n```typescript\ninterface User {\n  id: number;\n  name: string;\n  email: string;\n}\n\n// Correct usage of Omit (or our OmitStrict definition)\ntype UserWithoutEmail = Pick<User, Exclude<keyof User, 'email'>>;\n// type UserWithoutEmail = OmitStrict<User, 'email'>;\n\nconst user1: UserWithoutEmail = { id: 1, name: \"Alice\" }; // OK\n\n// If we try to use OmitStrict with a non-key:\n// type InvalidOmit = OmitStrict<User, 'nonExistentKey'>;\n// This would cause a TypeScript error: \n// Type '\"nonExistentKey\"' does not satisfy the constraint 'keyof User'.\n```\n\nThe key is that `K extends keyof T` in the generic parameters of `OmitStrict` provides the desired compile-time check. The implementation can then be the same as the standard `Omit`.\n\n**Why other options are less direct or don't add the strictness correctly:**\n* `type OmitStrict<T, K> = K extends keyof T ? Omit<T, K> : never;`: This would make the *result* `never` if `K` isn't a key, but it doesn't error on `K` itself at the usage site in the same way a generic constraint does. The user would get `never` and might be confused. The goal is for `K` to be constrained.\n* `type OmitStrict<T, K extends string> = { [P in Exclude<keyof T, K>]: T[P] };`: This constrains `K` to be any `string`, not necessarily keys of `T`. `Exclude<keyof T, K>` would still work, but the constraint on `K` is too loose.\n* `type OmitStrict<T, K extends keyof T> = Omit<T, K>;`: This is essentially an alias, but the definition of `OmitStrict` *itself* is what needs to enforce the strictness on `K`. The question is how to *define* `OmitStrict`. The implementation using `Pick` and `Exclude` is the core, and the `K extends keyof T` constraint is what enforces strictness on the provided `K`."
        },
        {
            "question": "How can you define a TypeScript type `PathValue<T, P extends string>` that retrieves the type of a deeply nested property in `T` specified by a dot-separated path string `P` (e.g., `PathValue<User, 'address.city'>`)?",
            "answers": [
                {"answer": "type PathValue<T, P extends string> = P extends `${infer K}.${infer R}` ? (K extends keyof T ? PathValue<T[K], R> : never) : (P extends keyof T ? T[P] : never);"},
                {"answer": "type PathValue<T, P extends string> = T[P]; // Only works for shallow paths"},
                {"answer": "type PathValue<T, P extends string> = P.split('.').reduce((obj, key) => obj[key], T);"},
                {"answer": "type PathValue<T, P extends string> = P extends keyof T ? T[P] : (P extends `${string}.${string}` ? unknown : never);"}
            ],
            "answer": "type PathValue<T, P extends string> = P extends `${infer K}.${infer R}` ? (K extends keyof T ? PathValue<T[K], R> : never) : (P extends keyof T ? T[P] : never);",
            "explanation": "This is a complex type that requires recursive conditional types and template literal type inference."
        },
        {
            "question": "What is an accessor decorator in TypeScript, and what arguments does it receive?",
            "answers": [
                {"answer": "A decorator applied to an accessor's `get` or `set` method individually, receiving the target, property key, and property descriptor."},
                {"answer": "A decorator applied to an accessor (a property with `get` and/or `set`), receiving the class constructor, property key, and an index if it's a static accessor."},
                {"answer": "A decorator applied once to an accessor (property with `get` and/or `set`), receiving three arguments: the target (class prototype or constructor), the property key (name of the accessor), and the property descriptor for the accessor."},
                {"answer": "A decorator factory that generates `get` and `set` methods for a property."}
            ],
            "answer": "A decorator applied once to an accessor (property with `get` and/or `set`), receiving three arguments: the target (class prototype or constructor), the property key (name of the accessor), and the property descriptor for the accessor.",
            "explanation": "An **accessor decorator** is declared just before an accessor declaration (a property defined with `get` and/or `set` methods).\n\n**Key Points:**\n* It's applied to the accessor as a whole, not to the `get` or `set` part individually.\n* It receives **three arguments**:\n    1.  **`target`**: Either the constructor function of the class for a static member, or the prototype of the class for an instance member.\n    2.  **`propertyKey`**: The name of the member (the accessor's name), as a string or symbol.\n    3.  **`descriptor`**: A `PropertyDescriptor` for the member. This descriptor will have `get` and/or `set` properties for the accessor.\n\n* **Return Value**: An accessor decorator can optionally return a `PropertyDescriptor`. If it does, this new descriptor will be used to configure the accessor. If it returns `undefined` (or nothing), the original descriptor is used (possibly modified by the decorator).\n\n**Example:**\n```typescript\nfunction EnumerableAccessor(value: boolean) {\n  return function (target: any, propertyKey: string, descriptor: PropertyDescriptor) {\n    console.log(`Accessor Decorator for: ${propertyKey}`);\n    descriptor.enumerable = value;\n    // Optionally, return descriptor if you want to replace it entirely\n    // return newDescriptor;\n  };\n}\n\nclass Point {\n  private _x: number = 0;\n  private _y: number = 0;\n\n  @EnumerableAccessor(true)\n  get x() {\n    return this._x;\n  }\n  set x(newX: number) {\n    this._x = newX;\n  }\n\n  @EnumerableAccessor(false) // y will not be enumerable\n  get y() {\n    return this._y;\n  }\n  set y(newY: number) {\n    this._y = newY;\n  }\n}\n\nconst p = new Point();\np.x = 10;\np.y = 20;\n\nconsole.log('Iterating over Point properties:');\nfor (const key in p) {\n  // Depending on other factors, 'x' might show up if enumerable is true\n  // 'y' should not if enumerable is false\n  console.log(key); \n}\n\n// Check descriptor directly\nconst xDescriptor = Object.getOwnPropertyDescriptor(Point.prototype, 'x');\nconsole.log('x enumerable:', xDescriptor?.enumerable); // Expected: true\n\nconst yDescriptor = Object.getOwnPropertyDescriptor(Point.prototype, 'y');\nconsole.log('y enumerable:', yDescriptor?.enumerable); // Expected: false\n```\n\n**Incorrect Answers:**\n* It's applied to the accessor as a whole, not `get`/`set` individually.\n* The arguments are target, property key, and descriptor, not class constructor and index for static accessors in that specific way.\n* It modifies an existing accessor; it doesn't typically generate `get` and `set` methods from scratch (that would be more like a property decorator transforming a simple property)."
        },
        {
            "question": "What is the purpose of `export = ` and `import = require()` syntax in TypeScript, and when might it be used?",
            "answers": [
                {"answer": "It's the modern ECMAScript standard for exporting and importing modules, replacing `export default`."},
                {"answer": "It's used for compatibility with traditional CommonJS/AMD modules that export a single entity (e.g., an object, function, or class), especially when `esModuleInterop` is false."},
                {"answer": "It allows renaming imports and exports at the module boundary for better organization."},
                {"answer": "It's a syntax for creating re-exports, similar to `export * from './module';`."}
            ],
            "answer": "It's used for compatibility with traditional CommonJS/AMD modules that export a single entity (e.g., an object, function, or class), especially when `esModuleInterop` is false.",
            "explanation": "The `export = ` and `import moduleName = require('module-path');` syntax in TypeScript is primarily for interoperability with older module systems, particularly **CommonJS** (like Node.js `module.exports = ...`) and **AMD** modules, which often export a single, primary object or function.\n\n**`export = ` (Export Assignment):**\n* A module can use `export = ` to specify a single object that will be the value of the module when imported by other modules using a compatible syntax.\n* A module can have at most one `export = ` statement.\n* It cannot be used alongside other top-level `export` declarations (like `export class ...` or `export const ...`) in the same module if you are targeting CommonJS/AMD (though some bundlers might handle this differently).\n\n```typescript\n// my-module.ts\nclass MyClass {\n  greet() { return \"Hello!\"; }\n}\nexport = MyClass; // MyClass is the single export of this module\n```\n\n**`import moduleName = require('module-path');` (Import Assignment):**\n* This syntax is used to import a module that was exported using `export = ` or a CommonJS/AMD module that sets `module.exports`.\n* `moduleName` will hold the single exported entity from `'module-path'`.\n\n```typescript\n// consumer.ts\nimport MyExportedClass = require('./my-module');\n\nconst instance = new MyExportedClass();\nconsole.log(instance.greet()); // Output: Hello!\n```\n\n**When to Use:**\n1.  **Consuming Old CommonJS/AMD Modules:** When you're working in a TypeScript project and need to consume a JavaScript library that uses `module.exports = ...` and you have `esModuleInterop` set to `false` (or you want to be explicit).\n2.  **Authoring Modules for CommonJS/AMD Compatibility:** If you are writing a TypeScript library that needs to be easily consumable by older CommonJS/AMD projects, you might use `export = ` for your main export.\n3.  **Compiler Target `commonjs` or `amd`:** This syntax is most relevant when your TypeScript compiler `target` or `module` option is set to something like `commonjs` or `amd`.\n\n**With `esModuleInterop: true` (default in many modern setups):**\nIf `esModuleInterop` is enabled in `tsconfig.json`, TypeScript provides better interoperability with CommonJS modules using standard ES module syntax (`import MyDefaultExport from 'commonjs-module'`). In such cases, direct use of `import = require()` becomes less common for consuming CommonJS modules, though `export =` might still be used by some older TypeScript-authored libraries for their primary export.\n\n**Incorrect Answers:**\n* It's not the modern ECMAScript standard; ES modules use `export default`, named exports (`export const ...`), and `import ... from ...`.\n* While it involves module boundaries, its primary purpose isn't just renaming; it's about a specific export/import mechanism for single-entity module exports.\n* It's different from `export * from './module';`, which re-exports all named exports or the default export of another ES module."
        },
        {
            "question": "What is a heterogeneous enum in TypeScript, and what is a potential downside of using them?",
            "answers": [
                {"answer": "An enum where members have different underlying numeric values, which is standard for all numeric enums."},
                {"answer": "An enum that mixes string literal members and numeric members. A downside is that they can be less predictable and harder to reason about due to the mixed types."},
                {"answer": "An enum that can only be accessed using string keys, not numeric indices. A downside is the lack of reverse mapping."},
                {"answer": "An enum declared with the `const` keyword, making its members behave differently at runtime."}
            ],
            "answer": "An enum that mixes string literal members and numeric members. A downside is that they can be less predictable and harder to reason about due to the mixed types.",
            "explanation": "A **heterogeneous enum** in TypeScript is an enum that contains members of different underlying types, specifically mixing **string literal values** and **numeric values**.\n\n**Example:**\n```typescript\n_enum Status {\n  Pending, // Numeric, defaults to 0\n  Success = \"SUCCESS\", // String literal\n  Failed = 1, // Numeric\n  Retry = \"RETRY_LATER\" // String literal\n}\n\nlet currentStatus: Status = Status.Pending; // currentStatus is 0 (number)\ncurrentStatus = Status.Success; // currentStatus is \"SUCCESS\" (string)\n```\n\nWhile TypeScript allows heterogeneous enums, they are generally **not recommended** for several reasons:\n\n**Potential Downsides:**\n1.  **Type Confusion and Unpredictability:** Working with an enum where members can be either numbers or strings can make the code harder to understand and reason about. Functions consuming these enum values need to be prepared to handle both types, potentially leading to more complex logic or type guards.\n    ```typescript\n    function handleStatus(s: Status) {\n      if (typeof s === 'number') {\n        // Handle numeric status (Pending, Failed)\n        console.log(`Numeric status: ${s}`);\n      } else {\n        // Handle string status (Success, Retry)\n        console.log(`String status: ${s.toUpperCase()}`);\n      }\n    }\n    ```\n2.  **Reduced Type Safety:** The primary benefit of enums is to create a set of distinct, named constants. Mixing underlying types can dilute this benefit if not handled carefully.\n3.  **Maintenance Challenges:** If the underlying types of enum members change, it can have a wider impact on the codebase that consumes them.\n4.  **JavaScript Output:** The JavaScript object generated for heterogeneous enums can also be a bit more complex to inspect if you're relying on its runtime structure, although TypeScript generally handles the typing correctly.\n\n**Best Practice:**\nIt's usually better to stick to enums that are entirely numeric or entirely string-based. If you have conceptually different types of states, consider using separate enums or union types of string literals.\n\n```typescript\n// Preferable: All numeric or all string\nenum NumericStatus { Pending, Failed }\nenum StringStatus { Success = \"SUCCESS\", Retry = \"RETRY\" }\n\n// Or using string literal unions (often preferred over string enums now)\ntype RequestState = \"pending\" | \"success\" | \"failed\" | \"retry\";\n```\n\n**Incorrect Answers:**\n* Standard numeric enums have all numeric values; heterogeneity refers to mixing number and string types.\n* Heterogeneous enums can still have reverse mapping for their numeric members. Lack of reverse mapping is characteristic of string enums (they don't generate number-to-string reverse mappings).\n* `const` enums are about inlining values, not about mixing member types."
        },
        {
            "question": "What is the effect of the `noUncheckedIndexedAccess` compiler option in `tsconfig.json`?",
            "answers": [
                {"answer": "It prevents accessing array elements or object properties using an index signature if the key is not a literal type."},
                {"answer": "It adds `| undefined` to the type of any property accessed via an index signature (e.g., `obj[key]` or `arr[index]`), forcing checks for `undefined` values."},
                {"answer": "It ensures that all array indices are numerically checked at runtime to prevent out-of-bounds errors."},
                {"answer": "It disallows the use of index signatures (`[key: string]: any`) in type definitions."}
            ],
            "answer": "It adds `| undefined` to the type of any property accessed via an index signature (e.g., `obj[key]` or `arr[index]`), forcing checks for `undefined` values.",
            "explanation": "The `noUncheckedIndexedAccess` compiler option in `tsconfig.json` (available since TypeScript 4.1) changes how TypeScript treats access to properties via index signatures (for objects) and element access for arrays.\n\n**Without `noUncheckedIndexedAccess` (or when it's `false`):**\nWhen you access an element of an array or a property of an object with an index signature, TypeScript assumes the access will be successful and return a value of the declared element/property type. It doesn't automatically consider that the key might not exist or the index might be out of bounds, which could lead to `undefined` at runtime.\n\n```typescript\n// tsconfig.json: { \"compilerOptions\": { \"noUncheckedIndexedAccess\": false (or not set) } }\n\nconst arr: number[] = [10, 20];\nconst val1 = arr[0]; // val1 is type number\nconst val2 = arr[2]; // val2 is type number (even though it's undefined at runtime)\n\ninterface StringMap { [key: string]: string; }\nconst map: StringMap = { a: \"Alice\" };\nconst name1 = map.a;   // name1 is type string\nconst name2 = map.b;   // name2 is type string (even though it's undefined at runtime)\n```\n\n**With `noUncheckedIndexedAccess: true`:**\nWhen this option is enabled, any access via an index signature (e.g., `object[stringKey]` or `array[numberIndex]`) will result in a type that includes `| undefined`.\nThis forces you to explicitly check for `undefined` before using the value, making your code safer by reflecting the runtime reality that an index access might not yield a defined value.\n\n```typescript\n// tsconfig.json: { \"compilerOptions\": { \"noUncheckedIndexedAccess\": true, \"strictNullChecks\": true } }\n\nconst arr: number[] = [10, 20];\nconst val1 = arr[0]; // val1 is type number | undefined\nconst val2 = arr[2]; // val2 is type number | undefined\n\nif (val1 !== undefined) {\n  console.log(val1.toFixed(2)); // OK\n}\n\ninterface StringMap { [key: string]: string; }\nconst map: StringMap = { a: \"Alice\" };\nconst name1 = map.a;   // name1 is type string | undefined\nconst name2 = map.b;   // name2 is type string | undefined\n\nif (name2) { // or typeof name2 === 'string'\n  console.log(name2.toUpperCase()); // OK\n}\n```\n\n**Benefits:**\n* **Increased Type Safety:** Catches potential runtime errors where `undefined` is accessed as if it were a defined value.\n* **More Accurate Typing:** Reflects the true nature of indexed access, which can yield `undefined`.\n\nThis option works best when `strictNullChecks` is also enabled.\n\n**Incorrect Answers:**\n* It doesn't prevent access; it modifies the resulting type.\n* It's a compile-time type system feature, not a runtime check for out-of-bounds errors.\n* It doesn't disallow index signatures in definitions; it affects how values accessed through them are typed."
        },
        {
            "question": "How can you write a TypeScript assertion function `assertIsString` that asserts a value is a string, and if not, throws an error, while also narrowing the type of the value in the calling scope?",
            "answers": [
                {"answer": "function assertIsString(value: unknown): asserts value is string {\n  if (typeof value !== 'string') throw new Error('Not a string!');\n}"},
                {"answer": "function assertIsString(value: unknown): boolean {\n  if (typeof value !== 'string') throw new Error('Not a string!');\n  return true;\n}"},
                {"answer": "function assertIsString(value: unknown): string {\n  if (typeof value !== 'string') throw new Error('Not a string!');\n  return value;\n}"},
                {"answer": "function assertIsString(value: unknown): void {\n  if (typeof value !== 'string') throw new Error('Not a string!');\n  // No type narrowing happens\n}"}
            ],
            "answer": "function assertIsString(value: unknown): asserts value is string {\n  if (typeof value !== 'string') throw new Error('Not a string!');\n}",
            "explanation": "**Assertion Functions (`asserts condition`)**\n\nAssertion functions are a feature in TypeScript (since 3.7) that allow you to declare that a function will throw an error if a certain condition is not met. More importantly for type checking, they can also signal to the compiler that if the function returns normally (i.e., doesn't throw), a specific variable or property now has a narrower type in the remaining scope.\n\n**Syntax:**\nThe return type of an assertion function uses the `asserts` keyword followed by a condition (often a type predicate like `value is string` or just a variable name if asserting its truthiness `asserts condition`).\n`function fnName(param: SomeType): asserts param is MoreSpecificType { ... }`\nOr for asserting a general condition:\n`function assert(condition: any, message: string): asserts condition { ... }`\n\n**Correct Implementation `assertIsString`:**\n```typescript\nfunction assertIsString(value: unknown, message: string = \"Value is not a string!\"): asserts value is string {\n  if (typeof value !== \"string\") {\n    throw new Error(message);\n  }\n  // No explicit return value is needed when using 'asserts' for type predicate assertion\n}\n\nfunction processValue(input: unknown) {\n  // console.log(input.toUpperCase()); // Error: Object is of type 'unknown'.\n\n  assertIsString(input);\n\n  // After this point, TypeScript knows 'input' MUST be a string\n  // because assertIsString would have thrown an error otherwise.\n  console.log(input.toUpperCase()); // OK! 'input' is now typed as string.\n}\n\nprocessValue(\"hello\");\n// processValue(123); // This would throw an error inside assertIsString\n```\n\n**How it Works for Type Narrowing:**\nWhen `assertIsString(input)` is called:\n* If `input` is not a string, an error is thrown, and execution of `processValue` stops.\n* If `input` *is* a string, `assertIsString` completes normally.\n* Because `assertIsString` is declared with `asserts value is string`, TypeScript understands that if the function didn't throw, then `value` (which corresponds to `input` in the call) must be a `string` in the code that follows the call to `assertIsString`.\n\n**Incorrect Answers:**\n* Returning `boolean`: This would make it a regular type guard function, used like `if (isString(value)) { ... }`, not an assertion function that throws and narrows on successful return.\n* Returning `string`: This would be a function that validates and returns the string, or throws. While useful, it's not the specific `asserts` syntax for control-flow based narrowing post-call.\n* Returning `void` without `asserts`: This function would throw but TypeScript wouldn't get any information to narrow the type of `value` in the calling scope."
        },
        {
            "question": "How can you type a TypeScript function `processTuple` that accepts a tuple with a specific structure (e.g., a string, then a number, then an optional boolean) using rest parameters and infers the types correctly?",
            "answers": [
                {"answer": "function processTuple(...args: [string, number, boolean?]): void { const [name, age, active] = args; /* ... */ }"},
                {"answer": "function processTuple(...args: (string | number | boolean)[]): void { /* less type safe */ }"},
                {"answer": "function processTuple(args: [name: string, age: number, active?: boolean]): void { /* args is the tuple directly */ }"},
                {"answer": "function processTuple<T extends [string, number, boolean?]>(...args: T): void { const [name, age, active] = args; /* ... */ }"}
            ],
            "answer": "function processTuple(...args: [string, number, boolean?]): void { const [name, age, active] = args; /* ... */ }",
            "explanation": "TypeScript allows you to strongly type rest parameters (`...args`) as tuple types. This is very useful when you want a function to accept a fixed sequence of arguments with specific types, while still using the rest parameter syntax.\n\n**Correct Syntax for Typing Rest Parameters as a Tuple:**\n```typescript\nfunction processTuple(...args: [string, number, boolean?]): void {\n  const [name, age, active] = args; // Destructuring is convenient here\n\n  console.log(`Name: ${name}`);       // name is string\n  console.log(`Age: ${age}`);         // age is number\n  if (active !== undefined) {\n    console.log(`Active: ${active}`); // active is boolean | undefined\n  } else {\n    console.log(\"Active status not provided.\");\n  }\n}\n\n// Valid calls:\nprocessTuple(\"Alice\", 30, true);\nprocessTuple(\"Bob\", 25);\n\n// Invalid calls:\n// processTuple(\"Carol\"); // Error: Expected 2-3 arguments, but got 1.\n// processTuple(\"Dave\", \"forty\"); // Error: Argument of type 'string' is not assignable to parameter of type 'number'.\n```\n\n**Explanation:**\n* `...args: [string, number, boolean?]`: \n    * `...args`: Declares `args` as a rest parameter, meaning it will collect all remaining arguments passed to the function into an array.\n    * `[string, number, boolean?]`: This is a **tuple type**. It specifies that `args` must be an array-like structure where:\n        * The first element (`args[0]`) must be a `string`.\n        * The second element (`args[1]`) must be a `number`.\n        * The third element (`args[2]`) is optional (due to `?`) and must be a `boolean` if provided.\n\n**Why this is powerful:**\n* **Type Safety:** Ensures the correct number and types of arguments are passed.\n* **Readability:** Clearly documents the expected sequence of arguments.\n* **Tooling:** Provides excellent autocompletion and type checking in IDEs.\n\n**Incorrect Answers:**\n* `function processTuple(...args: (string | number | boolean)[]): void { ... }`: This types `args` as an array where *each element* can be a string, number, or boolean, and there's no restriction on the length or order. This is much less type-safe than a tuple.\n* `function processTuple(args: [name: string, age: number, active?: boolean]): void { ... }`: This is how you'd type a *single parameter* that is expected to be a tuple. The question asks for using *rest parameters* (`...args`). If you call this as `processTuple([\"Alice\", 30])`, `args` would be `[\"Alice\", 30]`. If you call it as `processTuple(\"Alice\", 30)`, it would be an error because it expects one argument of tuple type.\n* `function processTuple<T extends [string, number, boolean?]>(...args: T): void { ... }`: While this uses generics and constrains `T` to the tuple type, it's an unnecessary layer of genericity for simply typing the rest parameters directly. The direct tuple type on `...args` is cleaner and more idiomatic for this specific case."
        },
        {
            "question": "What does the TypeScript utility type `Awaited<T>` do, and in what scenario is it most useful?",
            "answers": [
                {"answer": "It extracts the return type of an async function, similar to `ReturnType` but specifically for async functions."},
                {"answer": "It recursively unwraps `Promise` types. For example, `Awaited<Promise<Promise<string>>>` would be `string`. It's useful for modeling the result of `await` on potentially nested promises."},
                {"answer": "It converts a synchronous function type into an asynchronous one by wrapping its return type in a `Promise`."},
                {"answer": "It checks if a type `T` is a `Promise` and returns `true` or `false`."}
            ],
            "answer": "It recursively unwraps `Promise` types. For example, `Awaited<Promise<Promise<string>>>` would be `string`. It's useful for modeling the result of `await` on potentially nested promises.",
            "explanation": "The `Awaited<T>` utility type (introduced in TypeScript 4.5) is designed to model the behavior of the `await` keyword in JavaScript, especially when dealing with Promises or other \"awaitable\" types (types with a `.then(onfulfilled, onrejected)` method).\n\n**Core Functionality:**\n* It recursively unwraps `Promise` types.\n* If `T` is not a Promise-like type, `Awaited<T>` resolves to `T` itself.\n\n**Examples:**\n```typescript\ntype T0 = Awaited<Promise<string>>; // T0 is string\ntype T1 = Awaited<Promise<Promise<number>>>; // T1 is number (recursively unwrapped)\ntype T2 = Awaited<string | Promise<boolean>>; // T2 is string | boolean (distributes over unions)\ntype T3 = Awaited<number>; // T3 is number (not a Promise)\n\ninterface Thenable<T> {\n  then(onfulfilled: (value: T) => any, onrejected?: (reason: any) => any): any;\n}\ntype T4 = Awaited<Thenable<Promise<number>>>; // T4 is number\n```\n\n**Use Scenario:**\nIts primary use case is to accurately model the type you get after using `await` in an `async` function. When you `await` a value:\n* If the value is a Promise, `await` pauses execution until the Promise settles, and then resumes with the resolved value (or throws the rejection reason).\n* If the value is not a Promise, `await` essentially returns the value itself.\n\n`Awaited<T>` helps define types that reflect this unwrapping behavior, especially in generic contexts or when dealing with complex promise chains or functions that return promises whose resolved values might themselves be promises.\n\nConsider a generic function that takes a promise and processes its result:\n```typescript\nasync function processPromise<P extends Promise<any>>(\nprom: P\n): Promise<{ original: P; awaitedValue: Awaited<P> }> {\n  const awaitedValue = await prom;\n  return { original: prom, awaitedValue };\n}\n\nasync function main() {\n  const p1 = Promise.resolve(10); // Promise<number>\n  const res1 = await processPromise(p1);\n  // res1.awaitedValue is type number (Awaited<Promise<number>>)\n\n  const p2 = Promise.resolve(Promise.resolve(\"hello\")); // Promise<Promise<string>>\n  const res2 = await processPromise(p2);\n  // res2.awaitedValue is type string (Awaited<Promise<Promise<string>>>)\n}\n```\n\n**Incorrect Answers:**\n* `ReturnType<T>` extracts the return type of any function. `Awaited<ReturnType<F>>` would be used for an async function `F`, but `Awaited` itself is about unwrapping any Promise-like type, not just function return types.\n* It unwraps Promises; it doesn't wrap synchronous return types into Promises.\n* It's a type transformation, not a boolean check like a type guard would provide."
        },
        {
            "question": "How can you achieve a form of nominal typing in TypeScript for a type that should be distinct from its underlying primitive type (e.g., creating a distinct `UserID` type that is a string but not assignable from a generic string)?",
            "answers": [
                {"answer": "Using a type alias: `type UserID = string;` This makes `UserID` distinct."},
                {"answer": "Using an enum: `enum UserID { ID = \"ID\" }` and using `UserID.ID` as the type."},
                {"answer": "Using intersection types with a unique branding property: `type UserID = string & { readonly __brand: 'UserID' };`"},
                {"answer": "By creating a class `UserID extends String {}`."}
            ],
            "answer": "Using intersection types with a unique branding property: `type UserID = string & { readonly __brand: 'UserID' };`",
            "explanation": "TypeScript has a structural type system, meaning types are compatible if their structure matches. This can sometimes be too lenient, especially when you want to ensure that a `string` (or `number`) used for one purpose (e.g., a User ID) isn't accidentally used where a `string` for another purpose (e.g., a Product ID) is expected, even if both are just strings.\n\n**Nominal typing** (achieved by name) can be emulated in TypeScript using a technique called **branding** or **tagging**.\n\nThe most common way is to intersect the primitive type with an object type that has a unique, non-existent property (the \"brand\" or \"tag\").\n\n**Correct Technique (Branding):**\n```typescript\n// 1. Define the branded type\ntype UserID = string & { readonly __brand: 'UserID' };\ntype ProductID = string & { readonly __brand: 'ProductID' };\n\n// 2. Create helper functions to create branded values (type assertion needed)\nfunction createUserID(id: string): UserID {\n  return id as UserID;\n}\n\nfunction createProductID(id: string): ProductID {\n  return id as ProductID;\n}\n\n// 3. Usage\nconst userId1 = createUserID(\"user-123\");\nconst productId1 = createProductID(\"prod-456\");\n\nfunction processUser(id: UserID) {\n  console.log(`Processing user: ${id}`);\n}\n\nfunction processProduct(id: ProductID) {\n  console.log(`Processing product: ${id}`);\n}\n\nprocessUser(userId1);    // OK\n// processUser(productId1); // Error: Type 'ProductID' is not assignable to type 'UserID'.\n                         // Types have separate declarations of a private property '__brand'.\n\n// processUser(\"some-random-string\"); // Error: Type 'string' is not assignable to type 'UserID'.\n                                   // Type 'string' is not assignable to type '{ readonly __brand: \"UserID\"; }'.\n\nlet genericString: string = \"generic\";\n// processUser(genericString); // Error\n\n// To use the underlying string value:\nconst idString: string = userId1; // OK, UserID is a subtype of string\n```\n\n**Explanation of the Brand:**\n* `string & { readonly __brand: 'UserID' }`: This means a `UserID` is something that is *both* a `string` AND an object with a (conceptual) readonly property `__brand` whose type is the literal string `'UserID'`.\n* Since a plain string doesn't have the `__brand` property, it's not assignable to `UserID` directly.\n* The `__brand` property doesn't exist at runtime; it's purely a compile-time construct to make the types distinct.\n* The uniqueness of the brand's literal type (e.g., `'UserID'` vs `'ProductID'`) is what distinguishes the different nominal types.\n\n**Incorrect Answers:**\n* `type UserID = string;`: This is just a type alias. `UserID` would be fully interchangeable with `string`, offering no nominal distinction.\n* `enum UserID { ID = \"ID\" }`: This creates an enum with one member. `UserID.ID` would be of type `UserID` (the enum type itself), which is distinct, but it's not a *string* that's branded; it's an enum member. If you wanted `UserID` to be a string with specific allowed values, string enums or string literal unions are better.\n* `class UserID extends String {}`: While classes create nominal types, extending the `String` wrapper object is generally not recommended for this purpose in TypeScript. It introduces prototype chains and object wrappers around primitives, which can be cumbersome and have performance implications. Branding is a more lightweight, compile-time solution."
        }
    ]
},
    {
    "name": "Advanced TypeScript Features Quiz - Set 1",
    "image": "https://images.unsplash.com/photo-1612838320302-4b3b3b3b3b3b",
    "questions": [
        {
            "question": "What is the primary purpose of the `infer` keyword when used within a conditional type in TypeScript?",
            "answers": [
                {"answer": "To infer the type of a generic parameter from its usage within a function body."},
                {"answer": "To declare a new type variable whose type is inferred based on the structure of the type being checked in the true branch of a conditional type."},
                {"answer": "To automatically cast a type to `any` if type inference fails within a conditional type."},
                {"answer": "To force TypeScript to infer a specific literal type instead of a general primitive type."}
            ],
            "answer": "To declare a new type variable whose type is inferred based on the structure of thetype being checked in the true branch of a conditional type.",
            "explanation": "The `infer` keyword in TypeScript is used within the `extends` clause of a conditional type to declare a type variable that will be inferred by TypeScript. If the type being checked (`T` in `T extends U ? X : Y`) matches the pattern where `infer R` is used, then `R` will capture the type that corresponds to that part of the pattern.\n\n**Syntax:**\n`SomeType extends infer InferredType ? TrueType<InferredType> : FalseType;`\nOr, more commonly, within a structured type:\n`SomeType extends AnotherType<infer InferredPart> ? TrueType<InferredPart> : FalseType;`\n\n**Example: Unwrapping a Promise type**\n```typescript\ntype UnwrapPromise<T> = T extends Promise<infer U> ? U : T;\n\n// Usage:\ntype MyStringType = UnwrapPromise<Promise<string>>; // MyStringType is string\ntype MyNumberType = UnwrapPromise<number>;         // MyNumberType is number (not a Promise, so T is returned)\n\nfunction fetchData(): Promise<{ id: number; data: string }> {\n  return Promise.resolve({ id: 1, data: \"Sample\" });\n}\n\n// If we want the type of the data *inside* the Promise returned by fetchData:\ntype FetchedDataType = UnwrapPromise<ReturnType<typeof fetchData>>;\n// FetchedDataType is { id: number; data: string }\n```\nIn `T extends Promise<infer U> ? U : T;`:\n- If `T` is a `Promise<Something>`, TypeScript tries to match `Something` with `infer U`.\n- If it matches, `U` becomes `Something`, and the conditional type resolves to `U`.\n- If `T` is not a `Promise`, the condition is false, and the type resolves to `T`.\n\nThis allows you to extract parts of types in a powerful and flexible way. It's commonly used in utility types like `Parameters<T>`, `ReturnType<T>`, `InstanceType<T>`, and custom complex type transformations."
        },
        {
            "question": "How can you define a mapped type in TypeScript that creates a new object type where all properties of an existing type `T` are made optional and their types are wrapped in `Promise`?",
            "answers": [
                {"answer": "type AsyncOptional<T> = { [P in keyof T]?: Promise<T[P]> };"},
                {"answer": "type AsyncOptional<T> = Partial<Promise<T>>;" },
                {"answer": "type AsyncOptional<T> = { [P in keyof T]: Promise<T[P] | undefined> };"},
                {"answer": "type AsyncOptional<T> = Promise<{ [P in keyof T]?: T[P] }>;"}
            ],
            "answer": "type AsyncOptional<T> = { [P in keyof T]?: Promise<T[P]> };",
            "explanation": "Mapped types allow you to create new types based on the properties of an existing type. The syntax is `{[P in K]: X}` where `K` is a union of property keys and `P` iterates over them.\n\nLet's break down the correct answer: `type AsyncOptional<T> = { [P in keyof T]?: Promise<T[P]> };`\n\n1.  **`[P in keyof T]`**: This iterates over all property keys (`P`) of the input type `T`. `keyof T` gives a union of all public property names of `T`.\n2.  **`?` (Optional Modifier)**: The `?` after `[P in keyof T]` makes each property `P` in the new type optional.\n3.  **`: Promise<T[P]>`**: This defines the type of each property `P` in the new type.\n    * `T[P]` is the original type of the property `P` in type `T`.\n    * `Promise<T[P]>` wraps that original property type in a `Promise`.\n\n**Example Usage:**\n```typescript\ninterface UserProfile {\n  id: number;\n  username: string;\n  email: string;\n}\n\ntype AsyncOptionalUserProfile = AsyncOptional<UserProfile>;\n\n// AsyncOptionalUserProfile would be equivalent to:\n// {\n//   id?: Promise<number>;\n//   username?: Promise<string>;\n//   email?: Promise<string>;\n// }\n\nconst profileData: AsyncOptionalUserProfile = {\n  username: Promise.resolve(\"Alice\"),\n  // id and email are optional\n};\n```\n\n**Why other options are incorrect:**\n* `Partial<Promise<T>>;`: `Partial` makes properties of its generic argument optional. `Promise<T>` is a single promise type, not an object whose properties you'd make optional in this way. This doesn't map over the properties of `T`.\n* `{ [P in keyof T]: Promise<T[P] | undefined> };`: This makes the *value inside* the Promise potentially `undefined` (`Promise<Type | undefined>`), but it doesn't make the property itself optional in the new object type.\n* `Promise<{ [P in keyof T]?: T[P] }>;`: This wraps the *entire resulting object* in a single Promise, rather than wrapping each property's type in a Promise."
        },
        {
            "question": "What is the purpose of a decorator factory in TypeScript?",
            "answers": [
                {"answer": "To create multiple instances of a decorator with different configurations."},
                {"answer": "A function that returns the decorator function itself, allowing the decorator to be configured with parameters when applied."},
                {"answer": "A built-in TypeScript feature that automatically generates decorators based on class structure."},
                {"answer": "To ensure decorators are only applied once to a class or method, acting as a singleton factory."}
            ],
            "answer": "A function that returns the decorator function itself, allowing the decorator to be configured with parameters when applied.",
            "explanation": "A **decorator factory** is a function that returns the actual decorator function. This pattern is used when you want to customize the decorator's behavior by passing arguments to it when you apply the decorator.\n\nIf a decorator expression evaluates to a function, TypeScript treats that function as the decorator. If the decorator expression is a function call (e.g., `@myDecoratorFactory(arg1, arg2)`), then `myDecoratorFactory` is the factory, and it must return the actual decorator function.\n\n**Structure:**\n```typescript\nfunction decoratorFactory(configValue: string) {\n  // This is the factory function. It receives configuration.\n  console.log(`Decorator Factory called with: ${configValue}`);\n\n  return function (target: any, propertyKey: string, descriptor: PropertyDescriptor) {\n    // This is the actual decorator function.\n    // It can use 'configValue' from the outer scope.\n    console.log(`Decorator for ${propertyKey} applied with config: ${configValue}`);\n    // ... decorator logic ...\n  };\n}\n\nclass MyClass {\n  @decoratorFactory(\"customSetting1\") // Applying the decorator via its factory\n  method1() {}\n\n  @decoratorFactory(\"anotherSetting\")\n  method2() {}\n}\n```\n\n**Execution Flow:**\n1.  When `MyClass` is defined, `@decoratorFactory(\"customSetting1\")` is encountered.\n2.  The `decoratorFactory(\"customSetting1\")` function (the factory) is called immediately with `\"customSetting1\"`.\n3.  The factory logs \"Decorator Factory called with: customSetting1\" and returns the inner function (the actual decorator).\n4.  This returned decorator function is then applied to `method1`, logging \"Decorator for method1 applied with config: customSetting1\".\n5.  The same process happens for `method2` with `\"anotherSetting\"`.\n\n**Benefits:**\n* **Configurability:** Allows decorators to be parameterized, making them more reusable and flexible.\n* **Readability:** Can make the intent of the decorator clearer if the configuration is passed explicitly.\n\n**Incorrect Answers:**\n* While you can create different configurations, it's about passing parameters to a single decorator's logic, not creating entirely separate decorator *instances* in an OOP sense.\n* It's a pattern you implement, not an automatic generation feature.\n* It doesn't inherently act as a singleton factory for the decorator's application."
        },
        {
            "question": "What is the difference between a `const enum` and a regular `enum` in TypeScript regarding the compiled JavaScript output?",
            "answers": [
                {"answer": "`const enum` members are always compiled to string literals, while regular `enum` members are numbers."},
                {"answer": "Regular `enum`s generate a lookup object in JavaScript, while `const enum` members are inlined at usage sites, generating no extra JavaScript object if possible."},
                {"answer": "`const enum`s can only have string values, whereas regular `enum`s can have number or string values."},
                {"answer": "There is no difference in the compiled output; `const enum` is only a compile-time check for immutability."}
            ],
            "answer": "Regular `enum`s generate a lookup object in JavaScript, while `const enum` members are inlined at usage sites, generating no extra JavaScript object if possible.",
            "explanation": "**Regular Enums:**\nA standard `enum` in TypeScript compiles down to a JavaScript object that serves as a reverse mapping (from value to name) and a forward mapping (from name to value).\n\n```typescript\n// TypeScript\nenum Direction {\n  Up,\n  Down,\n  Left,\n  Right,\n}\n\nlet dir = Direction.Up;\n```\nCompiled JavaScript (conceptual, may vary slightly):\n```javascript\nvar Direction;\n(function (Direction) {\n    Direction[Direction[\"Up\"] = 0] = \"Up\";\n    Direction[Direction[\"Down\"] = 1] = \"Down\";\n    Direction[Direction[\"Left\"] = 2] = \"Left\";\n    Direction[Direction[\"Right\"] = 3] = \"Right\";\n})(Direction || (Direction = {}));\n\nlet dir = Direction.Up; // dir will be 0\n```\nThis generates an IIFE that populates the `Direction` object.\n\n**Const Enums:**\nA `const enum` is a compile-time only construct. Its members are inlined wherever they are used. No JavaScript object is generated for the enum itself if its members can be fully inlined.\n\n```typescript\n// TypeScript\nconst enum HttpStatus {\n  Ok = 200,\n  NotFound = 404,\n  ServerError = 500,\n}\n\nlet status = HttpStatus.Ok;\nlet isError = status === HttpStatus.ServerError;\n```\nCompiled JavaScript:\n```javascript\nlet status = 200; // HttpStatus.Ok is inlined as 200\nlet isError = status === 500; // HttpStatus.ServerError is inlined as 500\n// No 'HttpStatus' object is generated\n```\n\n**Key Differences & Implications:**\n1.  **JavaScript Output:** Regular enums create runtime objects; `const enum`s typically do not, leading to potentially smaller bundle sizes if values are inlined.\n2.  **Inlining:** `const enum` values are substituted directly at their usage sites.\n3.  **Ambient Contexts:** You cannot use `const enum`s in ambient contexts (e.g., in `.d.ts` files that describe existing JavaScript) because they require the compiler to have access to the original enum definition to inline values. Regular enums can be used in ambient declarations.\n4.  **Computed Members:** `const enum` members can only have constant enum expressions (literals or other `const enum` members). Regular enums can have computed members that are evaluated at runtime.\n\n**When to use `const enum`?**\n* When you want to avoid the overhead of an extra object and function wrapper in your emitted JavaScript.\n* When you are sure that the enum values will be used in contexts where inlining is safe and desirable (e.g., not across separate compilation boundaries without shared source or `--preserveConstEnums`).\n\n**Incorrect Answers:**\n* Both can have numeric values by default. Regular enums can also have string values. `const enum` members are inlined, not necessarily as string literals unless defined as such.\n* `const enum` can also have string values.\n* There is a significant difference in compiled output."
        },
        {
            "question": "How can you use module augmentation in TypeScript to add a new property to an existing interface exported by an external library module?",
            "answers": [
                {"answer": "By re-declaring the interface with the new property in a global `.ts` file."},
                {"answer": "By using `Object.defineProperty` on the imported library's interface at runtime."},
                {"answer": "By creating a new `.d.ts` file, using `declare module 'library-name'` and then re-declaring the interface within that module block with the added properties."},
                {"answer": "By importing the interface, extending it with a new interface, and using the new extended interface throughout the application."}
            ],
            "answer": "By creating a new `.d.ts` file, using `declare module 'library-name'` and then re-declaring the interface within that module block with the added properties.",
            "explanation": "Module augmentation allows you to extend existing modules and their declarations (like interfaces) without modifying their original source code."
        },
        {
            "question": "What is the main advantage of using TypeScript's `unknown` type over `any` when dealing with values of uncertain type?",
            "answers": [
                {"answer": "`unknown` allows implicit conversion to any other type, while `any` requires explicit casting."},
                {"answer": "`unknown` is a subtype of all other types, whereas `any` is a supertype."},
                {"answer": "`unknown` forces you to perform explicit type checks or assertions before performing operations on the value, enhancing type safety, unlike `any` which allows any operation."},
                {"answer": "`unknown` and `any` are functionally identical, but `unknown` provides better JSDoc comments."}
            ],
            "answer": "`unknown` forces you to perform explicit type checks or assertions before performing operations on the value, enhancing type safety, unlike `any` which allows any operation.",
            "explanation": "Both `any` and `unknown` are top types in TypeScript, meaning a value of any type can be assigned to a variable of type `any` or `unknown`.\n\n**`any` (The \"Escape Hatch\"):**\n* If a variable has type `any`, you can perform virtually any operation on it: access any property, call it as a function, assign it to any other type, etc., without TypeScript performing compile-time checks.\n* This effectively opts out of type checking for that variable, which can lead to runtime errors if assumptions about the value are incorrect.\n```typescript\nlet valAny: any = \"hello\";\nconsole.log(valAny.toUpperCase()); // OK at compile time\nvalAny.foo(); // OK at compile time (but likely runtime error)\nlet num: number = valAny; // OK at compile time (but runtime error if valAny is not number-like)\n```\n\n**`unknown` (The Type-Safe Counterpart):**\n* If a variable has type `unknown`, TypeScript **prevents** you from performing most operations on it directly.\n* To use an `unknown` value, you **must first narrow its type** using:\n    * Type guards (`typeof x === \"string\"`, `x instanceof MyClass`, custom type guards).\n    * Type assertions (`x as string`).\n    * Control flow analysis based on equality checks.\n* This forces you to explicitly handle the uncertainty of the type, leading to safer code.\n\n```typescript\nlet valUnknown: unknown = \"hello\";\n\n// console.log(valUnknown.toUpperCase()); // Error: Object is of type 'unknown'.\n// valUnknown.foo();                     // Error\n// let str: string = valUnknown;          // Error: Type 'unknown' is not assignable to type 'string'.\n\nif (typeof valUnknown === 'string') {\n  console.log(valUnknown.toUpperCase()); // OK, valUnknown is narrowed to string here\n  let str: string = valUnknown;         // OK\n}\n\nfunction processValue(val: unknown) {\n  if (val instanceof Date) {\n    console.log(val.getFullYear()); // OK\n  } else if (typeof val === 'number') {\n    console.log(val.toFixed(2)); // OK\n  }\n}\n```\n\n**Main Advantage of `unknown`:**\nIt enforces type safety by requiring developers to prove the type of an `unknown` value before it can be used in potentially unsafe ways. This prevents the accidental errors that `any` can easily allow.\n\n**Incorrect Answers:**\n* `unknown` does *not* allow implicit conversion; it's the opposite. `any` behaves more like that.\n* Both are top types. `unknown` is assignable from any type, but not assignable *to* most types without a check. `any` is assignable from and to any type.\n* They are functionally very different regarding type safety."
        },
        {
            "question": "Which TypeScript utility type constructs a type with a set of properties `K` of a type `T`?",
            "answers": [
                {"answer": "Omit<T, K>"},
                {"answer": "Pick<T, K>"},
                {"answer": "Extract<T, U>"},
                {"answer": "Record<K, T>"}
            ],
            "answer": "Pick<T, K>",
            "explanation": "The `Pick<T, K>` utility type constructs a new type by picking a set of properties `K` (which must be keys of `T`) from an existing type `T`.\n\n**Syntax:** `Pick<Type, Keys>`\n* `Type`: The original type from which to pick properties.\n* `Keys`: A union of string literal types or numeric literal types representing the keys of the properties to pick. These keys must exist in `Type` (`K extends keyof T`).\n\n**Example:**\n```typescript\ninterface User {\n  id: number;\n  name: string;\n  email: string;\n  isAdmin: boolean;\n  createdAt: Date;\n}\n\n// Create a type with only 'id' and 'name' from User\ntype UserSummary = Pick<User, 'id' | 'name'>;\n\n// UserSummary is equivalent to:\n// {\n//   id: number;\n//   name: string;\n// }\n\nconst summary: UserSummary = {\n  id: 1,\n  name: \"Alice\",\n  // email: \"alice@example.com\" // Error: 'email' does not exist in type 'UserSummary'\n};\n```\n\n**Other Utility Types Mentioned:**\n* **`Omit<T, K>`**: Constructs a type by picking all properties from `T` and then removing `K`. It's the opposite of `Pick` in terms of which keys are kept vs. removed.\n    ```typescript\n    type UserDetails = Omit<User, 'isAdmin' | 'createdAt'>;\n    // UserDetails will have 'id', 'name', 'email'\n    ```\n\n* **`Extract<T, U>`**: Constructs a type by extracting from `T` all union members that are assignable to `U`.\n    ```typescript\n    type StringOrNumber = string | number | boolean;\n    type JustStrings = Extract<StringOrNumber, string | (() => void)>; // Result: string\n    ```\n\n* **`Record<K, T>`**: Constructs an object type whose property keys are `K` and whose property values are `T`. `K` typically is `string | number | symbol` or a union of specific string/number literals.\n    ```typescript\n    type PageInfo = 'home' | 'about' | 'contact';\n    type PageVisits = Record<PageInfo, number>;\n    // PageVisits is equivalent to:\n    // {\n    //   home: number;\n    //   about: number;\n    //   contact: number;\n    // }\n    ```"
        },
        {
            "question": "What is a key characteristic and use case for `const` assertions in TypeScript (e.g., `as const`)?",
            "answers": [
                {"answer": "They ensure that an object's properties can be reassigned at runtime but not re-typed."},
                {"answer": "They widen literal types to their primitive equivalents (e.g., 'hello' to string) for more flexibility."},
                {"answer": "They signal to TypeScript to infer the most specific literal types for object properties or array elements and make them `readonly`."},
                {"answer": "They are primarily used to cast `any` type to a specific constant value for improved performance."}
            ],
            "answer": "They signal to TypeScript to infer the most specific literal types for object properties or array elements and make them `readonly`.",
            "explanation": "`as const` is a **const assertion** in TypeScript. When applied to an object literal, array literal, or a literal type, it tells TypeScript to infer the narrowest, most specific type possible and to treat the properties/elements as `readonly`.\n\n**Key Effects of `as const`:**\n\n1.  **Literal Types for Properties/Elements:**\n    * For object properties, string literal types are inferred instead of general `string`, number literal types instead of `number`, etc.\n    * For array elements, they are also inferred as literal types.\n\n2.  **`readonly` Properties:**\n    * Object properties become `readonly`.\n\n3.  **`readonly` Tuples:**\n    * Array literals become `readonly` tuples with specific literal types for each element.\n\n**Example without `as const`:**\n```typescript\nlet config = {\n  mode: \"development\",\n  port: 3000,\n  features: [\"auth\", \"logging\"]\n};\n// Inferred type of config:\n// {\n//   mode: string;         // widened to string\n//   port: number;         // widened to number\n//   features: string[];   // widened to array of strings\n// }\nconfig.mode = \"production\"; // OK\nconfig.port = 8080;       // OK\nconfig.features.push(\"cache\"); // OK\n```\n\n**Example with `as const`:**\n```typescript\nlet configConst = {\n  mode: \"development\",\n  port: 3000,\n  features: [\"auth\", \"logging\"]\n} as const;\n\n// Inferred type of configConst:\n// {\n//   readonly mode: \"development\";     // literal type, readonly\n//   readonly port: 3000;            // literal type, readonly\n//   readonly features: readonly [\"auth\", \"logging\"]; // readonly tuple with literal types\n// }\n\n// configConst.mode = \"production\"; // Error: Cannot assign to 'mode' because it is a read-only property.\n// configConst.port = 8080;       // Error: Cannot assign to 'port' because it is a read-only property.\n// configConst.features.push(\"cache\"); // Error: Property 'push' does not exist on type 'readonly [\"auth\", \"logging\"]'.\n```\n\n**Use Cases:**\n* **Creating True Constants:** When you want to define an object or array that should not be mutated and whose values should be treated as specific literals (e.g., for action types in Redux, status codes, configuration objects).\n* **Improving Type Inference:** Provides more precise types to functions or other parts of your code, enabling better type checking and autocompletion.\n* **API Design:** When you want to define an API that expects very specific literal values.\n\n**Incorrect Answers:**\n* They make properties `readonly`, preventing reassignment.\n* They do the opposite: they narrow types to literals, not widen them.\n* They are a compile-time construct for type inference and immutability, not primarily for casting `any` or runtime performance related to casting."
        },
        {
            "question": "How does TypeScript's indexed access type `T[K]` work, and what are its common use cases?",
            "answers": [
                {"answer": "It dynamically accesses a property `K` of an object `T` at runtime and returns its value."},
                {"answer": "It creates a new type representing the type of the property `K` within type `T`. `K` can be a string literal, number literal, or a union of these corresponding to keys of `T`."},
                {"answer": "It's a way to iterate over the keys of type `T` similar to a `for...in` loop, where `K` is the current key."},
                {"answer": "It defines an array type `T` where `K` specifies the fixed length of the array."}
            ],
            "answer": "It creates a new type representing the type of the property `K` within type `T`. `K` can be a string literal, number literal, or a union of these corresponding to keys of `T`.",
            "explanation": "Indexed access types (also known as lookup types) allow you to look up the type of a specific property on another type.\n\n**Syntax:** `T[K]`\n* `T`: The type you are looking into (e.g., an interface, object type alias, or class type).\n* `K`: The key (or keys) whose property type you want to extract. This can be:\n    * A string literal type (`'propertyName'`)\n    * A number literal type (for array/tuple element types or numeric keys)\n    * A union of string/number literal types\n    * A type variable that extends `keyof T`\n\n**How it Works:**\n`T[K]` resolves to the type of the property named `K` within type `T`.\n\n**Examples:**\n```typescript\ninterface User {\n  id: number;\n  name: string;\n  address: {\n    street: string;\n    city: string;\n  };\n  roles: string[];\n}\n\ntype UserIdType = User['id'];     // UserIdType is number\ntype UserNameType = User['name'];   // UserNameType is string\ntype UserAddressType = User['address']; // UserAddressType is { street: string; city: string; }\ntype UserCityType = User['address']['city']; // UserCityType is string (nested access)\ntype UserRoleElementType = User['roles'][number]; // UserRoleElementType is string (type of elements in roles array)\n\n// Using a union of keys\ntype IdOrNameType = User['id' | 'name']; // IdOrNameType is number | string\n\n// Using with keyof and generics\nfunction getProperty<T, K extends keyof T>(obj: T, key: K): T[K] {\n  return obj[key];\n}\n\nconst user: User = {\n  id: 1, name: \"Alice\", \n  address: { street: \"123 Main St\", city: \"Wonderland\" },\n  roles: [\"admin\", \"editor\"]\n};\n\nconst userName: string = getProperty(user, 'name');\nconst userRoles: string[] = getProperty(user, 'roles');\n```\n\n**Common Use Cases:**\n1.  **Extracting Property Types:** To get the type of a specific property for use elsewhere (e.g., variable annotations, function return types).\n2.  **Generic Functions:** Creating generic functions that operate on properties of objects in a type-safe way (like the `getProperty` example).\n3.  **Mapped Types:** Often used within mapped types to refer to the original type of a property being transformed.\n    ```typescript\n    type ReadonlyProps<T> = {\n      readonly [P in keyof T]: T[P]; // T[P] uses indexed access\n    };\n    ```\n\n**Incorrect Answers:**\n* It's a compile-time type operation, not a runtime value access (though the syntax `obj[key]` for runtime access is similar).\n* It's not for iteration; `keyof T` combined with mapped types is used for that.\n* It doesn't define array length; tuple types define fixed-length arrays."
        },
        {
            "question": "In TypeScript, what is a `never` type primarily used to represent?",
            "answers": [
                {"answer": "A type that can hold any value, similar to `any` but with stricter checking."},
                {"answer": "The type of a value that will never occur. For example, the return type of a function that always throws an error or has an infinite loop."},
                {"answer": "An alias for `void` when a function explicitly returns nothing."},
                {"answer": "A placeholder type for generic parameters that haven't been inferred yet."}
            ],
            "answer": "The type of a value that will never occur. For example, the return type of a function that always throws an error or has an infinite loop.",
            "explanation": "The `never` type in TypeScript represents the type of values that **never** occur.\n\n**Key Characteristics & Use Cases:**\n\n1.  **Functions that Never Return:**\n    * A function that always throws an exception.\n    * A function that contains an infinite loop (and thus never reaches an endpoint).\n    ```typescript\n    function throwError(message: string): never {\n      throw new Error(message);\n    }\n\n    function infiniteLoop(): never {\n      while (true) {}\n    }\n    ```\n    Assigning `never` as the return type tells TypeScript that the normal execution path will not continue after this function call.\n\n2.  **Exhaustiveness Checking in Control Flow:**\n    `never` is extremely useful for ensuring that all possible cases in a union type or a `switch` statement are handled. If a variable can be narrowed down to `never`, it means all legitimate possibilities have been exhausted, and any remaining path should be impossible.\n    ```typescript\n    type Shape = Square | Circle;\n    interface Square { kind: \"square\"; size: number; }\n    interface Circle { kind: \"circle\"; radius: number; }\n\n    function getArea(shape: Shape): number {\n      switch (shape.kind) {\n        case \"square\": return shape.size * shape.size;\n        case \"circle\": return Math.PI * shape.radius ** 2;\n        default:\n          // If all known kinds are handled, 'shape' here would be of type 'never'\n          const _exhaustiveCheck: never = shape;\n          // If a new shape kind is added to the Shape union without updating the switch,\n          // '_exhaustiveCheck = shape' will cause a compile-time error because\n          // the unhandled shape kind cannot be assigned to 'never'.\n          return _exhaustiveCheck;\n      }\n    }\n    ```\n\n3.  **Filtering Union Types in Conditional Types:**\n    In conditional types, if a branch results in `never`, that member is effectively removed from a union if the conditional type is distributive.\n    ```typescript\n    type NonFunctionKeys<T> = {\n      [K in keyof T]: T[K] extends Function ? never : K;\n    }[keyof T];\n\n    interface MyObject {\n      name: string;\n      age: number;\n      greet: () => void;\n    }\n    // NonFunctionKeys<MyObject> will be \"name\" | \"age\"\n    // The 'greet' key results in 'never' and is filtered out.\n    ```\n\n4.  **Bottom Type:**\n    `never` is the bottom type in TypeScript's type system. This means `never` is assignable to every other type, but no type (except `never` itself) is assignable to `never`.\n\n**Incorrect Answers:**\n* `unknown` is more like a type that can hold any value but with strict checking. `any` is the one that allows any value with loose checking.\n* `void` represents the absence of a return value (like a function that returns `undefined` implicitly or explicitly). `never` means the function *never even completes* its normal execution path.\n* It's not a placeholder for uninferred generics; generics often have default types or constraints for that."
        }
    ]
},
    {
    "name": "Comprehensive AWS CI/CD with GitLab and CDK Quiz",
    "image": "https://images.unsplash.com/photo-1523961131990-5EA7c61b2107",
    "questions": [
      {
        "question": "In a GitLab CI/CD pipeline deploying an AWS CDK app, what is the primary purpose of the `cdk synth` command?",
        "answers": [
          {"answer": "To directly deploy the infrastructure to AWS."},
          {"answer": "To synthesize the CDK app into a CloudFormation template."},
          {"answer": "To install project dependencies."},
          {"answer": "To run unit tests for the CDK constructs."}
        ],
        "answer": "To synthesize the CDK app into a CloudFormation template.",
        "explanation": "The `cdk synth` command processes your CDK code and outputs a CloudFormation template, which can then be deployed. It doesn't deploy the resources itself."
      },
      {
        "question": "Which GitLab CI/CD component is responsible for defining the stages, jobs, and scripts that make up your CI/CD pipeline for deploying the CDK app?",
        "answers": [
          {"answer": "GitLab Runner"},
          {"answer": "`.gitlab-ci.yml` file"},
          {"answer": "GitLab Web UI"},
          {"answer": "AWS CodePipeline"}
        ],
        "answer": "`.gitlab-ci.yml` file",
        "explanation": "The `.gitlab-ci.yml` file is the core configuration file where you define your CI/CD pipeline's structure and execution flow within GitLab."
      },
      {
        "question": "When deploying a frontend service (e.g., a React app) using AWS CDK within a GitLab CI/CD pipeline, which AWS service is commonly used for hosting the static assets?",
        "answers": [
          {"answer": "Amazon EC2"},
          {"answer": "AWS Lambda"},
          {"answer": "Amazon S3 (Simple Storage Service)"},
          {"answer": "Amazon RDS"}
        ],
        "answer": "Amazon S3 (Simple Storage Service)",
        "explanation": "Amazon S3 is a highly scalable and cost-effective service for storing and serving static website content, making it ideal for frontend applications. Often, Amazon CloudFront is used in conjunction with S3 for CDN capabilities."
      },
      {
        "question": "How should AWS credentials ideally be managed within a GitLab CI/CD pipeline to allow the CDK to deploy resources?",
        "answers": [
          {"answer": "Hardcoding AWS access keys directly in the `.gitlab-ci.yml` file."},
          {"answer": "Storing AWS access keys as GitLab CI/CD variables (masked and protected)."},
          {"answer": "Committing an IAM user's credentials to the Git repository."},
          {"answer": "Using a shared EC2 instance profile for all pipeline jobs."}
        ],
        "answer": "Storing AWS access keys as GitLab CI/CD variables (masked and protected).",
        "explanation": "GitLab CI/CD variables are the secure way to store sensitive information like AWS credentials. They can be masked in job logs and protected to limit their exposure to specific branches or environments. Using IAM roles with OIDC federation is an even more secure and recommended approach if available."
      },
      {
        "question": "For a backend service (e.g., a Node.js API) deployed with AWS CDK via GitLab, which of these AWS compute services is a common target for containerized applications?",
        "answers": [
          {"answer": "Amazon S3"},
          {"answer": "Amazon CloudFront"},
          {"answer": "Amazon Elastic Container Service (ECS) or Amazon Elastic Kubernetes Service (EKS)"},
          {"answer": "AWS Snowball"}
        ],
        "answer": "Amazon Elastic Container Service (ECS) or Amazon Elastic Kubernetes Service (EKS)",
        "explanation": "ECS and EKS are AWS's managed container orchestration services, suitable for deploying, managing, and scaling containerized backend applications. AWS Lambda is another option for serverless backends."
      },
      {
        "question": "What is the role of `cdk deploy` in the CI/CD pipeline for the CDK app?",
        "answers": [
          {"answer": "To validate the CDK code for syntax errors."},
          {"answer": "To compare the current stack with the deployed stack and show differences."},
          {"answer": "To deploy the synthesized CloudFormation template to your AWS account."},
          {"answer": "To bootstrap the AWS environment for CDK."}
        ],
        "answer": "To deploy the synthesized CloudFormation template to your AWS account.",
        "explanation": "The `cdk deploy` command takes the CloudFormation template generated by `cdk synth` (or synthesizes it if not already done) and provisions or updates the resources in your AWS account."
      },
      {
        "question": "What is the purpose of the `cache` keyword in a `.gitlab-ci.yml` job?",
        "answers": [
          {"answer": "To store job artifacts for later stages."},
          {"answer": "To speed up job execution by reusing downloaded dependencies or build outputs from previous runs."},
          {"answer": "To encrypt sensitive variables used in the job."},
          {"answer": "To define the Docker image used for the job."}
        ],
        "answer": "To speed up job execution by reusing downloaded dependencies or build outputs from previous runs.",
        "explanation": "The `cache` keyword is used to specify a list of files and directories to be cached between job runs, which can significantly speed up pipelines by avoiding re-downloading dependencies or re-building unchanged components."
      },
      {
        "question": "In AWS CDK, what is the key difference between an L1 (CFN) construct and an L2 construct?",
        "answers": [
          {"answer": "L1 constructs are for frontend, L2 for backend."},
          {"answer": "L1 constructs are high-level abstractions with sensible defaults, while L2 constructs map directly to CloudFormation resources."},
          {"answer": "L2 constructs are high-level abstractions with sensible defaults and convenience methods, while L1 constructs map directly to raw CloudFormation resources."},
          {"answer": "L1 constructs are deprecated, and only L2 constructs should be used."}
        ],
        "answer": "L2 constructs are high-level abstractions with sensible defaults and convenience methods, while L1 constructs map directly to raw CloudFormation resources.",
        "explanation": "L1 (CFN) constructs are auto-generated from CloudFormation specifications, providing a direct mapping. L2 constructs are curated, higher-level abstractions that offer more convenience, sensible defaults, and boilerplate reduction for common patterns."
      },
      {
        "question": "To enable GitLab CI/CD pipelines to securely authenticate with AWS without storing long-lived credentials, which AWS IAM feature is commonly used with GitLab's OIDC provider support?",
        "answers": [
          {"answer": "IAM Users with access keys stored as GitLab variables."},
          {"answer": "IAM Roles for EC2 Instance Profiles."},
          {"answer": "IAM Roles with an OIDC identity provider configured for GitLab."},
          {"answer": "AWS Secrets Manager to retrieve temporary credentials."}
        ],
        "answer": "IAM Roles with an OIDC identity provider configured for GitLab.",
        "explanation": "Using an IAM OIDC identity provider allows GitLab to securely request temporary credentials from AWS by assuming an IAM Role, eliminating the need for long-lived AWS access keys in GitLab CI/CD variables."
      },
      {
        "question": "During a frontend deployment using CDK and GitLab CI/CD, which typical command would be run *before* `cdk deploy` to prepare the static assets for an S3 bucket deployment?",
        "answers": [
          {"answer": "`npm test`"},
          {"answer": "`docker build -t frontend .`"},
          {"answer": "`npm run build` or `yarn build`"},
          {"answer": "`cdk synth`"}
        ],
        "answer": "`npm run build` or `yarn build`",
        "explanation": "For most JavaScript-based frontends (React, Vue, Angular), a build command like `npm run build` compiles the application into static HTML, CSS, and JavaScript files that are then uploaded by the CDK's S3 deployment construct."
      },
      {
        "question": "What is the `cdk bootstrap` command primarily used for?",
        "answers": [
          {"answer": "To create a new CDK project from a template."},
          {"answer": "To install the AWS CDK Toolkit globally."},
          {"answer": "To provision initial resources in an AWS environment (account/region) required by the CDK to deploy stacks, like an S3 bucket for assets."},
          {"answer": "To deploy all stacks defined in the CDK app."}
        ],
        "answer": "To provision initial resources in an AWS environment (account/region) required by the CDK to deploy stacks, like an S3 bucket for assets.",
        "explanation": "`cdk bootstrap` sets up the necessary infrastructure (e.g., an S3 bucket for file assets, IAM roles for deployment) that the CDK needs to perform deployments into a specific AWS account and region."
      },
      {
        "question": "How can you ensure a GitLab CI/CD job only runs on specific runners?",
        "answers": [
          {"answer": "By naming the job with a specific prefix."},
          {"answer": "Using the `environment` keyword in the job definition."},
          {"answer": "Assigning `tags` to runners and specifying those tags in the job definition."},
          {"answer": "By configuring runner IP whitelists in project settings."}
        ],
        "answer": "Assigning `tags` to runners and specifying those tags in the job definition.",
        "explanation": "Runners can be configured with tags (e.g., `docker`, `windows`, `gpu`). Jobs in `.gitlab-ci.yml` can then use the `tags` keyword to specify which runners are eligible to execute them."
      },
      {
        "question": "When deploying a backend API using AWS Lambda and API Gateway with CDK, what does API Gateway primarily provide?",
        "answers": [
          {"answer": "Long-term storage for API request and response data."},
          {"answer": "A fully managed compute environment for running the Lambda function."},
          {"answer": "An HTTP endpoint, request routing, authorization, and rate limiting for your Lambda functions."},
          {"answer": "A relational database service for the backend."}
        ],
        "answer": "An HTTP endpoint, request routing, authorization, and rate limiting for your Lambda functions.",
        "explanation": "Amazon API Gateway acts as the 'front door' for your Lambda-based APIs, handling incoming HTTP requests, invoking the correct Lambda function, and managing aspects like authentication, authorization, throttling, and caching."
      },
      {
        "question": "If you want to apply a common configuration or transformation to multiple constructs in a CDK stack or app programmatically (e.g., adding a specific tag to all S3 buckets), what CDK feature would be most suitable?",
        "answers": [
          {"answer": "Manually editing the synthesized CloudFormation template."},
          {"answer": "Using CDK Context variables."},
          {"answer": "Implementing a CDK Aspect."},
          {"answer": "Creating separate L1 constructs for each resource."}
        ],
        "answer": "Implementing a CDK Aspect.",
        "explanation": "CDK Aspects allow you to visit and modify constructs in a scope (like a stack or app) using a visitor pattern. This is ideal for applying cross-cutting concerns like tagging, security policies, or compliance checks."
      },
      {
        "question": "What is the function of `artifacts` in a GitLab CI/CD job?",
        "answers": [
          {"answer": "To specify the Docker image for the job."},
          {"answer": "To cache dependencies between pipeline runs."},
          {"answer": "To define files and directories that should be passed from one job to subsequent jobs in later stages or for download."},
          {"answer": "To store environment variables for the job."}
        ],
        "answer": "To define files and directories that should be passed from one job to subsequent jobs in later stages or for download.",
        "explanation": "Job artifacts are files (e.g., build outputs, test reports) generated by a job that can be used by other jobs in the pipeline or downloaded from the GitLab UI."
      },
      {
        "question": "For a containerized backend service deployed to Amazon ECS using CDK, where would you define the Docker image to use, CPU/memory allocation, and port mappings?",
        "answers": [
          {"answer": "In the GitLab runner configuration."},
          {"answer": "Directly in the Dockerfile."},
          {"answer": "Within an ECS Task Definition, defined using CDK constructs like `ecs.FargateTaskDefinition` or `ecs.Ec2TaskDefinition`."},
          {"answer": "In an S3 bucket policy."}
        ],
        "answer": "Within an ECS Task Definition, defined using CDK constructs like `ecs.FargateTaskDefinition` or `ecs.Ec2TaskDefinition`.",
        "explanation": "An ECS Task Definition is a blueprint for your application. It specifies the container image, CPU and memory, port mappings, environment variables, and other parameters required to run your Docker containers on ECS."
      },
      {
        "question": "What does the `cdk diff` command allow you to do?",
        "answers": [
          {"answer": "Show the differences between two Git branches."},
          {"answer": "Deploy only the changes since the last deployment."},
          {"answer": "Compare the stack defined in your CDK app with the currently deployed stack in AWS and show proposed changes."},
          {"answer": "Calculate the cost difference for the proposed infrastructure changes."}
        ],
        "answer": "Compare the stack defined in your CDK app with the currently deployed stack in AWS and show proposed changes.",
        "explanation": "`cdk diff` is a crucial command to review what changes (creations, updates, deletions) will be made to your AWS infrastructure before actually applying them with `cdk deploy`."
      },
      {
        "question": "In a multi-stage GitLab CI/CD pipeline, how can you define that a job in a later stage should only run after specific jobs in an earlier stage have successfully completed, allowing for parallel execution within stages?",
        "answers": [
          {"answer": "Using the `dependencies` keyword."},
          {"answer": "Using the `needs` keyword with a list of prerequisite jobs."},
          {"answer": "Jobs in later stages automatically wait for all jobs in earlier stages."},
          {"answer": "By setting job priorities with the `priority` keyword."}
        ],
        "answer": "Using the `needs` keyword with a list of prerequisite jobs.",
        "explanation": "The `needs` keyword creates a directed acyclic graph (DAG) of job dependencies, allowing jobs to start as soon as their specified predecessor jobs complete, rather than waiting for the entire previous stage to finish."
      },
      {
        "question": "When serving a frontend application from S3 via CloudFront, what is the purpose of an Origin Access Identity (OAI) or Origin Access Control (OAC)?",
        "answers": [
          {"answer": "To allow public read access to the S3 bucket directly."},
          {"answer": "To provide users with IAM credentials to access the S3 bucket."},
          {"answer": "To restrict direct access to the S3 bucket, ensuring content is only served through CloudFront."},
          {"answer": "To cache S3 bucket content at edge locations."}
        ],
        "answer": "To restrict direct access to the S3 bucket, ensuring content is only served through CloudFront.",
        "explanation": "OAI (older) or OAC (newer, recommended) allows CloudFront to securely fetch private content from an S3 bucket on behalf of viewers, while preventing users from bypassing CloudFront and accessing the S3 bucket content directly."
      },
      {
        "question": "How can you manage environment-specific configurations (e.g., different instance sizes for dev vs. prod) in an AWS CDK application deployed via GitLab CI/CD?",
        "answers": [
          {"answer": "By hardcoding values directly in the CDK constructs."},
          {"answer": "Using separate Git branches for each environment and modifying the CDK code in each branch."},
          {"answer": "Passing context variables (`-c key=value`) or using environment variables during `cdk synth/deploy` within GitLab CI jobs, and reading these in the CDK app."},
          {"answer": "Modifying the CloudFormation template manually after `cdk synth`."}
        ],
        "answer": "Passing context variables (`-c key=value`) or using environment variables during `cdk synth/deploy` within GitLab CI jobs, and reading these in the CDK app.",
        "explanation": "CDK apps can be parameterized using context values (from `cdk.json`, command line, or environment variables). GitLab CI jobs can then set these values differently for various deployment environments (e.g., dev, staging, prod)."
      },
      {
        "question": "What is the significance of the `image` keyword specified at the top level or per-job in `.gitlab-ci.yml`?",
        "answers": [
          {"answer": "It defines the application image to be deployed to AWS ECS."},
          {"answer": "It specifies the Docker image in which the GitLab CI/CD job will run."},
          {"answer": "It sets the background image for the GitLab pipeline view."},
          {"answer": "It links to a base CDK construct image."}
        ],
        "answer": "It specifies the Docker image in which the GitLab CI/CD job will run.",
        "explanation": "The `image` keyword tells the GitLab Runner which Docker image to use as the execution environment for the CI/CD job, providing necessary tools and dependencies (e.g., Node.js, Python, AWS CLI, CDK CLI)."
      },
      {
        "question": "Which AWS service would you typically use with CDK to define and manage a relational database (e.g., PostgreSQL, MySQL) for your backend service?",
        "answers": [
          {"answer": "Amazon DynamoDB"},
          {"answer": "Amazon S3"},
          {"answer": "Amazon RDS (Relational Database Service) or Amazon Aurora"},
          {"answer": "Amazon ElastiCache"}
        ],
        "answer": "Amazon RDS (Relational Database Service) or Amazon Aurora",
        "explanation": "Amazon RDS provides managed relational database instances. Aurora is AWS's MySQL and PostgreSQL-compatible relational database built for the cloud. Both can be provisioned and managed using CDK."
      },
      {
        "question": "If your CDK application needs to package local code, such as a Lambda function's handler or a Docker image from a local Dockerfile, how does the CDK handle these?",
        "answers": [
          {"answer": "You must manually pre-upload these to S3 or ECR before running `cdk deploy`."},
          {"answer": "CDK automatically discovers and ignores local files."},
          {"answer": "CDK uses 'Assets' which bundle local files/directories or build Docker images and upload them to a bootstrap S3 bucket or ECR repository during deployment."},
          {"answer": "These files are embedded directly into the CloudFormation template."}
        ],
        "answer": "CDK uses 'Assets' which bundle local files/directories or build Docker images and upload them to a bootstrap S3 bucket or ECR repository during deployment.",
        "explanation": "The CDK's asset model allows you to define Lambda code from a local directory or Docker images from a local Dockerfile. During `cdk deploy`, the CDK CLI packages and uploads these assets to AWS (S3 for files, ECR for images) so CloudFormation can use them."
      },
      {
        "question": "What is the purpose of 'Protected Variables' in GitLab CI/CD settings?",
        "answers": [
          {"answer": "To make variables available only to specific users."},
          {"answer": "To encrypt all CI/CD variables by default."},
          {"answer": "To expose variables only to jobs running on protected branches or tags, enhancing security for sensitive data."},
          {"answer": "To prevent variables from being overridden by job-level definitions."}
        ],
        "answer": "To expose variables only to jobs running on protected branches or tags, enhancing security for sensitive data.",
        "explanation": "Protected variables are only passed to jobs running on protected branches (e.g., `main`) or protected tags, which is a best practice for managing secrets like deployment credentials."
      },
      {
        "question": "For a serverless backend, besides AWS Lambda, which service is commonly used with CDK to store application state or data in a highly available NoSQL fashion?",
        "answers": [
          {"answer": "Amazon RDS"},
          {"answer": "Amazon EBS (Elastic Block Store)"},
          {"answer": "Amazon DynamoDB"},
          {"answer": "AWS Storage Gateway"}
        ],
        "answer": "Amazon DynamoDB",
        "explanation": "Amazon DynamoDB is a fully managed, serverless NoSQL key-value and document database that offers high scalability and availability, making it a popular choice for serverless applications built with Lambda and CDK."
      },
      {
        "question": "How can you destroy all AWS resources created by a specific CDK stack using the CDK CLI?",
        "answers": [
          {"answer": "By deleting the stack from the AWS CloudFormation console."},
          {"answer": "Using the `cdk delete <StackName>` command."},
          {"answer": "Using the `cdk destroy <StackName>` command."},
          {"answer": "By removing the stack definition from your CDK app and running `cdk deploy`."}
        ],
        "answer": "Using the `cdk destroy <StackName>` command.",
        "explanation": "The `cdk destroy <StackName>` command will remove the specified stack and all its associated resources from your AWS account, as defined in your CDK application."
      },
      {
        "question": "How can you include external YAML configurations into your main `.gitlab-ci.yml` file to promote reusability and modularity?",
        "answers": [
          {"answer": "Using `import` statements at the beginning of the file."},
          {"answer": "Using the `include` keyword with paths to local files, external URLs, or templates from other projects."},
          {"answer": "Copy-pasting the content directly into the main file."},
          {"answer": "GitLab CI/CD does not support including external YAML files."}
        ],
        "answer": "Using the `include` keyword with paths to local files, external URLs, or templates from other projects.",
        "explanation": "The `include` keyword in `.gitlab-ci.yml` allows you to break down complex pipeline configurations into smaller, reusable pieces, which can be sourced from the same repository, other repositories, or even remote URLs."
      },
      {
        "question": "In a sophisticated CI/CD pipeline for a backend service, where would 'integration tests' that verify interactions between your service and other services (like a database) typically run?",
        "answers": [
          {"answer": "Only on developers' local machines before pushing code."},
          {"answer": "As part of the `cdk synth` command."},
          {"answer": "In a dedicated test stage in the GitLab CI/CD pipeline, after the service has been deployed to a test/staging environment."},
          {"answer": "During the Docker image build process."}
        ],
        "answer": "In a dedicated test stage in the GitLab CI/CD pipeline, after the service has been deployed to a test/staging environment.",
        "explanation": "Integration tests require the service and its dependencies (like databases or other microservices) to be running. Thus, they are typically executed in the CI/CD pipeline after a deployment to a non-production environment."
      },
      {
        "question": "What is a 'CDK Aspect' used for?",
        "answers": [
          {"answer": "To define the visual appearance of CDK construct documentation."},
          {"answer": "A specific type of L3 construct for building user interfaces."},
          {"answer": "A mechanism to apply operations or modifications to all constructs of a certain type within a scope (e.g., a Stack or App) using a visitor pattern."},
          {"answer": "To manage IAM permissions for CDK deployments."}
        ],
        "answer": "A mechanism to apply operations or modifications to all constructs of a certain type within a scope (e.g., a Stack or App) using a visitor pattern.",
        "explanation": "Aspects traverse the construct tree and allow you to perform actions like adding tags, enforcing policies, or checking for compliance on constructs encountered during the traversal."
      },
      {
        "question": "When deploying a backend service, if you need to store sensitive information like database passwords for the *application to use at runtime* (not pipeline credentials), which AWS services are commonly integrated with CDK for this?",
        "answers": [
          {"answer": "Hardcoding them in the application source code."},
          {"answer": "Storing them as plain text in GitLab CI/CD variables."},
          {"answer": "AWS Secrets Manager or AWS Systems Manager Parameter Store (SecureString type)."},
          {"answer": "Embedding them directly in ECS Task Definitions as environment variables."}
        ],
        "answer": "AWS Secrets Manager or AWS Systems Manager Parameter Store (SecureString type).",
        "explanation": "AWS Secrets Manager and Parameter Store (using SecureString) are designed to securely store and manage secrets. CDK applications can grant IAM permissions to services like ECS or Lambda to retrieve these secrets at runtime."
      },
      {
        "question": "What is the role of the `stages` keyword in `.gitlab-ci.yml`?",
        "answers": [
          {"answer": "To define the different deployment environments (dev, staging, prod)."},
          {"answer": "To list the Docker images used in the pipeline."},
          {"answer": "To define the sequence of execution for groups of jobs. Jobs in the same stage can run in parallel, while jobs in different stages run sequentially by default."},
          {"answer": "To specify the conditions under which a pipeline should run."}
        ],
        "answer": "To define the sequence of execution for groups of jobs. Jobs in the same stage can run in parallel, while jobs in different stages run sequentially by default.",
        "explanation": "The `stages` keyword defines the overall order of execution for your CI/CD pipeline (e.g., build, test, deploy). All jobs within a single stage are typically run in parallel (if enough runners are available)."
      },
      {
        "question": "If you define an S3 bucket in your CDK app for frontend assets, how can you ensure its contents are automatically deleted when the CDK stack is destroyed?",
        "answers": [
          {"answer": "S3 buckets are always automatically deleted when their parent stack is destroyed."},
          {"answer": "You must manually empty the bucket before running `cdk destroy`."},
          {"answer": "By setting the `autoDeleteObjects` property to `true` and `removalPolicy` to `RemovalPolicy.DESTROY` on the CDK S3 Bucket construct."},
          {"answer": "This requires a custom Lambda resource to be written and deployed."}
        ],
        "answer": "By setting the `autoDeleteObjects` property to `true` and `removalPolicy` to `RemovalPolicy.DESTROY` on the CDK S3 Bucket construct.",
        "explanation": "By default, S3 buckets are not deleted if they contain objects. Setting `autoDeleteObjects: true` (which deploys a helper Lambda) along with `removalPolicy: RemovalPolicy.DESTROY` ensures the bucket and its contents are removed when the stack is destroyed."
      },
      {
        "question": "Which AWS service is essential for routing traffic to your frontend (on S3/CloudFront) and backend services (on ECS/Lambda) using custom domain names?",
        "answers": [
          {"answer": "AWS Direct Connect"},
          {"answer": "Amazon Route 53"},
          {"answer": "AWS Transit Gateway"},
          {"answer": "Amazon VPC Endpoints"}
        ],
        "answer": "Amazon Route 53",
        "explanation": "Amazon Route 53 is a scalable Domain Name System (DNS) web service. You use it to configure DNS records (e.g., A, CNAME) to point your custom domain names to AWS resources like CloudFront distributions or Application Load Balancers fronting your services."
      },
      {
        "question": "How can you pass dynamic values generated in one GitLab CI/CD job (e.g., a built image tag) to another job in a subsequent stage?",
        "answers": [
          {"answer": "By writing them to a shared file system accessible by all runners."},
          {"answer": "Using global environment variables defined in GitLab settings."},
          {"answer": "By writing the values to a `.env` file, declaring it as an artifact using `artifacts:reports:dotenv`, which then loads them as variables into subsequent jobs in the same pipeline."},
          {"answer": "This is not possible; jobs are completely isolated."}
        ],
        "answer": "By writing the values to a `.env` file, declaring it as an artifact using `artifacts:reports:dotenv`, which then loads them as variables into subsequent jobs in the same pipeline.",
        "explanation": "Using `artifacts:reports:dotenv` allows jobs to export variables that will be automatically available as environment variables to jobs in later stages, facilitating dynamic data flow within the pipeline."
      },
      {
        "question": "When defining an Amazon ECS service in CDK, what is the purpose of setting a `desiredCount` property?",
        "answers": [
          {"answer": "The maximum number of tasks the service can scale out to."},
          {"answer": "The minimum number of healthy tasks the service should maintain."},
          {"answer": "The number of tasks that ECS should launch and maintain for the service."},
          {"answer": "The CPU units desired by each task."}
        ],
        "answer": "The number of tasks that ECS should launch and maintain for the service.",
        "explanation": "The `desiredCount` in an ECS service definition specifies how many instances of your task definition (i.e., containers) should be running and maintained by the ECS scheduler."
      },
      {
        "question": "What is a common strategy for versioning your frontend and backend services within the CI/CD pipeline, especially when using CDK for deployments?",
        "answers": [
          {"answer": "Using the date of deployment as the version number."},
          {"answer": "Using Git commit SHAs or Git tags as version identifiers, and passing these to the CDK app (e.g., for Docker image tags or Lambda versions)."},
          {"answer": "Incrementing a version number stored in a text file in the repository."},
          {"answer": "CDK automatically versions deployments, so manual versioning is not needed."}
        ],
        "answer": "Using Git commit SHAs or Git tags as version identifiers, and passing these to the CDK app (e.g., for Docker image tags or Lambda versions).",
        "explanation": "Git commit SHAs or tags provide unique and traceable version identifiers. These can be passed into the CDK app (e.g., via context or environment variables in the pipeline) to tag Docker images, version Lambda functions, or name deployment artifacts."
      },
      {
        "question": "What does the `rules` keyword in a GitLab CI/CD job allow you to do with more fine-grained control than the older `only`/`except` keywords?",
        "answers": [
          {"answer": "Define the execution order of jobs within a stage."},
          {"answer": "Specify the Docker image for the job based on conditions."},
          {"answer": "Define complex conditions (e.g., based on branch name, commit message, file changes, variables) for when a job should be added to a pipeline, and control job variables based on these conditions."},
          {"answer": "Limit the number of concurrent runners for a job."}
        ],
        "answer": "Define complex conditions (e.g., based on branch name, commit message, file changes, variables) for when a job should be added to a pipeline, and control job variables based on these conditions.",
        "explanation": "The `rules` keyword provides a powerful way to include or exclude jobs from pipelines based on various conditions, offering more flexibility than `only`/`except` for controlling pipeline behavior."
      },
      {
        "question": "How can you reference a resource created in one CDK Stack (e.g., a VPC's ID) in another CDK Stack within the same CDK App?",
        "answers": [
          {"answer": "By hardcoding the ARN of the resource from the AWS console."},
          {"answer": "CDK stacks are completely isolated and cannot reference resources from each other."},
          {"answer": "By passing the construct or its properties (e.g., `vpc.vpcId`) as props to the dependent stack during instantiation, or by using `CfnOutput` in one stack and `Fn.importValue` in the other (cross-stack references)."},
          {"answer": "Using global CDK variables."}
        ],
        "answer": "By passing the construct or its properties (e.g., `vpc.vpcId`) as props to the dependent stack during instantiation, or by using `CfnOutput` in one stack and `Fn.importValue` in the other (cross-stack references).",
        "explanation": "For stacks within the same CDK app and deployed to the same account/region, direct property passing is common. For loosely coupled stacks or stacks in different regions/accounts, CloudFormation cross-stack references via `CfnOutput` and `Fn.importValue` (or `Stack.exportValue` and `Fn.importValue` in CDK) are used."
      },
      {
        "question": "For monitoring the health and performance of your backend services (e.g., Lambda, ECS) deployed via CDK, which AWS service provides metrics, logs, and alarms?",
        "answers": [
          {"answer": "AWS Config"},
          {"answer": "Amazon CloudWatch"},
          {"answer": "AWS X-Ray"},
          {"answer": "AWS Service Catalog"}
        ],
        "answer": "Amazon CloudWatch",
        "explanation": "Amazon CloudWatch is the central monitoring service for AWS resources. It collects logs, metrics (e.g., CPU utilization, invocation counts, error rates), and allows you to set alarms based on these to get notified of issues."
      },
      {
        "question": "What is a 'GitLab Environment' in the context of CI/CD?",
        "answers": [
          {"answer": "The operating system of the GitLab runner."},
          {"answer": "A way to define named deployment targets (e.g., `staging`, `production`) in GitLab, which helps track deployments, control access, and manage environment-specific variables."},
          {"answer": "A specific version of the GitLab software."},
          {"answer": "A container image used for CI/CD jobs."}
        ],
        "answer": "A way to define named deployment targets (e.g., `staging`, `production`) in GitLab, which helps track deployments, control access, and manage environment-specific variables.",
        "explanation": "GitLab Environments provide a way to track deployments to specific targets, view deployment history, define environment-specific variables, and implement features like protected environments and manual approvals for deployments."
      },
      {
        "question": "If you need to execute custom logic during a CloudFormation deployment that isn't natively supported by existing resources (e.g., provisioning a resource in an on-premises system or making a complex API call after infrastructure is up), what CDK mechanism can you use?",
        "answers": [
          {"answer": "Manually intervene during the `cdk deploy` process."},
          {"answer": "CDK Aspects."},
          {"answer": "AWS CDK Custom Resources, often backed by an AWS Lambda function."},
          {"answer": "Modifying the synthesized CloudFormation template to add custom scripts."}
        ],
        "answer": "AWS CDK Custom Resources, often backed by an AWS Lambda function.",
        "explanation": "CDK Custom Resources allow you to extend CloudFormation's capabilities by writing custom provisioning logic in an AWS Lambda function, which is invoked by CloudFormation during stack create, update, or delete operations."
      },
      {
        "question": "When building Docker images for your backend service within the GitLab CI/CD pipeline, where would you typically push these images to be accessible by AWS ECS or EKS?",
        "answers": [
          {"answer": "To a local Docker registry on the GitLab runner."},
          {"answer": "Directly to the EC2 instances that will run the containers."},
          {"answer": "To Amazon Elastic Container Registry (ECR) or another container registry like Docker Hub or GitLab's own container registry."},
          {"answer": "To an S3 bucket."}
        ],
        "answer": "To Amazon Elastic Container Registry (ECR) or another container registry like Docker Hub or GitLab's own container registry.",
        "explanation": "Container orchestrators like ECS and EKS pull Docker images from a container registry. Amazon ECR is a fully managed Docker container registry provided by AWS, making it a common choice. GitLab also offers a built-in registry."
      },
      {
        "question": "How can you manually trigger a deployment job in GitLab for a specific environment (e.g., production) after all tests have passed and perhaps after a manual review?",
        "answers": [
          {"answer": "By pushing a specific commit message."},
          {"answer": "This is not possible; all jobs must be automated."},
          {"answer": "By configuring the deployment job with `when: manual` and optionally associating it with a GitLab Environment."},
          {"answer": "By SSHing into the runner and executing the script."}
        ],
        "answer": "By configuring the deployment job with `when: manual` and optionally associating it with a GitLab Environment.",
        "explanation": "Setting `when: manual` for a job in `.gitlab-ci.yml` adds a 'play' button in the GitLab UI for that job, allowing authorized users to trigger it manually, often used for production deployments or sensitive operations."
      },
      {
        "question": "What is the primary benefit of using higher-level (L2/L3) constructs in AWS CDK over lower-level L1 (CFN) constructs?",
        "answers": [
          {"answer": "L2/L3 constructs offer finer-grained control over every CloudFormation property."},
          {"answer": "L2/L3 constructs provide better performance during `cdk synth`."},
          {"answer": "L2/L3 constructs encapsulate best practices, provide sensible defaults, and reduce boilerplate code, making infrastructure definition more concise and developer-friendly."},
          {"answer": "L1 constructs are always more secure than L2/L3 constructs."}
        ],
        "answer": "L2/L3 constructs encapsulate best practices, provide sensible defaults, and reduce boilerplate code, making infrastructure definition more concise and developer-friendly.",
        "explanation": "Higher-level constructs (L2 and pattern-based L3) are designed to simplify common use cases by abstracting away much of the complexity of raw CloudFormation, providing convenient APIs and incorporating AWS best practices."
      },
      {
        "question": "What is 'Infrastructure as Code (IaC)' and how does AWS CDK embody this principle?",
        "answers": [
          {"answer": "IaC is manually configuring infrastructure through the AWS Console, and CDK documents these steps."},
          {"answer": "IaC is the practice of managing and provisioning infrastructure through machine-readable definition files, rather than manual configuration. CDK allows you to define infrastructure using familiar programming languages."},
          {"answer": "IaC refers to the physical hardware infrastructure of data centers, which CDK helps to inventory."},
          {"answer": "IaC is a specific AWS service for code deployment, and CDK is its client."}
        ],
        "answer": "IaC is the practice of managing and provisioning infrastructure through machine-readable definition files, rather than manual configuration. CDK allows you to define infrastructure using familiar programming languages.",
        "explanation": "CDK implements IaC by allowing developers to use languages like TypeScript, Python, Java, etc., to define cloud resources, enabling versioning, reusability, and automated provisioning of infrastructure."
      },
      {
        "question": "How can you implement a basic approval step before deploying to a production environment in GitLab CI/CD?",
        "answers": [
          {"answer": "By adding a `sleep` command to the deployment job."},
          {"answer": "By configuring the production deployment job with `when: manual` and ensuring only authorized users can trigger it, possibly combined with Protected Environments."},
          {"answer": "By sending an email notification and waiting for a reply before proceeding."},
          {"answer": "GitLab CI/CD does not support explicit approval steps; third-party tools are required."}
        ],
        "answer": "By configuring the production deployment job with `when: manual` and ensuring only authorized users can trigger it, possibly combined with Protected Environments.",
        "explanation": "A `when: manual` job requires explicit user action to start. Combined with GitLab's Protected Environments feature, you can restrict who is allowed to trigger deployments to critical environments like production."
      },
      {
        "question": "When using TypeScript for your AWS CDK app, what is the primary purpose of the `cdk.json` file?",
        "answers": [
          {"answer": "To store AWS credentials for deployment."},
          {"answer": "To define the CloudFormation template directly in JSON format."},
          {"answer": "To specify how the CDK Toolkit should execute your app (e.g., the command to run like `npx ts-node --prefer-ts-exts bin/my-app.ts`) and to store context values."},
          {"answer": "To list all npm dependencies for the CDK project."}
        ],
        "answer": "To specify how the CDK Toolkit should execute your app (e.g., the command to run like `npx ts-node --prefer-ts-exts bin/my-app.ts`) and to store context values.",
        "explanation": "The `cdk.json` file tells the CDK CLI how to run your CDK application (via the `app` key) and can also be used to store persistent context data that parameterizes your CDK stacks."
      },
      {
        "question": "If your frontend application (e.g., hosted on S3/CloudFront) needs to make authenticated API calls to your backend service (e.g., API Gateway with Lambda authorizers), which AWS service can help manage user sign-up, sign-in, and token-based authentication?",
        "answers": [
          {"answer": "AWS IAM (Identity and Access Management)"},
          {"answer": "Amazon Cognito"},
          {"answer": "AWS Shield"},
          {"answer": "AWS Key Management Service (KMS)"}
        ],
        "answer": "Amazon Cognito",
        "explanation": "Amazon Cognito provides user identity and access management for web and mobile applications. It can handle user registration, sign-in, and issue JWT tokens that can be used to authenticate API calls to services like API Gateway."
      },
      {
        "question": "What is a 'merge request pipeline' (or 'branch pipeline') in GitLab CI/CD?",
        "answers": [
          {"answer": "A pipeline that only runs after a merge request has been merged."},
          {"answer": "A pipeline that is manually triggered from the merge request UI."},
          {"answer": "A pipeline that runs on the commits of a merge request's source branch, or specifically for the merge request itself, often used to run tests and quality checks before merging."},
          {"answer": "A pipeline that deploys the changes from a merge request directly to production."}
        ],
        "answer": "A pipeline that runs on the commits of a merge request's source branch, or specifically for the merge request itself, often used to run tests and quality checks before merging.",
        "explanation": "Merge request pipelines are crucial for CI, as they allow you to validate changes in isolation before they are integrated into the main codebase, helping to catch issues early."
      },
      {
        "question": "How does the AWS CDK Toolkit typically determine which AWS region and account to deploy resources to if not explicitly specified in the code or environment variables?",
        "answers": [
          {"answer": "It always defaults to `us-east-1` and the default account in your AWS CLI profile."},
          {"answer": "It prompts the user for the region and account during every `cdk deploy`."},
          {"answer": "It primarily uses the region and account configured in the current AWS CLI profile (e.g., via `aws configure` or environment variables like `AWS_PROFILE`, `AWS_DEFAULT_REGION`)."},
          {"answer": "It reads the region and account from the `cdk.json` file."}
        ],
        "answer": "It primarily uses the region and account configured in the current AWS CLI profile (e.g., via `aws configure` or environment variables like `AWS_PROFILE`, `AWS_DEFAULT_REGION`).",
        "explanation": "The CDK CLI relies on the AWS SDK's standard credential and region resolution chain, which often defaults to the settings in your active AWS CLI profile or standard AWS environment variables. These can be overridden per stack in CDK code or via CLI parameters if needed."
      },
      {
        "question": "In the context of deploying a frontend and backend, what is a 'monorepo' vs. 'polyrepo' approach, and how might it affect the GitLab CI/CD pipeline structure?",
        "answers": [
          {"answer": "Monorepo means one pipeline for all projects; polyrepo means no pipelines."},
          {"answer": "Monorepo stores frontend and backend in the same repository, potentially sharing a single complex pipeline or using path-based triggers. Polyrepo uses separate repositories, leading to distinct pipelines per service."},
          {"answer": "Monorepo is for monolithic apps, polyrepo for microservices; CDK only supports polyrepo."},
          {"answer": "Monorepo uses one GitLab instance, polyrepo uses multiple."}
        ],
        "answer": "Monorepo stores frontend and backend in the same repository, potentially sharing a single complex pipeline or using path-based triggers. Polyrepo uses separate repositories, leading to distinct pipelines per service.",
        "explanation": "A monorepo can simplify cross-service changes but may require more complex CI/CD logic (e.g., `rules:changes`) to avoid rebuilding/redeploying unaffected services. Polyrepos offer simpler, independent pipelines but can make coordinated deployments more challenging."
      },
      {
        "question": "What is the `needs:` keyword in GitLab CI/CD and how does it differ from `dependencies:` used with `artifacts`?",
        "answers": [
          {"answer": "`needs:` specifies Docker images, `dependencies:` specifies software packages."},
          {"answer": "`needs:` defines job execution order creating a DAG, allowing earlier start than stage-based execution; `dependencies:` controls artifact download from specific jobs that `needs:` implies."},
          {"answer": "`dependencies:` defines job execution order, `needs:` controls artifact download."},
          {"answer": "They are interchangeable keywords with the same functionality."}
        ],
        "answer": "`needs:` defines job execution order creating a DAG, allowing earlier start than stage-based execution; `dependencies:` controls artifact download from specific jobs that `needs:` implies.",
        "explanation": "`needs:` allows a job to start as soon as listed prior jobs complete, irrespective of stage. If `needs:` is used, a job will by default only download artifacts from the jobs listed in `needs:`. The `dependencies:` keyword can further refine this or be used with stage-based execution to specify which jobs' artifacts to download."
      },
      {
        "question": "When defining an AWS Lambda function in CDK using a construct like `lambda.Function`, how can you specify its runtime environment (e.g., Node.js 18.x, Python 3.11)?",
        "answers": [
          {"answer": "By setting an environment variable in the GitLab CI/CD job."},
          {"answer": "It is automatically detected from the handler file's extension."},
          {"answer": "Using the `runtime` property of the `lambda.Function` construct, e.g., `lambda.Runtime.NODEJS_18_X`."},
          {"answer": "By including a `runtime.txt` file in the Lambda deployment package."}
        ],
        "answer": "Using the `runtime` property of the `lambda.Function` construct, e.g., `lambda.Runtime.NODEJS_18_X`.",
        "explanation": "The CDK's Lambda constructs provide a `runtime` property where you specify the desired Lambda runtime environment using predefined constants like `lambda.Runtime.NODEJS_18_X`, `lambda.Runtime.PYTHON_3_11`, etc."
      },
      {
        "question": "What is the primary role of AWS CloudFormation, which AWS CDK uses under the hood?",
        "answers": [
          {"answer": "A code repository service similar to Git."},
          {"answer": "A build service for compiling application code."},
          {"answer": "An infrastructure provisioning and management service that allows you to model, provision, and manage AWS and third-party resources using templates."},
          {"answer": "A monitoring service for tracking application performance."}
        ],
        "answer": "An infrastructure provisioning and management service that allows you to model, provision, and manage AWS and third-party resources using templates.",
        "explanation": "AWS CDK synthesizes CloudFormation templates. CloudFormation then interprets these templates to create, update, or delete AWS resources in a predictable and declarative manner."
      },
      {
        "question": "What is the purpose of the `allow_failure: true` attribute for a job in `.gitlab-ci.yml`?",
        "answers": [
          {"answer": "It makes the job automatically retry on failure."},
          {"answer": "It allows the job to fail without causing the entire pipeline to fail, often used for non-critical jobs like code linters or optional tests."},
          {"answer": "It forces the job to always report success, regardless of its exit code."},
          {"answer": "It skips the job execution entirely."}
        ],
        "answer": "It allows the job to fail without causing the entire pipeline to fail, often used for non-critical jobs like code linters or optional tests.",
        "explanation": "When `allow_failure: true` is set, a job's failure will not stop the pipeline's progression or mark the overall pipeline as failed. This is useful for informational jobs or non-blocking checks."
      },
      {
        "question": "How can AWS CDK help in managing and deploying multiple instances of your application for different environments (e.g., staging, production) from the same CDK codebase?",
        "answers": [
          {"answer": "CDK does not support multi-environment deployments; a separate CDK app is needed for each."},
          {"answer": "By manually copying and pasting stack definitions and renaming resources."},
          {"answer": "By parameterizing stacks using props, context variables, or environment variables. Different instances of the app/stacks can be synthesized and deployed with environment-specific configurations (e.g., `new MyStack(app, 'StagingStack', { envType: 'staging' })`)."},
          {"answer": "Through AWS CloudFormation StackSets, which CDK directly manages."}
        ],
        "answer": "By parameterizing stacks using props, context variables, or environment variables. Different instances of the app/stacks can be synthesized and deployed with environment-specific configurations (e.g., `new MyStack(app, 'StagingStack', { envType: 'staging' })`).",
        "explanation": "CDK's programmatic nature allows you to instantiate stacks multiple times with different configurations, often driven by environment variables or context values passed from the CI/CD pipeline, enabling consistent deployments across environments from a single codebase."
      }
    ]
  },
    {
    "name": "AWS Fullstack Developer Interview Quiz (Comprehensive)",
    "image": "https://images.unsplash.com/photo-1589149098258-3e9102cd63d3",
    "questions": [
        {
            "question": "You need to deploy a scalable, serverless REST API. Which combination of AWS services is most suitable for the API endpoint and backend logic?",
            "answers": [
                {"answer": "EC2 and Elastic Load Balancer"},
                {"answer": "API Gateway and AWS Lambda"},
                {"answer": "AWS AppSync and Elastic Beanstalk"},
                {"answer": "Amazon S3 and AWS Step Functions"}
            ],
            "answer": "API Gateway and AWS Lambda",
            "explanation": "API Gateway creates, publishes, maintains, monitors, and secures APIs. AWS Lambda runs code serverlessly, ideal for backend logic triggered by API Gateway."
        },
        {
            "question": "For a modern web application, where would you host the static frontend assets (e.g., React, Angular, Vue build files) to ensure low latency and high availability globally?",
            "answers": [
                {"answer": "Directly on an AWS Lambda function"},
                {"answer": "On an Amazon EC2 instance with a web server"},
                {"answer": "In Amazon S3, distributed by Amazon CloudFront"},
                {"answer": "In Amazon DynamoDB"}
            ],
            "answer": "In Amazon S3, distributed by Amazon CloudFront",
            "explanation": "S3 provides object storage, and CloudFront (CDN) caches assets at edge locations, reducing latency."
        },
        {
            "question": "Your application requires a flexible NoSQL database that can scale seamlessly and provide single-digit millisecond latency. Which AWS database service is the best fit?",
            "answers": [
                {"answer": "Amazon RDS for PostgreSQL"},
                {"answer": "Amazon Redshift"},
                {"answer": "Amazon DynamoDB"},
                {"answer": "Amazon Aurora"}
            ],
            "answer": "Amazon DynamoDB",
            "explanation": "DynamoDB is a key-value/document database delivering low-latency performance at scale, fully managed and serverless."
        },
        {
            "question": "Which AWS service provides a fully managed continuous integration and continuous delivery (CI/CD) workflow to build, test, and deploy your application code?",
            "answers": [
                {"answer": "AWS CodeCommit"},
                {"answer": "AWS CodeBuild"},
                {"answer": "AWS CodeDeploy"},
                {"answer": "AWS CodePipeline"}
            ],
            "answer": "AWS CodePipeline",
            "explanation": "CodePipeline automates CI/CD workflows, integrating with CodeCommit (source), CodeBuild (build), and CodeDeploy (deployment)."
        },
        {
            "question": "To manage user authentication and authorization for your web and mobile applications, which AWS service offers user pools and identity pools?",
            "answers": [
                {"answer": "AWS IAM (Identity and Access Management)"},
                {"answer": "Amazon Cognito"},
                {"answer": "AWS Secrets Manager"},
                {"answer": "AWS Shield"}
            ],
            "answer": "Amazon Cognito",
            "explanation": "Cognito provides user sign-up/sign-in and access control. User pools are directories; identity pools grant AWS service access."
        },
        {
            "question": "Scenario: Your application allows users to upload images. You need to store the original image, automatically create a thumbnail version, and record image metadata. Which set of services would you primarily use to implement this serverlessly?",
            "answers": [
                {"answer": "EC2 for image processing, RDS for metadata, S3 for storage."},
                {"answer": "S3 for storage, Lambda for thumbnail generation triggered by S3 events, DynamoDB for metadata."},
                {"answer": "Elastic Beanstalk for image processing, S3 for storage, ElastiCache for metadata."},
                {"answer": "API Gateway to receive images, Lambda to store on EBS, RDS for metadata."}
            ],
            "answer": "S3 for storage, Lambda for thumbnail generation triggered by S3 events, DynamoDB for metadata.",
            "explanation": "S3 stores images. S3 events trigger Lambda for thumbnailing. DynamoDB stores metadata for fast querying."
        },
        {
            "question": "Scenario: A serverless API built with API Gateway and Lambda is experiencing intermittent failures. Which AWS services are essential for diagnosing and troubleshooting these issues by inspecting logs, metrics, and request traces?",
            "answers": [
                {"answer": "AWS Config, AWS Trusted Advisor, and Amazon Inspector."},
                {"answer": "Amazon CloudWatch (Logs & Metrics) and AWS X-Ray."},
                {"answer": "AWS CloudFormation, AWS Systems Manager, and AWS Health Dashboard."},
                {"answer": "Amazon S3 (for logs), AWS Glue (for log processing), and Amazon QuickSight (for visualization)."}
            ],
            "answer": "Amazon CloudWatch (Logs & Metrics) and AWS X-Ray.",
            "explanation": "CloudWatch Logs captures logs, CloudWatch Metrics provides performance data, and X-Ray offers end-to-end request tracing for debugging."
        },
        {
            "question": "Scenario: You are building a chat application where multiple users need to receive real-time messages. Which AWS service is specifically designed to manage persistent WebSocket connections from clients to enable this real-time, two-way communication?",
            "answers": [
                {"answer": "Amazon SQS for message queuing."},
                {"answer": "Amazon SNS for push notifications."},
                {"answer": "AWS AppSync with GraphQL subscriptions."},
                {"answer": "Amazon API Gateway (WebSocket APIs)."}
            ],
            "answer": "Amazon API Gateway (WebSocket APIs).",
            "explanation": "API Gateway WebSocket APIs enable real-time, two-way communication by managing persistent connections with clients."
        },
        {
            "question": "Scenario: Your fullstack application consists of several microservices (e.g., order service, payment service, notification service) that need to communicate asynchronously to improve resilience and scalability. Which AWS service is best suited for reliably queuing messages between these microservices?",
            "answers": [
                {"answer": "Amazon Kinesis Data Streams for real-time data ingestion."},
                {"answer": "AWS Step Functions for orchestrating complex workflows."},
                {"answer": "Amazon SQS (Simple Queue Service)."},
                {"answer": "Amazon ElastiCache for in-memory caching."}
            ],
            "answer": "Amazon SQS (Simple Queue Service).",
            "explanation": "SQS enables decoupled, scalable microservices by providing managed message queues for asynchronous communication."
        },
        {
            "question": "How should your application, running on AWS Lambda or EC2, securely access database credentials or third-party API keys without hardcoding them into the application code?",
            "answers": [
                {"answer": "Store them in a text file within the deployment package."},
                {"answer": "Pass them as environment variables directly in the Lambda/EC2 configuration console."},
                {"answer": "Use AWS Secrets Manager or AWS Systems Manager Parameter Store (SecureString)."},
                {"answer": "Embed them in a configuration object directly in the source code."}
            ],
            "answer": "Use AWS Secrets Manager or AWS Systems Manager Parameter Store (SecureString).",
            "explanation": "Secrets Manager (lifecycle, rotation) and Parameter Store SecureString provide secure, IAM-controlled access to secrets at runtime."
        },
        {
            "question": "What is the primary purpose of a NAT Gateway within an Amazon VPC?",
            "answers": [
                {"answer": "To allow instances in public subnets to access the internet."},
                {"answer": "To allow instances in private subnets to initiate outbound traffic to the internet while preventing inbound traffic."},
                {"answer": "To provide a dedicated hardware connection to AWS."},
                {"answer": "To inspect traffic between subnets for malicious activity."}
            ],
            "answer": "To allow instances in private subnets to initiate outbound traffic to the internet while preventing inbound traffic.",
            "explanation": "A NAT Gateway is a managed service that allows resources in private subnets (e.g., backend EC2 instances, Lambda functions) to access the internet or other AWS services, but prevents the internet from initiating connections with those instances."
        },
        {
            "question": "In Amazon S3, what is the default storage class for newly uploaded objects if none is specified?",
            "answers": [
                {"answer": "S3 Glacier Deep Archive"},
                {"answer": "S3 Intelligent-Tiering"},
                {"answer": "S3 Standard"},
                {"answer": "S3 One Zone-IA"}
            ],
            "answer": "S3 Standard",
            "explanation": "S3 Standard is the default storage class, offering high durability, availability, and performance for frequently accessed data."
        },
        {
            "question": "Which AWS service allows you to run Docker containers without managing the underlying EC2 instances, focusing purely on the container workload?",
            "answers": [
                {"answer": "Amazon EC2 with Docker installed"},
                {"answer": "Amazon ECS with EC2 launch type"},
                {"answer": "AWS Fargate"},
                {"answer": "AWS Elastic Beanstalk with Docker platform"}
            ],
            "answer": "AWS Fargate",
            "explanation": "AWS Fargate is a serverless compute engine for containers that works with both Amazon ECS and EKS. You don't need to provision, configure, or scale clusters of virtual machines to run containers."
        },
        {
            "question": "What is the primary role of AWS IAM Roles when granting permissions to AWS services or applications running on EC2/Lambda?",
            "answers": [
                {"answer": "To create permanent access keys for services."},
                {"answer": "To define user passwords and MFA settings."},
                {"answer": "To securely delegate permissions to entities you trust, without sharing long-term credentials."},
                {"answer": "To manage billing and cost allocation for AWS resources."}
            ],
            "answer": "To securely delegate permissions to entities you trust, without sharing long-term credentials.",
            "explanation": "IAM Roles provide temporary security credentials that AWS services or applications can use to make AWS API calls. This is more secure than embedding access keys."
        },
        {
            "question": "You want to implement a publish/subscribe messaging pattern to send notifications to multiple interested downstream services. Which AWS service is most suitable for this?",
            "answers": [
                {"answer": "Amazon SQS (Simple Queue Service)"},
                {"answer": "Amazon SNS (Simple Notification Service)"},
                {"answer": "AWS Step Functions"},
                {"answer": "Amazon Kinesis Data Streams"}
            ],
            "answer": "Amazon SNS (Simple Notification Service)",
            "explanation": "SNS is a fully managed pub/sub messaging service that enables decoupling of microservices, distributed systems, and serverless applications. Publishers send messages to topics, and multiple subscribers (e.g., Lambda, SQS, HTTP endpoints) receive them."
        },
        {
            "question": "What is the main benefit of using Amazon RDS Multi-AZ deployments for a relational database?",
            "answers": [
                {"answer": "Enhanced read scalability using multiple read replicas."},
                {"answer": "Reduced cost compared to single AZ deployments."},
                {"answer": "Increased database write performance."},
                {"answer": "Enhanced availability and durability through synchronous replication to a standby instance in a different AZ."}
            ],
            "answer": "Enhanced availability and durability through synchronous replication to a standby instance in a different AZ.",
            "explanation": "RDS Multi-AZ deployments automatically replicate data synchronously to a standby instance in a different Availability Zone, providing data redundancy, eliminating I/O freezes, and minimizing latency spikes during system backups. It provides failover support for DB instances."
        },
        {
            "question": "Which file in an AWS CodeBuild project defines the build commands and related settings?",
            "answers": [
                {"answer": "Dockerfile"},
                {"answer": "buildspec.yml (or buildspec.yaml)"},
                {"answer": "appspec.yml"},
                {"answer": "template.yaml"}
            ],
            "answer": "buildspec.yml (or buildspec.yaml)",
            "explanation": "A buildspec file is a collection of build commands and related settings, in YAML format, that CodeBuild uses to run a build. It defines phases like install, pre_build, build, and post_build."
        },
        {
            "question": "When using Amazon CloudFront, what is the purpose of an 'Origin'?",
            "answers": [
                {"answer": "The AWS region where CloudFront was configured."},
                {"answer": "The end-user's location from which requests are made."},
                {"answer": "The source location (e.g., S3 bucket, HTTP server) from which CloudFront gets your files to cache and serve."},
                {"answer": "A specific cache behavior rule."}
            ],
            "answer": "The source location (e.g., S3 bucket, HTTP server) from which CloudFront gets your files to cache and serve.",
            "explanation": "An origin in CloudFront is the original location of your content. CloudFront retrieves content from the origin and caches it at edge locations closer to users."
        },
        {
            "question": "What is AWS Amplify primarily designed to help developers with?",
            "answers": [
                {"answer": "Managing low-level network infrastructure."},
                {"answer": "Building, deploying, and hosting fullstack web and mobile applications with features like auth, storage, and APIs."},
                {"answer": "Performing large-scale data analytics and warehousing."},
                {"answer": "Orchestrating complex machine learning training jobs."}
            ],
            "answer": "Building, deploying, and hosting fullstack web and mobile applications with features like auth, storage, and APIs.",
            "explanation": "AWS Amplify provides a set of tools and services that enable developers to quickly build and deploy scalable fullstack applications, offering CLI toolchains, UI components, and a hosting service."
        },
        {
            "question": "In DynamoDB, what is the main difference between a Local Secondary Index (LSI) and a Global Secondary Index (GSI)?",
            "answers": [
                {"answer": "LSIs can only be created at table creation, while GSIs can be added later."},
                {"answer": "LSIs share the table's provisioned throughput, while GSIs have their own."},
                {"answer": "LSIs must use the same partition key as the base table, while GSIs can use different partition and sort keys."},
                {"answer": "All of the above."}
            ],
            "answer": "All of the above.",
            "explanation": "LSIs use the same partition key as the base table but a different sort key, share throughput, and must be created at table creation. GSIs can have different partition and sort keys, have separate provisioned throughput, and can be created/deleted after table creation."
        },
        {
            "question": "What is the purpose of AWS WAF (Web Application Firewall)?",
            "answers": [
                {"answer": "To manage DNS records for your domain."},
                {"answer": "To provide secure remote access to EC2 instances."},
                {"answer": "To protect web applications from common web exploits like SQL injection and cross-site scripting (XSS)."},
                {"answer": "To encrypt data at rest in S3 buckets."}
            ],
            "answer": "To protect web applications from common web exploits like SQL injection and cross-site scripting (XSS).",
            "explanation": "AWS WAF helps protect your web applications or APIs against common web exploits that may affect availability, compromise security, or consume excessive resources by allowing you to configure rules that filter traffic."
        },
        {
            "question": "If you want to define your entire AWS infrastructure as code, allowing for repeatable and predictable deployments, which AWS service or tool would you primarily use?",
            "answers": [
                {"answer": "AWS Management Console"},
                {"answer": "AWS SDKs"},
                {"answer": "AWS CloudFormation or AWS CDK (Cloud Development Kit)"},
                {"answer": "AWS Elastic Beanstalk"}
            ],
            "answer": "AWS CloudFormation or AWS CDK (Cloud Development Kit)",
            "explanation": "AWS CloudFormation provides a common language to describe and provision all the infrastructure resources in your cloud environment. AWS CDK allows you to define your cloud infrastructure in familiar programming languages."
        },
        {
            "question": "What type of API Gateway endpoint is best suited if you want your API to be accessible only from within your Amazon VPC?",
            "answers": [
                {"answer": "Edge-optimized endpoint"},
                {"answer": "Regional endpoint"},
                {"answer": "Private endpoint"},
                {"answer": "Public endpoint"}
            ],
            "answer": "Private endpoint",
            "explanation": "Private API endpoints are accessible only from your Amazon Virtual Private Cloud (VPC) by using an interface VPC endpoint. This keeps traffic within the AWS network and not exposed to the public internet."
        },
        {
            "question": "Which AWS service would you use to orchestrate a multi-step workflow involving several Lambda functions, human approval steps, and conditional logic?",
            "answers": [
                {"answer": "Amazon SQS"},
                {"answer": "AWS Lambda itself with callbacks"},
                {"answer": "AWS Step Functions"},
                {"answer": "Amazon EventBridge"}
            ],
            "answer": "AWS Step Functions",
            "explanation": "AWS Step Functions lets you coordinate multiple AWS services into serverless workflows. You can define state machines that describe your workflow as a series of steps, their relationships, and their inputs and outputs."
        },
        {
            "question": "What is a key benefit of using AWS Lambda Layers?",
            "answers": [
                {"answer": "To automatically scale Lambda function concurrency."},
                {"answer": "To reduce the deployment package size of Lambda functions and share common code/dependencies."},
                {"answer": "To provide a dedicated HTTP endpoint for Lambda functions."},
                {"answer": "To encrypt environment variables for Lambda functions."}
            ],
            "answer": "To reduce the deployment package size of Lambda functions and share common code/dependencies.",
            "explanation": "Lambda Layers allow you to package libraries and other dependencies that you can share across multiple Lambda functions, keeping your deployment packages small and making it easier to manage common components."
        },
        {
            "question": "In AWS CodeDeploy, what does an 'AppSpec file' define?",
            "answers": [
                {"answer": "The source code repository location."},
                {"answer": "The build commands for compiling the application."},
                {"answer": "Instructions for how to deploy the application, including source files, lifecycle event hooks, and deployment configurations."},
                {"answer": "The IAM role permissions for the deployment."}
            ],
            "answer": "Instructions for how to deploy the application, including source files, lifecycle event hooks, and deployment configurations.",
            "explanation": "The Application Specification (AppSpec) file is a YAML or JSON formatted file used by CodeDeploy to manage a deployment. It specifies source files, hooks to run at different lifecycle events (e.g., BeforeInstall, AfterInstall), and other deployment parameters."
        },
        {
            "question": "Which feature of Amazon S3 helps prevent accidental data deletion or overwriting by keeping multiple variants of an object in the same bucket?",
            "answers": [
                {"answer": "S3 Cross-Region Replication"},
                {"answer": "S3 Versioning"},
                {"answer": "S3 Lifecycle Policies"},
                {"answer": "S3 Storage Class Analysis"}
            ],
            "answer": "S3 Versioning",
            "explanation": "S3 Versioning allows you to keep multiple versions of an object in one bucket. This can help you recover objects from accidental deletion or application failures, and archive objects."
        },
        {
            "question": "What is the primary function of Amazon Route 53?",
            "answers": [
                {"answer": "To provide a secure VPN connection to your VPC."},
                {"answer": "To act as a scalable Domain Name System (DNS) web service, including domain registration and health checks."},
                {"answer": "To distribute incoming application traffic across multiple targets, such as EC2 instances."},
                {"answer": "To manage SSL/TLS certificates for your applications."}
            ],
            "answer": "To act as a scalable Domain Name System (DNS) web service, including domain registration and health checks.",
            "explanation": "Amazon Route 53 is a highly available and scalable cloud DNS web service. It is designed to give developers and businesses an extremely reliable and cost-effective way to route end users to Internet applications."
        },
        {
            "question": "You need to cache frequently accessed data from your RDS database to reduce latency for read-heavy workloads. Which AWS service is suitable for this?",
            "answers": [
                {"answer": "Amazon S3"},
                {"answer": "Amazon DynamoDB Accelerator (DAX)"},
                {"answer": "Amazon ElastiCache (using Redis or Memcached)"},
                {"answer": "AWS Storage Gateway"}
            ],
            "answer": "Amazon ElastiCache (using Redis or Memcached)",
            "explanation": "Amazon ElastiCache is a web service that makes it easy to deploy, operate, and scale an in-memory cache in the cloud. It improves application performance by allowing you to retrieve information from fast, managed, in-memory caches, instead of relying entirely on slower disk-based databases."
        },
        {
            "question": "For a serverless application, what is an 'event source' in the context of AWS Lambda?",
            "answers": [
                {"answer": "The programming language used to write the Lambda function."},
                {"answer": "The AWS service or custom application that publishes events to trigger the Lambda function."},
                {"answer": "The IAM role that grants the Lambda function permissions."},
                {"answer": "The output data returned by the Lambda function."}
            ],
            "answer": "The AWS service or custom application that publishes events to trigger the Lambda function.",
            "explanation": "An event source is an AWS service (like S3, API Gateway, SQS, DynamoDB Streams) or a custom application that generates events that trigger an AWS Lambda function to run."
        },
        {
            "question": "What is the concept of 'Idempotency' in the context of API design and Lambda functions, and why is it important?",
            "answers": [
                {"answer": "Ensuring an operation can be performed multiple times with the same effect as if it were performed only once; important for handling retries and duplicates."},
                {"answer": "Making the API accessible only from specific IP addresses for security."},
                {"answer": "Optimizing the API for the lowest possible latency."},
                {"answer": "Allowing the API to be versioned easily without breaking existing clients."}
            ],
            "answer": "Ensuring an operation can be performed multiple times with the same effect as if it were performed only once; important for handling retries and duplicates.",
            "explanation": "Idempotency ensures that making the same request multiple times yields the same result as making it once. This is crucial in distributed systems where retries due to network issues or transient errors are common, preventing unintended side effects like duplicate processing."
        },
        {
            "question": "Which AWS service would you use if you need to build a GraphQL API backend for your application?",
            "answers": [
                {"answer": "Amazon API Gateway with REST endpoints"},
                {"answer": "AWS Lambda directly"},
                {"answer": "AWS AppSync"},
                {"answer": "Amazon EC2 with a custom GraphQL server"}
            ],
            "answer": "AWS AppSync",
            "explanation": "AWS AppSync is a managed service that uses GraphQL to make it easy for applications to get exactly the data they need. It can connect to various data sources like DynamoDB, Lambda, RDS, and HTTP endpoints."
        },
        {
            "question": "How can you grant an EC2 instance permissions to access an S3 bucket without using long-term access keys?",
            "answers": [
                {"answer": "By embedding access keys in the EC2 user data."},
                {"answer": "By creating an IAM user and storing its credentials on the EC2 instance."},
                {"answer": "By assigning an IAM Role with the necessary S3 permissions to the EC2 instance profile."},
                {"answer": "By configuring the S3 bucket policy to allow anonymous access."}
            ],
            "answer": "By assigning an IAM Role with the necessary S3 permissions to the EC2 instance profile.",
            "explanation": "Using an IAM Role associated with an EC2 instance profile is the most secure way. The EC2 instance automatically receives temporary credentials from the role, eliminating the need to manage access keys."
        },
        {
            "question": "What is a primary use case for Amazon Elastic File System (EFS)?",
            "answers": [
                {"answer": "Storing block-level storage volumes for EC2 instances with high IOPS requirements."},
                {"answer": "Providing object storage for static website hosting."},
                {"answer": "Offering scalable, shared file storage for use with AWS Cloud services and on-premises resources, accessible via NFS protocol."},
                {"answer": "Long-term archival of data at very low cost."}
            ],
            "answer": "Offering scalable, shared file storage for use with AWS Cloud services and on-premises resources, accessible via NFS protocol.",
            "explanation": "Amazon EFS provides simple, scalable, elastic file storage that can be mounted by multiple EC2 instances (or other services like ECS/EKS) simultaneously. It's ideal for shared datasets, content management systems, etc."
        },
        {
            "question": "In the context of AWS networking, what is the difference between a Security Group and a Network ACL (NACL)?",
            "answers": [
                {"answer": "Security Groups are stateless; NACLs are stateful."},
                {"answer": "Security Groups operate at the instance level; NACLs operate at the subnet level."},
                {"answer": "Security Groups only allow rules; NACLs only have deny rules."},
                {"answer": "There is no functional difference; they are interchangeable."}
            ],
            "answer": "Security Groups operate at the instance level; NACLs operate at the subnet level.",
            "explanation": "Security Groups act as a virtual firewall for EC2 instances to control inbound and outbound traffic at the instance level (stateful). Network ACLs act as a firewall for controlling traffic in and out of one or more subnets (stateless)."
        },
        {
            "question": "If you need to run a Lambda function at the edge locations of CloudFront to customize content delivery (e.g., modify headers, A/B testing), which service would you use?",
            "answers": [
                {"answer": "AWS WAF"},
                {"answer": "AWS Shield Advanced"},
                {"answer": "Lambda@Edge"},
                {"answer": "Amazon API Gateway regional endpoints"}
            ],
            "answer": "Lambda@Edge",
            "explanation": "Lambda@Edge lets you run Lambda functions at AWS Edge Locations in response to CloudFront events (viewer request, origin request, origin response, viewer response), allowing you to customize content delivery with low latency."
        },
        {
            "question": "What is a 'Dead-Letter Queue (DLQ)' in Amazon SQS used for?",
            "answers": [
                {"answer": "To store messages that have been successfully processed."},
                {"answer": "To archive old messages that are no longer needed."},
                {"answer": "To isolate and handle messages that cannot be processed successfully by a consumer application after a certain number of retries."},
                {"answer": "To increase the throughput of the main SQS queue."}
            ],
            "answer": "To isolate and handle messages that cannot be processed successfully by a consumer application after a certain number of retries.",
            "explanation": "A DLQ is a queue where other (source) queues can send messages that can't be processed successfully. This helps troubleshoot problematic messages without blocking the main queue and allows for later analysis or reprocessing."
        },
        {
            "question": "Which AWS service provides managed relational database instances with automated patching, backups, and scaling, supporting engines like MySQL, PostgreSQL, SQL Server, etc.?",
            "answers": [
                {"answer": "Amazon DynamoDB"},
                {"answer": "Amazon Redshift"},
                {"answer": "Amazon RDS (Relational Database Service)"},
                {"answer": "Amazon DocumentDB"}
            ],
            "answer": "Amazon RDS (Relational Database Service)",
            "explanation": "Amazon RDS makes it easy to set up, operate, and scale a relational database in the cloud. It provides cost-efficient and resizable capacity while automating time-consuming administration tasks."
        },
        {
            "question": "When using AWS CodePipeline, what is an 'Artifact'?",
            "answers": [
                {"answer": "A specific version of the pipeline configuration."},
                {"answer": "The collection of files or changes that are output by an action in the pipeline (e.g., build output, source code)."},
                {"answer": "A manual approval step in the pipeline."},
                {"answer": "A third-party tool integrated into the pipeline."}
            ],
            "answer": "The collection of files or changes that are output by an action in the pipeline (e.g., build output, source code).",
            "explanation": "Artifacts in CodePipeline are the files (like source code, built applications, or configuration files) that are passed between stages and actions in your pipeline. They are stored in an S3 artifact bucket."
        },
        {
            "question": "What is the primary purpose of Amazon CloudTrail?",
            "answers": [
                {"answer": "To monitor application performance and collect metrics."},
                {"answer": "To provide a visual interface for managing AWS resources."},
                {"answer": "To log, continuously monitor, and retain account activity related to actions across your AWS infrastructure (API calls)."},
                {"answer": "To automate infrastructure provisioning using code."}
            ],
            "answer": "To log, continuously monitor, and retain account activity related to actions across your AWS infrastructure (API calls).",
            "explanation": "CloudTrail provides event history of your AWS account activity, including actions taken through the AWS Management Console, AWS SDKs, command line tools, and other AWS services. This is crucial for security analysis, resource change tracking, and compliance auditing."
        },
        {
            "question": "Which AWS service offers a fully managed, highly scalable, and cost-effective data warehouse solution?",
            "answers": [
                {"answer": "Amazon RDS"},
                {"answer": "Amazon DynamoDB"},
                {"answer": "Amazon Redshift"},
                {"answer": "Amazon S3 Select"}
            ],
            "answer": "Amazon Redshift",
            "explanation": "Amazon Redshift is a fast, fully managed, petabyte-scale data warehouse service that makes it simple and cost-effective to analyze all your data using standard SQL and your existing Business Intelligence (BI) tools."
        },
        {
            "question": "In Amazon Cognito User Pools, what is the role of 'triggers'?",
            "answers": [
                {"answer": "To automatically scale the user pool capacity."},
                {"answer": "To invoke AWS Lambda functions at various stages of the user lifecycle (e.g., pre sign-up, post confirmation, pre token generation)."},
                {"answer": "To enforce Multi-Factor Authentication (MFA) for all users."},
                {"answer": "To integrate with third-party identity providers directly."}
            ],
            "answer": "To invoke AWS Lambda functions at various stages of the user lifecycle (e.g., pre sign-up, post confirmation, pre token generation).",
            "explanation": "Cognito User Pool triggers allow you to customize user workflows by invoking Lambda functions at specific points, such as validating user attributes before sign-up, sending custom verification messages, or modifying claims in ID tokens."
        },
        {
            "question": "You need to provision your AWS infrastructure using a familiar programming language like Python, TypeScript, or Java. Which AWS Infrastructure as Code (IaC) tool would you choose?",
            "answers": [
                {"answer": "AWS CloudFormation templates (YAML/JSON)"},
                {"answer": "AWS Management Console"},
                {"answer": "AWS CDK (Cloud Development Kit)"},
                {"answer": "AWS CLI scripts"}
            ],
            "answer": "AWS CDK (Cloud Development Kit)",
            "explanation": "The AWS CDK is an open-source software development framework to define your cloud application resources using familiar programming languages. It provisions your resources through AWS CloudFormation."
        },
        {
            "question": "What does 'provisioned throughput' refer to in the context of Amazon DynamoDB?",
            "answers": [
                {"answer": "The total amount of data storage available for a table."},
                {"answer": "The number of read and write operations per second that a table or index can support."},
                {"answer": "The network bandwidth allocated to the DynamoDB table."},
                {"answer": "The number of concurrent user connections allowed."}
            ],
            "answer": "The number of read and write operations per second that a table or index can support.",
            "explanation": "Provisioned throughput is measured in Read Capacity Units (RCUs) and Write Capacity Units (WCUs). You specify the capacity you need, and DynamoDB allocates resources to meet that capacity with predictable performance."
        },
        {
            "question": "Which deployment strategy in AWS CodeDeploy gradually shifts traffic from the old version of an application to the new version, allowing for monitoring and quick rollback if issues occur?",
            "answers": [
                {"answer": "In-place deployment"},
                {"answer": "Blue/green deployment"},
                {"answer": "Canary deployment or Linear deployment"},
                {"answer": "All-at-once deployment"}
            ],
            "answer": "Canary deployment or Linear deployment",
            "explanation": "Canary and Linear deployments (types of rolling updates) shift traffic in configurable increments (e.g., 10% at a time). Blue/green swaps all traffic to a new environment after testing. In-place updates the existing instances."
        },
        {
            "question": "What is Amazon EventBridge primarily used for in a modern serverless architecture?",
            "answers": [
                {"answer": "Storing large binary objects securely."},
                {"answer": "Building event-driven applications by routing events between AWS services, custom applications, and SaaS applications."},
                {"answer": "Providing a relational database service."},
                {"answer": "Managing user identities and access permissions."}
            ],
            "answer": "Building event-driven applications by routing events between AWS services, custom applications, and SaaS applications.",
            "explanation": "Amazon EventBridge is a serverless event bus service that makes it easy to connect applications together using data from your own applications, integrated Software-as-a-Service (SaaS) applications, and AWS services. It enables building loosely coupled, event-driven architectures."
        },
        {
            "question": "When configuring an S3 bucket for static website hosting, what is typically used as the 'index document'?",
            "answers": [
                {"answer": "A JSON file listing all website assets."},
                {"answer": "The main JavaScript file for a single-page application."},
                {"answer": "The HTML file that serves as the default page for a directory (e.g., index.html)."},
                {"answer": "A configuration file for CloudFront."}
            ],
            "answer": "The HTML file that serves as the default page for a directory (e.g., index.html).",
            "explanation": "When you configure an S3 bucket for website hosting, the index document (commonly index.html) is the webpage that Amazon S3 returns when a request is made to the root of a website or any subfolder."
        },
        {
            "question": "What is the difference between AWS Shield Standard and AWS Shield Advanced?",
            "answers": [
                {"answer": "Shield Standard is a paid service; Shield Advanced is free."},
                {"answer": "Shield Standard protects only EC2 instances; Shield Advanced protects all AWS resources."},
                {"answer": "Shield Standard provides automatic protection against common DDoS attacks for all AWS customers at no additional charge; Shield Advanced provides enhanced, customizable protection and access to the DDoS Response Team (DRT)."},
                {"answer": "Shield Standard is for network layer attacks; Shield Advanced is for application layer attacks."}
            ],
            "answer": "Shield Standard provides automatic protection against common DDoS attacks for all AWS customers at no additional charge; Shield Advanced provides enhanced, customizable protection and access to the DDoS Response Team (DRT).",
            "explanation": "AWS Shield Standard is automatically enabled for all AWS customers. Shield Advanced is a paid service offering more sophisticated protection for applications running on services like EC2, ELB, CloudFront, Route 53, and Global Accelerator, including 24x7 access to the AWS DDoS Response Team (DRT) and cost protection against DDoS-related spikes."
        },
        {
            "question": "How does AWS Key Management Service (KMS) help with data encryption?",
            "answers": [
                {"answer": "By directly encrypting and decrypting large volumes of data within the KMS service itself."},
                {"answer": "By creating, managing, and controlling the use of cryptographic keys (Customer Master Keys - CMKs) used to encrypt your data stored in other AWS services or applications."},
                {"answer": "By providing a hardware security module (HSM) that you fully manage."},
                {"answer": "By scanning your data for sensitive information and automatically encrypting it."}
            ],
            "answer": "By creating, managing, and controlling the use of cryptographic keys (Customer Master Keys - CMKs) used to encrypt your data stored in other AWS services or applications.",
            "explanation": "AWS KMS provides a secure and resilient service for managing cryptographic keys. It integrates with many AWS services to simplify encrypting data using these keys. You control the lifecycle and permissions of the keys (CMKs), which are used to encrypt/decrypt data keys, which in turn encrypt/decrypt your actual data."
        },
        {
            "question": "You have a containerized application defined with a Dockerfile. Which AWS service is specifically designed to store and manage your Docker container images?",
            "answers": [
                {"answer": "Amazon S3"},
                {"answer": "AWS CodeCommit"},
                {"answer": "Amazon ECR (Elastic Container Registry)"},
                {"answer": "Amazon EC2 Instance Store"}
            ],
            "answer": "Amazon ECR (Elastic Container Registry)",
            "explanation": "Amazon ECR is a fully-managed Docker container registry that makes it easy for developers to store, manage, and deploy Docker container images. It integrates well with ECS, EKS, and Fargate."
        },
        {
            "question": "What is a VPC Endpoint and what problem does it solve?",
            "answers": [
                {"answer": "A VPN connection to your on-premises network; solves hybrid connectivity."},
                {"answer": "A public IP address for your EC2 instance; solves internet accessibility."},
                {"answer": "It enables you to privately connect your VPC to supported AWS services (e.g., S3, DynamoDB) and VPC endpoint services without requiring an internet gateway, NAT device, VPN connection, or AWS Direct Connect connection. Solves secure, private connectivity to services."},
                {"answer": "A load balancer for distributing traffic; solves high availability."}
            ],
            "answer": "It enables you to privately connect your VPC to supported AWS services (e.g., S3, DynamoDB) and VPC endpoint services without requiring an internet gateway, NAT device, VPN connection, or AWS Direct Connect connection. Solves secure, private connectivity to services.",
            "explanation": "VPC Endpoints keep traffic between your VPC and the supported AWS service on the Amazon network, enhancing security and potentially reducing data transfer costs. There are Interface Endpoints (using Elastic Network Interfaces) and Gateway Endpoints (for S3 and DynamoDB)."
        },
        {
            "question": "What is the primary use case for Amazon Aurora's Global Database feature?",
            "answers": [
                {"answer": "To automatically scale database storage capacity across multiple regions."},
                {"answer": "To provide low-latency global reads and disaster recovery by replicating your database across multiple AWS Regions."},
                {"answer": "To encrypt database backups stored in different regions."},
                {"answer": "To enable cross-database queries between Aurora instances in different regions."}
            ],
            "answer": "To provide low-latency global reads and disaster recovery by replicating your database across multiple AWS Regions.",
            "explanation": "Amazon Aurora Global Database is designed for globally distributed applications, allowing a single Aurora database to span multiple AWS Regions. It replicates data with typical latency of less than one second, enabling fast local reads in secondary regions and providing a robust disaster recovery option."
        },
        {
            "question": "If you want to run a piece of code in response to changes in a DynamoDB table (e.g., when a new item is added or an item is updated), which AWS service would you typically use as the trigger target?",
            "answers": [
                {"answer": "Amazon EC2 instance"},
                {"answer": "AWS Lambda function (via DynamoDB Streams)"},
                {"answer": "Amazon SQS queue"},
                {"answer": "AWS Step Functions state machine"}
            ],
            "answer": "AWS Lambda function (via DynamoDB Streams)",
            "explanation": "DynamoDB Streams capture a time-ordered sequence of item-level modifications in a DynamoDB table. These streams can then be configured as an event source for AWS Lambda, allowing you to trigger a Lambda function to process these changes, for example, to replicate data, send notifications, or perform aggregations."
        },
        {
            "question": "Which CloudWatch feature allows you to create customized views of metrics and alarms for your AWS resources, providing a consolidated operational dashboard?",
            "answers": [
                {"answer": "CloudWatch Logs Insights"},
                {"answer": "CloudWatch Alarms"},
                {"answer": "CloudWatch Dashboards"},
                {"answer": "CloudWatch Events (now EventBridge)"}
            ],
            "answer": "CloudWatch Dashboards",
            "explanation": "CloudWatch Dashboards are customizable home pages in the CloudWatch console that you can use to monitor your resources in a single view, even resources that are in different regions. You can create dashboards that display metrics, graphs, and alarms."
        },
        {
            "question": "You're deploying a microservices architecture on Amazon ECS. How can you enable service discovery, allowing services to dynamically find and communicate with each other?",
            "answers": [
                {"answer": "By hardcoding IP addresses in service configurations."},
                {"answer": "Using AWS Cloud Map integrated with Amazon ECS."},
                {"answer": "Manually updating DNS records in Route 53 for each service instance."},
                {"answer": "Relying solely on Elastic Load Balancers for all inter-service communication."}
            ],
            "answer": "Using AWS Cloud Map integrated with Amazon ECS.",
            "explanation": "AWS Cloud Map allows you to register any application resources, such as databases, queues, microservices, and other cloud resources with custom names. Your application can then query for these names via the AWS SDK or DNS. ECS integrates with Cloud Map to make service discovery straightforward for containerized applications."
        },
        {
            "question": "What is the purpose of an 'Invocation Type' when calling an AWS Lambda function (e.g., RequestResponse, Event, DryRun)?",
            "answers": [
                {"answer": "It determines the programming language runtime of the Lambda function."},
                {"answer": "It specifies how the Lambda function should be triggered and how the caller expects a response."},
                {"answer": "It defines the memory allocation for the Lambda function."},
                {"answer": "It controls the IAM permissions granted to the Lambda function."}
            ],
            "answer": "It specifies how the Lambda function should be triggered and how the caller expects a response.",
            "explanation": "'RequestResponse' (default, synchronous) waits for the function to complete and returns the result. 'Event' (asynchronous) invokes the function and returns immediately. 'DryRun' tests permissions without actually invoking the function."
        },
        {
            "question": "Which Amazon S3 feature allows you to automatically transition objects to more cost-effective storage classes (e.g., S3 Standard-IA, S3 Glacier) or delete them after a specified period?",
            "answers": [
                {"answer": "S3 Versioning"},
                {"answer": "S3 Bucket Policies"},
                {"answer": "S3 Lifecycle Policies"},
                {"answer": "S3 Replication Time Control (RTC)"}
            ],
            "answer": "S3 Lifecycle Policies",
            "explanation": "S3 Lifecycle policies enable you to define rules to automate the transition of objects to different storage classes or to expire (delete) objects after a certain time. This helps optimize storage costs and manage object lifecycles."
        },
        {
            "question": "In a serverless application, if a Lambda function needs to perform a long-running task (e.g., video processing that might exceed Lambda's maximum execution time), which service could orchestrate this by breaking it into smaller steps or managing the long-running job?",
            "answers": [
                {"answer": "Amazon API Gateway"},
                {"answer": "AWS Fargate for running the entire long task in a container"},
                {"answer": "AWS Step Functions for workflow orchestration, potentially combined with Fargate or Batch for the long task itself."},
                {"answer": "Amazon SQS to queue the task indefinitely."}
            ],
            "answer": "AWS Step Functions for workflow orchestration, potentially combined with Fargate or Batch for the long task itself.",
            "explanation": "AWS Step Functions can orchestrate workflows that include long-running tasks. For tasks exceeding Lambda's limits, Step Functions can integrate with services like AWS Batch or AWS Fargate (via activity tasks or service integrations) to run the compute-intensive part, while Step Functions manages the overall state and retries."
        },
        {
            "question": "What is the primary benefit of using Amazon Aurora Serverless compared to provisioned Amazon Aurora?",
            "answers": [
                {"answer": "It offers significantly higher write throughput."},
                {"answer": "It automatically starts up, shuts down, and scales capacity up or down based on your application's needs, making it ideal for infrequent, intermittent, or unpredictable workloads."},
                {"answer": "It provides more database engine options (e.g., SQL Server)."},
                {"answer": "It allows for direct SSH access to the underlying database instances."}
            ],
            "answer": "It automatically starts up, shuts down, and scales capacity up or down based on your application's needs, making it ideal for infrequent, intermittent, or unpredictable workloads.",
            "explanation": "Aurora Serverless is an on-demand, auto-scaling configuration for Amazon Aurora. It automatically adjusts database capacity based on application demand, reducing costs for variable workloads as you only pay for the capacity consumed."
        },
        {
            "question": "Which AWS service can you use to create and manage SSL/TLS certificates for your website or application that is fronted by services like Elastic Load Balancing or CloudFront?",
            "answers": [
                {"answer": "AWS IAM"},
                {"answer": "AWS KMS (Key Management Service)"},
                {"answer": "AWS Certificate Manager (ACM)"},
                {"answer": "AWS Secrets Manager"}
            ],
            "answer": "AWS Certificate Manager (ACM)",
            "explanation": "AWS Certificate Manager (ACM) handles the complexity of creating, storing, and renewing public and private SSL/TLS X.509 certificates and keys that protect your AWS websites and applications. You can provision public certificates for free to use with ACM-integrated services."
        }
    ]
},
    {
    "name": "Test Quiz",
    "image": "https://images.unsplash.com/photo-1612838320302-4b3b3b3b3b3b",
    "questions": [
        {
            "question": "What is the capital of France?",
            "answers": [
                {"answer": "Paris"},
                {"answer": "London"},
                {"answer": "Berlin"},
                {"answer": "Madrid"}
            ],
            "answer": "Paris",
            "explanation": "Paris is the capital city of France."
        },
        {
            "question": "What is 2 + 2?",
            "answers": [
                {"answer": "3"},
                {"answer": "4"},
                {"answer": "5"},
                {"answer": "6"}
            ],
            "answer": "4",  
            "explanation": "2 + 2 equals 4."
        },
        {
            "question": "What is the largest planet in our solar system?",
            "answers": [
                {"answer": "Earth"},
                {"answer": "Mars"},
                {"answer": "Jupiter"},
                {"answer": "Saturn"}
            ],
            "answer": "Jupiter",
            "explanation": "Jupiter is the largest planet in our solar system."
        },
        {
            "question": "What is the boiling point of water?",
            "answers": [
                {"answer": "100 degrees Celsius"},
                {"answer": "90 degrees Celsius"},
                {"answer": "80 degrees Celsius"},
                {"answer": "70 degrees Celsius"}
            ],
            "answer": "100 degrees Celsius",
            "explanation": "Water boils at 100 degrees Celsius at sea level."
        }
    ]
},
    {
    "name": "AWS SaaS Deployment & Debugging Expert",
    "image": "https://images.unsplash.com/photo-1612838320302-4b3b3b3b3b3b",
    "questions": [
        {
            "question": "Which CLI command deploys a CloudFormation stack?",
            "answers": [
                {"answer": "aws cloudformation deploy --template-file template.yaml"},
                {"answer": "aws deploy create-stack template.yml"},
                {"answer": "aws s3 cp template.yml stack-deploy"},
                {"answer": "aws ec2 create-stack --template template.yaml"}
            ],
            "answer": "aws cloudformation deploy --template-file template.yaml",
            "explanation": "The correct command uses the CloudFormation service's deploy command with the --template-file parameter. Other options either use incorrect service names (ec2) or invalid command syntax."
        },
        {
            "question": "How to troubleshoot 'Lambda function timed out' error?",
            "answers": [
                {"answer": "Increase timeout value and check for infinite loops"},
                {"answer": "Reduce memory allocation"},
                {"answer": "Enable VPC configuration"},
                {"answer": "Delete and recreate the function"}
            ],
            "answer": "Increase timeout value and check for infinite loops",
            "explanation": "Lambda timeouts occur when execution exceeds configured duration. First increase timeout (up to 15min max), then analyze code for long-running processes or infinite loops using CloudWatch Logs."
        },
        {
            "question": "Which command shows real-time Lambda logs?",
            "answers": [
                {"answer": "aws logs tail /aws/lambda/my-function"},
                {"answer": "aws lambda get-log my-function"},
                {"answer": "aws cloudwatch stream-logs lambda"},
                {"answer": "aws lambda trace --function my-function"}
            ],
            "answer": "aws logs tail /aws/lambda/my-function",
            "explanation": "The 'aws logs tail' command follows log streams in real-time. Other options use incorrect service names or non-existent commands."
        },
        {
            "question": "What's the first step to debug '403 Forbidden' errors from S3?",
            "answers": [
                {"answer": "Check bucket policies and IAM permissions"},
                {"answer": "Enable CORS configuration"},
                {"answer": "Increase bucket storage capacity"},
                {"answer": "Modify network ACLs"}
            ],
            "answer": "Check bucket policies and IAM permissions",
            "explanation": "403 errors typically indicate permission issues. First verify bucket policies (public access) and IAM permissions of the requesting entity before investigating network rules."
        },
        {
            "question": "Which service automatically retries failed database migrations?",
            "answers": [
                {"answer": "AWS DMS (Database Migration Service)"},
                {"answer": "RDS Automated Backups"},
                {"answer": "Lambda with exponential backoff"},
                {"answer": "EC2 Spot Instances"}
            ],
            "answer": "AWS DMS (Database Migration Service)",
            "explanation": "AWS DMS has built-in retry logic for database migrations. While Lambda can implement retries, DMS is purpose-built for database migration tasks with automatic recovery."
        },
        {
            "question": "How to resolve 'Cold Start' issues in Lambda?",
            "answers": [
                {"answer": "Use Provisioned Concurrency"},
                {"answer": "Increase memory allocation"},
                {"answer": "Convert to EC2 instances"},
                {"answer": "Enable X-Ray tracing"}
            ],
            "answer": "Use Provisioned Concurrency",
            "explanation": "Provisioned Concurrency keeps functions initialized and ready to respond. Increasing memory helps but doesn't eliminate cold starts. X-Ray only helps diagnose, not prevent."
        },
        {
            "question": "Which CLI command invokes a Lambda function for testing?",
            "answers": [
                {"answer": "aws lambda invoke --function-name my-function output.txt"},
                {"answer": "aws lambda test my-function payload.json"},
                {"answer": "aws function invoke my-function"},
                {"answer": "aws lambda run --function my-function"}
            ],
            "answer": "aws lambda invoke --function-name my-function output.txt",
            "explanation": "The invoke command requires specifying output file. Other options use incorrect command syntax or non-existent subcommands."
        },
        {
            "question": "What's the best way to manage environment variables across stages?",
            "answers": [
                {"answer": "Use Parameter Store in Systems Manager"},
                {"answer": "Store in GitHub Secrets"},
                {"answer": "Hardcode in deployment scripts"},
                {"answer": "Use S3 bucket configuration"}
            ],
            "answer": "Use Parameter Store in Systems Manager",
            "explanation": "Parameter Store provides secure, versioned storage with IAM access control. GitHub Secrets only work in CI/CD, S3 isn't secure for credentials."
        },
        {
            "question": "How to debug '502 Bad Gateway' in API Gateway?",
            "answers": [
                {"answer": "Check Lambda integration timeout values"},
                {"answer": "Modify Route 53 DNS settings"},
                {"answer": "Increase API Gateway cache size"},
                {"answer": "Enable CloudFront distribution"}
            ],
            "answer": "Check Lambda integration timeout values",
            "explanation": "502 errors often occur when backend services (like Lambda) timeout before responding. API Gateway has 29s max timeout, Lambda can be up to 15min."
        },
        {
            "question": "Which command creates an ECS service?",
            "answers": [
                {"answer": "aws ecs create-service --cluster my-cluster --service-name my-service"},
                {"answer": "aws ecs new service my-service"},
                {"answer": "aws deploy create-ecs-service"},
                {"answer": "aws ec2 create-ecs-service"}
            ],
            "answer": "aws ecs create-service --cluster my-cluster --service-name my-service",
            "explanation": "ECS services are created through the ecs namespace. Other options use incorrect service names or non-existent commands."
        },
        {
            "question": "How to troubleshoot 'No space left on device' in EC2?",
            "answers": [
                {"answer": "Resize EBS volume and modify filesystem"},
                {"answer": "Reboot the instance"},
                {"answer": "Increase instance type"},
                {"answer": "Delete CloudWatch logs"}
            ],
            "answer": "Resize EBS volume and modify filesystem",
            "explanation": "After resizing via AWS console/CLI, must extend filesystem using growpart or similar tools. Rebooting alone doesn't resolve storage issues."
        },
        {
            "question": "Which command lists running containers in ECS?",
            "answers": [
                {"answer": "aws ecs list-container-instances --cluster my-cluster"},
                {"answer": "aws ec2 describe-containers"},
                {"answer": "aws docker ps"},
                {"answer": "aws ecs get-containers"}
            ],
            "answer": "aws ecs list-container-instances --cluster my-cluster",
            "explanation": "ECS manages container instances through its own API. The 'docker ps' command only works on local Docker installations."
        },
        {
            "question": "What's the first step to diagnose high latency in API responses?",
            "answers": [
                {"answer": "Use CloudWatch Metrics and X-Ray tracing"},
                {"answer": "Increase Lambda memory allocation"},
                {"answer": "Add more API Gateway stages"},
                {"answer": "Enable Auto Scaling"}
            ],
            "answer": "Use CloudWatch Metrics and X-Ray tracing",
            "explanation": "X-Ray provides service maps and traces to identify bottlenecks. Scaling should only be done after identifying the root cause."
        },
        {
            "question": "How to rollback a failed CloudFormation deployment?",
            "answers": [
                {"answer": "Use the AWS Console rollback option"},
                {"answer": "Delete the stack and recreate"},
                {"answer": "Modify template and redeploy"},
                {"answer": "aws cloudformation rollback-stack --stack-name my-stack"}
            ],
            "answer": "Use the AWS Console rollback option",
            "explanation": "The console provides one-click rollback for failed deployments. CLI requires more complex stack update operations."
        },
        {
            "question": "Which command troubleshoots network connectivity in VPC?",
            "answers": [
                {"answer": "aws ec2 describe-network-interfaces"},
                {"answer": "aws vpc test-connectivity"},
                {"answer": "aws network diagnose"},
                {"answer": "aws check-vpc-routes"}
            ],
            "answer": "aws ec2 describe-network-interfaces",
            "explanation": "This command shows ENI status and configurations. Other options use non-existent commands."
        },
        {
            "question": "How to debug 'Task failed to start' in ECS?",
            "answers": [
                {"answer": "Check task definition and container logs"},
                {"answer": "Increase CPU allocation"},
                {"answer": "Modify security groups"},
                {"answer": "Rebuild Docker image"}
            ],
            "answer": "Check task definition and container logs",
            "explanation": "Common issues include invalid container definitions, missing permissions, or resource constraints visible in ECS service event logs."
        },
        {
            "question": "Which CLI command gets RDS slow query logs?",
            "answers": [
                {"answer": "aws rds describe-db-log-files"},
                {"answer": "aws logs get rds-slow-queries"},
                {"answer": "aws rds export-logs-to-s3"},
                {"answer": "aws mysql show-slow-logs"}
            ],
            "answer": "aws rds describe-db-log-files",
            "explanation": "First list available logs with describe-db-log-files, then download with download-db-log-file-portion. Other options use incorrect service names."
        },
        {
            "question": "What's the best way to monitor Lambda memory usage?",
            "answers": [
                {"answer": "CloudWatch Lambda Insights"},
                {"answer": "X-Ray segment annotations"},
                {"answer": "S3 access logs"},
                {"answer": "API Gateway metrics"}
            ],
            "answer": "CloudWatch Lambda Insights",
            "explanation": "Lambda Insights provides detailed memory/cpu metrics. X-Ray focuses on tracing rather than resource monitoring."
        },
        {
            "question": "How to resolve 'The specified bucket does not exist' during deployment?",
            "answers": [
                {"answer": "Verify S3 bucket name and region"},
                {"answer": "Increase IAM permissions"},
                {"answer": "Modify bucket ACLs"},
                {"answer": "Enable versioning"}
            ],
            "answer": "Verify S3 bucket name and region",
            "explanation": "Common causes include typos in bucket names or deploying to wrong region. S3 bucket names are global but region-specific in operations."
        },
        {
            "question": "Which command tests API Gateway endpoints?",
            "answers": [
                {"answer": "aws apigateway test-invoke-method"},
                {"answer": "curl -X POST https://api-id.execute-api.region.amazonaws.com/stage"},
                {"answer": "aws lambda invoke api-test"},
                {"answer": "aws api test-endpoint"}
            ],
            "answer": "aws apigateway test-invoke-method",
            "explanation": "The test-invoke-method command validates integration without public exposure. Curl requires deployed stage and proper permissions."
        },
        {
            "question": "How to diagnose high CPU utilization in EC2?",
            "answers": [
                {"answer": "Use CloudWatch Metrics and install the CloudWatch agent"},
                {"answer": "Reboot the instance immediately"},
                {"answer": "Upgrade to a larger instance type"},
                {"answer": "Check S3 access patterns"}
            ],
            "answer": "Use CloudWatch Metrics and install the CloudWatch agent",
            "explanation": "The agent provides detailed system metrics. Rebooting or scaling should only be done after identifying the root process."
        },
        {
            "question": "Which command updates a Lambda function's environment variables?",
            "answers": [
                {"answer": "aws lambda update-function-configuration --environment Variables={KEY=VAL}"},
                {"answer": "aws lambda set-env my-function KEY=VAL"},
                {"answer": "aws update-lambda-env --function my-function KEY=VAL"},
                {"answer": "aws function config update --env KEY=VAL"}
            ],
            "answer": "aws lambda update-function-configuration --environment Variables={KEY=VAL}",
            "explanation": "Environment variables are part of function configuration. Other options use non-existent commands or incorrect syntax."
        },
        {
            "question": "How to troubleshoot 'InvalidSignatureException' in API calls?",
            "answers": [
                {"answer": "Check AWS credentials expiration and region"},
                {"answer": "Increase API Gateway timeout"},
                {"answer": "Modify VPC security groups"},
                {"answer": "Enable CloudTrail logging"}
            ],
            "answer": "Check AWS credentials expiration and region",
            "explanation": "Invalid signatures usually indicate clock skew, expired credentials, or region mismatch. Always verify credentials with 'aws sts get-caller-identity'."
        },
        {
            "question": "Which command exports DynamoDB table to S3?",
            "answers": [
                {"answer": "aws dynamodb export-table-to-point-in-time"},
                {"answer": "aws s3 sync dynamodb://table s3://bucket"},
                {"answer": "aws backup export-dynamodb-table"},
                {"answer": "aws data-pipeline create-from-dynamodb"}
            ],
            "answer": "aws dynamodb export-table-to-point-in-time",
            "explanation": "This native command performs point-in-time exports. Data Pipeline requires more complex setup for similar functionality."
        },
        {
            "question": "How to debug 'Execution failed due to configuration error' in Lambda?",
            "answers": [
                {"answer": "Check function role permissions and resource policies"},
                {"answer": "Increase function timeout"},
                {"answer": "Redeploy function code"},
                {"answer": "Enable VPC flow logs"}
            ],
            "answer": "Check function role permissions and resource policies",
            "explanation": "Configuration errors often relate to IAM permissions or resource policies (like S3 bucket permissions). Check CloudTrail for access denied errors."
        },
        {
            "question": "Which command lists all running EC2 instances?",
            "answers": [
                {"answer": "aws ec2 describe-instances --filters Name=instance-state-name,Values=running"},
                {"answer": "aws list ec2-instances"},
                {"answer": "aws ec2 get-running-instances"},
                {"answer": "aws compute list-instances"}
            ],
            "answer": "aws ec2 describe-instances --filters Name=instance-state-name,Values=running",
            "explanation": "The describe-instances command with filters is the correct approach. Other options use non-existent commands."
        },
        {
            "question": "How to resolve 'TooManyRequestsException' in AWS API calls?",
            "answers": [
                {"answer": "Implement exponential backoff in client code"},
                {"answer": "Increase IAM role permissions"},
                {"answer": "Upgrade AWS support plan"},
                {"answer": "Modify CloudWatch alarm thresholds"}
            ],
            "answer": "Implement exponential backoff in client code",
            "explanation": "AWS services throttle API requests. Exponential backoff with jitter is the recommended retry strategy."
        },
        {
            "question": "Which command checks CloudFormation stack drift?",
            "answers": [
                {"answer": "aws cloudformation detect-stack-drift"},
                {"answer": "aws cfn check-drift --stack my-stack"},
                {"answer": "aws cloudformation verify-stack"},
                {"answer": "aws drift detection start"}
            ],
            "answer": "aws cloudformation detect-stack-drift",
            "explanation": "Detect-stack-drift initiates drift detection. Results are checked with describe-stack-drift-detection-status."
        },
        {
            "question": "How to troubleshoot 'Unable to import module' in Lambda?",
            "answers": [
                {"answer": "Verify deployment package includes dependencies"},
                {"answer": "Increase function memory"},
                {"answer": "Modify runtime version"},
                {"answer": "Enable VPC configuration"}
            ],
            "answer": "Verify deployment package includes dependencies",
            "explanation": "This error indicates missing Python/Node.js modules. Always test deployment packages with 'lambda-local' or SAM CLI before deployment."
        },
        {
            "question": "Which command enables S3 bucket versioning?",
            "answers": [
                {"answer": "aws s3api put-bucket-versioning --bucket my-bucket --versioning-configuration Status=Enabled"},
                {"answer": "aws s3 versioning enable my-bucket"},
                {"answer": "aws s3 modify-bucket --versioning true"},
                {"answer": "aws bucket-version enable s3://my-bucket"}
            ],
            "answer": "aws s3api put-bucket-versioning --bucket my-bucket --versioning-configuration Status=Enabled",
            "explanation": "Versioning is managed through s3api subcommands. Other options use incorrect command syntax."
        },
        {
            "question": "How to debug 'TaskMemoryExhausted' in ECS?",
            "answers": [
                {"answer": "Increase task memory limits and check for memory leaks"},
                {"answer": "Add more CPU units"},
                {"answer": "Modify network mode"},
                {"answer": "Enable Fargate Spot"}
            ],
            "answer": "Increase task memory limits and check for memory leaks",
            "explanation": "Memory limits are set in task definitions. Use CloudWatch Container Insights to monitor memory usage patterns."
        },
        {
            "question": "Which command sets up CI/CD pipeline for Elastic Beanstalk?",
            "answers": [
                {"answer": "eb pipeline create"},
                {"answer": "aws codepipeline create-beanstalk"},
                {"answer": "aws deploy create-application"},
                {"answer": "eb init --pipeline"}
            ],
            "answer": "eb pipeline create",
            "explanation": "The Elastic Beanstalk CLI (eb) has pipeline-specific commands. Other options mix services incorrectly."
        },
        {
            "question": "How to resolve 'The security group ID does not exist' error?",
            "answers": [
                {"answer": "Verify security group exists in current region"},
                {"answer": "Create new IAM role"},
                {"answer": "Modify network ACLs"},
                {"answer": "Enable VPC flow logs"}
            ],
            "answer": "Verify security group exists in current region",
            "explanation": "Security groups are region-specific. Cross-region references require separate SG creation in target region."
        },
        {
            "question": "Which command rotates RDS database credentials?",
            "answers": [
                {"answer": "aws rds modify-db-instance --master-user-password new-password"},
                {"answer": "aws secretsmanager rotate-secret --secret-id db-creds"},
                {"answer": "aws iam update-login-profile"},
                {"answer": "aws rotate-credentials rds"}
            ],
            "answer": "aws rds modify-db-instance --master-user-password new-password",
            "explanation": "For RDS-managed credentials, use modify-db-instance. Secrets Manager is better for external credential management."
        },
        {
            "question": "How to troubleshoot 'Host key verification failed' in CodeDeploy?",
            "answers": [
                {"answer": "Verify SSH key in deployment group configuration"},
                {"answer": "Increase deployment timeout"},
                {"answer": "Modify Auto Scaling group"},
                {"answer": "Enable CloudWatch agent"}
            ],
            "answer": "Verify SSH key in deployment group configuration",
            "explanation": "This error indicates SSH key mismatch between CodeDeploy and target instances. Regenerate or verify key pairs."
        },
        {
            "question": "Which command checks EBS volume encryption status?",
            "answers": [
                {"answer": "aws ec2 describe-volumes --volume-ids vol-12345"},
                {"answer": "aws ebs check-encryption vol-12345"},
                {"answer": "aws encrypt status --volume vol-12345"},
                {"answer": "aws volume info vol-12345"}
            ],
            "answer": "aws ec2 describe-volumes --volume-ids vol-12345",
            "explanation": "Encryption status appears in volume details. Other options use non-existent commands."
        },
        {
            "question": "How to debug 'Execution role is not authorized to call CreateNetworkInterface'",
            "answers": [
                {"answer": "Add AWSLambdaVPCAccessExecutionRole policy to role"},
                {"answer": "Increase Lambda memory"},
                {"answer": "Modify VPC route tables"},
                {"answer": "Enable public IP assignment"}
            ],
            "answer": "Add AWSLambdaVPCAccessExecutionRole policy to role",
            "explanation": "Lambda functions in VPC require specific permissions to manage ENIs. This managed policy provides necessary permissions."
        },
        {
            "question": "Which command tests S3 bucket access permissions?",
            "answers": [
                {"answer": "aws s3 ls s3://bucket-name"},
                {"answer": "aws s3 test-access bucket-name"},
                {"answer": "aws check-s3-permissions bucket-name"},
                {"answer": "aws s3 verify bucket-name"}
            ],
            "answer": "aws s3 ls s3://bucket-name",
            "explanation": "Listing objects is the simplest access test. Requires s3:ListBucket permission. Other commands don't exist."
        },
        {
            "question": "How to resolve 'DockerTimeoutError' in ECS deployments?",
            "answers": [
                {"answer": "Increase ECS task execution timeout"},
                {"answer": "Reduce container image size"},
                {"answer": "Modify security groups"},
                {"answer": "Enable Fargate capacity provider"}
            ],
            "answer": "Increase ECS task execution timeout",
            "explanation": "Large images or slow networks may require longer pull times. Adjust ECS service's deployment configuration timeouts."
        },
        {
            "question": "Which command lists CloudFront distributions?",
            "answers": [
                {"answer": "aws cloudfront list-distributions"},
                {"answer": "aws cf list"},
                {"answer": "aws distributions list"},
                {"answer": "aws list-cloudfront"}
            ],
            "answer": "aws cloudfront list-distributions",
            "explanation": "CloudFront operations use the cloudfront namespace. Other options use incorrect service abbreviations."
        },
        {
            "question": "How to troubleshoot 'NoSuchBucket' in CloudFormation?",
            "answers": [
                {"answer": "Verify S3 bucket exists in template's region"},
                {"answer": "Increase template timeout"},
                {"answer": "Modify IAM roles"},
                {"answer": "Enable bucket versioning"}
            ],
            "answer": "Verify S3 bucket exists in template's region",
            "explanation": "CloudFormation templates must reference existing buckets in the same region. Cross-region access requires special permissions."
        },
        {
            "question": "Which command forces CloudFront cache invalidation?",
            "answers": [
                {"answer": "aws cloudfront create-invalidation --distribution-id ID --paths '/*'"},
                {"answer": "aws cf invalidate-cache ID"},
                {"answer": "aws s3 sync --cf-invalidate"},
                {"answer": "aws invalidate-cloudfront ID"}
            ],
            "answer": "aws cloudfront create-invalidation --distribution-id ID --paths '/*'",
            "explanation": "Proper cache invalidation requires creating a new invalidation request. Other options use incorrect command syntax."
        },
        {
            "question": "How to debug 'Unable to assume role' errors?",
            "answers": [
                {"answer": "Verify trust relationship in IAM role"},
                {"answer": "Increase role session duration"},
                {"answer": "Modify security groups"},
                {"answer": "Enable CloudTrail logging"}
            ],
            "answer": "Verify trust relationship in IAM role",
            "explanation": "The assuming entity (user/role) must be in the trust policy. Use 'aws sts assume-role' to test role assumptions."
        },
        {
            "question": "Which command checks Route 53 DNS propagation?",
            "answers": [
                {"answer": "dig +trace example.com"},
                {"answer": "aws route53 get-dns-propagation"},
                {"answer": "nslookup -type=soa example.com"},
                {"answer": "aws dns verify example.com"}
            ],
            "answer": "dig +trace example.com",
            "explanation": "The dig command provides detailed DNS resolution tracing. AWS CLI doesn't have DNS propagation checking commands."
        },
        {
            "question": "How to troubleshoot 'AccessDenied' when uploading to S3?",
            "answers": [
                {"answer": "Check bucket policy and IAM permissions"},
                {"answer": "Enable transfer acceleration"},
                {"answer": "Modify CORS configuration"},
                {"answer": "Increase bucket storage class"}
            ],
            "answer": "Check bucket policy and IAM permissions",
            "explanation": "AccessDenied errors indicate permission issues. Verify s3:PutObject permissions in both bucket policies and IAM roles."
        },
        {
            "question": "Which command updates an existing Lambda function code?",
            "answers": [
                {"answer": "aws lambda update-function-code --function-name my-function --zip-file fileb://deploy.zip"},
                {"answer": "aws lambda deploy --function my-function --code deploy.zip"},
                {"answer": "aws function update-code my-function deploy.zip"},
                {"answer": "aws update-lambda --code-file deploy.zip"}
            ],
            "answer": "aws lambda update-function-code --function-name my-function --zip-file fileb://deploy.zip",
            "explanation": "The update-function-code subcommand is used for code updates. Other options use incorrect syntax."
        },
        {
            "question": "How to debug 'ELB-HealthChecker' failures in EC2?",
            "answers": [
                {"answer": "Verify security groups allow health check ports"},
                {"answer": "Increase instance size"},
                {"answer": "Modify Auto Scaling group"},
                {"answer": "Enable detailed monitoring"}
            ],
            "answer": "Verify security groups allow health check ports",
            "explanation": "Health checks fail when security groups block access to the instance's health check port (default: 80/tcp)."
        },
        {
            "question": "Which command creates an ECR repository?",
            "answers": [
                {"answer": "aws ecr create-repository --repository-name my-repo"},
                {"answer": "aws docker create-repo my-repo"},
                {"answer": "aws ecs new-repository my-repo"},
                {"answer": "aws container-registry create my-repo"}
            ],
            "answer": "aws ecr create-repository --repository-name my-repo",
            "explanation": "ECR repositories are managed through the ecr namespace. Other options use incorrect service names."
        },
        {
            "question": "How to resolve 'InvalidParameterException' in CloudFormation?",
            "answers": [
                {"answer": "Validate template with cfn-lint"},
                {"answer": "Increase stack timeout"},
                {"answer": "Modify IAM roles"},
                {"answer": "Enable stack termination protection"}
            ],
            "answer": "Validate template with cfn-lint",
            "explanation": "This error indicates template syntax issues. Use AWS CLI validate-template command or cfn-lint for detailed validation."
        },
        {
            "question": "Which command lists all available AWS regions?",
            "answers": [
                {"answer": "aws ec2 describe-regions"},
                {"answer": "aws list-regions"},
                {"answer": "aws configure get-regions"},
                {"answer": "aws global describe-regions"}
            ],
            "answer": "aws ec2 describe-regions",
            "explanation": "Region information is managed through EC2 service. Other options use non-existent commands."
        },
        {
            "question": "How to troubleshoot 'Connection timed out' to RDS?",
            "answers": [
                {"answer": "Check security groups and NACLs"},
                {"answer": "Increase DB instance class"},
                {"answer": "Modify parameter groups"},
                {"answer": "Enable Multi-AZ deployment"}
            ],
            "answer": "Check security groups and NACLs",
            "explanation": "Timeout errors typically indicate network connectivity issues. Verify security groups allow traffic on correct port (default: 3306 for MySQL)."
        },
        {
            "question": "Which command enables S3 static website hosting?",
            "answers": [
                {"answer": "aws s3 website s3://my-bucket --index-document index.html"},
                {"answer": "aws s3api put-bucket-website --bucket my-bucket --website-configuration file://config.json"},
                {"answer": "aws s3 enable-static-hosting my-bucket"},
                {"answer": "aws website create --bucket my-bucket"}
            ],
            "answer": "aws s3api put-bucket-website --bucket my-bucket --website-configuration file://config.json",
            "explanation": "Website configuration requires JSON configuration. The s3api command is most precise, though other methods exist via Console."
        },
        {
            "question": "How to debug 'Read timed out' in AWS CLI?",
            "answers": [
                {"answer": "Increase timeout with --cli-read-timeout parameter"},
                {"answer": "Upgrade AWS CLI version"},
                {"answer": "Modify IAM permissions"},
                {"answer": "Enable debug logging"}
            ],
            "answer": "Increase timeout with --cli-read-timeout parameter",
            "explanation": "For long-running operations, increase timeout values. Debug logging (--debug) helps diagnose but doesn't fix timeout issues."
        },
        {
            "question": "Which command checks CloudTrail log integrity?",
            "answers": [
                {"answer": "aws cloudtrail validate-logs --trail-name my-trail"},
                {"answer": "Use the validate-logfile-integrity.sh script"},
                {"answer": "aws logs verify my-trail-logs"},
                {"answer": "CloudTrail validation is automatic"}
            ],
            "answer": "Use the validate-logfile-integrity.sh script",
            "explanation": "AWS provides a validation script using OpenSSL to verify CloudTrail log file integrity via digest files."
        },
        {
            "question": "How to resolve 'ThrottlingException' in DynamoDB?",
            "answers": [
                {"answer": "Implement exponential backoff in application code"},
                {"answer": "Increase provisioned capacity"},
                {"answer": "Modify partition keys"},
                {"answer": "Enable auto scaling"}
            ],
            "answer": "Implement exponential backoff in application code",
            "explanation": "Immediate fix is adding retries. Long-term solution may require adjusting capacity or improving data distribution."
        },
        {
            "question": "Which command monitors EC2 instance status checks?",
            "answers": [
                {"answer": "aws ec2 describe-instance-status"},
                {"answer": "aws cloudwatch get-instance-health"},
                {"answer": "aws health instance-checks"},
                {"answer": "aws monitor ec2-status"}
            ],
            "answer": "aws ec2 describe-instance-status",
            "explanation": "This command shows system/reachability status. CloudWatch alarms can be set up for automated monitoring."
        },
        {
            "question": "How to troubleshoot 'InvalidClientTokenId' in CLI?",
            "answers": [
                {"answer": "Verify AWS_ACCESS_KEY_ID and AWS_SECRET_ACCESS_KEY"},
                {"answer": "Increase IAM permissions"},
                {"answer": "Modify region configuration"},
                {"answer": "Enable MFA"}
            ],
            "answer": "Verify AWS_ACCESS_KEY_ID and AWS_SECRET_ACCESS_KEY",
            "explanation": "This error indicates invalid or expired access keys. Always rotate credentials regularly and use temporary credentials when possible."
        }
    ]
},
    {
        "name": "Genetic Testing Developer Quiz",
        "questions": [
            {
                "question": "What is a SNP?",
                "answers": [
                    {"answer": "A protein-coding gene"},
                    {"answer": "A single nucleotide polymorphism"},
                    {"answer": "A chromosomal deletion"},
                    {"answer": "A type of RNA molecule"}
                ],
                "answer": "A single nucleotide polymorphism",
                "explanation": "SNPs are single-base variations used in ancestry and disease risk analysis. Developers handle SNP data in VCF files."
            },
            {
                "question": "What does 'CLIA-certified lab' mean?",
                "answers": [
                    {"answer": "A lab compliant with Clinical Laboratory Improvement Amendments"},
                    {"answer": "A cancer research lab"},
                    {"answer": "A lab using CRISPR"},
                    {"answer": "A veterinary genetics lab"}
                ],
                "answer": "A lab compliant with Clinical Laboratory Improvement Amendments",
                "explanation": "CLIA ensures testing accuracy. Platforms must integrate with CLIA labs for valid clinical reports."
            },
            {
                "question": "Which file format stores raw genetic variant data?",
                "answers": [
                    {"answer": "VCF"},
                    {"answer": "CSV"},
                    {"answer": "JSON"},
                    {"answer": "BAM"}
                ],
                "answer": "VCF",
                "explanation": "VCF (Variant Call Format) is standard for SNPs/indels. Developers parse VCF files for test results."
            },
            {
                "question": "What is a 'variant of uncertain significance' (VUS)?",
                "answers": [
                    {"answer": "A mutation with unclear clinical impact"},
                    {"answer": "A harmless mutation"},
                    {"answer": "A cancer-causing mutation"},
                    {"answer": "An RNA-specific mutation"}
                ],
                "answer": "A mutation with unclear clinical impact",
                "explanation": "VUS results require careful UI flagging and follow-up recommendations."
            },
            {
                "question": "What does ACMG classify?",
                "answers": [
                    {"answer": "Pathogenicity of genetic variants"},
                    {"answer": "Ethical guidelines"},
                    {"answer": "Lab equipment standards"},
                    {"answer": "Data encryption protocols"}
                ],
                "answer": "Pathogenicity of genetic variants",
                "explanation": "ACMG guidelines (e.g., benign/likely pathogenic) are automated in reporting pipelines."
            },
            {
                "question": "What is NGS?",
                "answers": [
                    {"answer": "Next-Generation Sequencing"},
                    {"answer": "National Genetic Standard"},
                    {"answer": "Non-Genetic Screening"},
                    {"answer": "New Genome Sequencing"}
                ],
                "answer": "Next-Generation Sequencing",
                "explanation": "NGS enables high-throughput sequencing. Developers optimize pipelines for FASTQ/BAM files."
            },
            {
                "question": "What is the purpose of a BAM file?",
                "answers": [
                    {"answer": "Storing aligned sequencing reads"},
                    {"answer": "Storing patient demographics"},
                    {"answer": "Encrypting genetic data"},
                    {"answer": "Visualizing chromosomes"}
                ],
                "answer": "Storing aligned sequencing reads",
                "explanation": "BAM files require tools like SAMtools for processing."
            },
            {
                "question": "Which API standard is used for healthcare data exchange?",
                "answers": [
                    {"answer": "FHIR"},
                    {"answer": "GraphQL"},
                    {"answer": "SOAP"},
                    {"answer": "REST"}
                ],
                "answer": "FHIR",
                "explanation": "FHIR integrates genetic data into EHRs (e.g., Epic, Cerner)."
            },
            {
                "question": "What is 'sensitivity' in genetic testing?",
                "answers": [
                    {"answer": "Ability to detect true positives"},
                    {"answer": "Avoiding false positives"},
                    {"answer": "Data processing speed"},
                    {"answer": "Cost per test"}
                ],
                "answer": "Ability to detect true positives",
                "explanation": "High sensitivity reduces false negatives. Report these metrics in labs."
            },
            {
                "question": "What does 'phasing' mean in genomics?",
                "answers": [
                    {"answer": "Determining parental origin of alleles"},
                    {"answer": "Filtering low-quality variants"},
                    {"answer": "Encrypting patient data"},
                    {"answer": "Gene expression analysis"}
                ],
                "answer": "Determining parental origin of alleles",
                "explanation": "Phased data improves ancestry and inheritance reports."
            },
            {
                "question": "What is a 'PGx report'?",
                "answers": [
                    {"answer": "Pharmacogenomic drug response report"},
                    {"answer": "Ancestry composition report"},
                    {"answer": "Cancer risk report"},
                    {"answer": "Carrier screening report"}
                ],
                "answer": "Pharmacogenomic drug response report",
                "explanation": "PGx reports guide medication dosing for clinicians."
            },
            {
                "question": "Which encryption is required for genetic data?",
                "answers": [
                    {"answer": "AES-256"},
                    {"answer": "SHA-1"},
                    {"answer": "MD5"},
                    {"answer": "No encryption"}
                ],
                "answer": "AES-256",
                "explanation": "Genetic data requires AES-256 encryption at rest/transit."
            },
            {
                "question": "What does GINA regulate?",
                "answers": [
                    {"answer": "Genetic discrimination"},
                    {"answer": "Lab accuracy"},
                    {"answer": "Data formats"},
                    {"answer": "Drug approvals"}
                ],
                "answer": "Genetic discrimination",
                "explanation": "GINA prohibits misuse of genetic data in employment/insurance."
            },
            {
                "question": "What is 'informed consent' in genetic testing?",
                "answers": [
                    {"answer": "Patient permission after understanding risks"},
                    {"answer": "Lab billing agreement"},
                    {"answer": "Data analysis protocol"},
                    {"answer": "Software license"}
                ],
                "answer": "Patient permission after understanding risks",
                "explanation": "Platforms must document digital consent and allow withdrawals."
            },
            {
                "question": "What is a 'haplotype'?",
                "answers": [
                    {"answer": "A set of DNA variants inherited together"},
                    {"answer": "A type of RNA"},
                    {"answer": "A protein structure"},
                    {"answer": "A lab instrument"}
                ],
                "answer": "A set of DNA variants inherited together",
                "explanation": "Haplotypes are used in ancestry and disease linkage analysis."
            },
            {
                "question": "What is a FASTQ file?",
                "answers": [
                    {"answer": "Raw sequencing reads with quality scores"},
                    {"answer": "Aligned sequencing data"},
                    {"answer": "Variant call data"},
                    {"answer": "Encrypted patient data"}
                ],
                "answer": "Raw sequencing reads with quality scores",
                "explanation": "FASTQ files are processed in NGS pipelines before alignment."
            },
            {
                "question": "What does 'read depth' indicate?",
                "answers": [
                    {"answer": "Number of times a base is sequenced"},
                    {"answer": "Length of DNA fragments"},
                    {"answer": "Data storage size"},
                    {"answer": "Error rate in sequencing"}
                ],
                "answer": "Number of times a base is sequenced",
                "explanation": "Higher read depth improves variant detection accuracy."
            },
            {
                "question": "What is 'variant annotation'?",
                "answers": [
                    {"answer": "Adding clinical/database info to variants"},
                    {"answer": "Encrypting genetic data"},
                    {"answer": "Visualizing chromosomes"},
                    {"answer": "Filtering low-quality SNPs"}
                ],
                "answer": "Adding clinical/database info to variants",
                "explanation": "Tools like ANNOVAR automate annotation for reports."
            },
            {
                "question": "What is a 'BED file' used for?",
                "answers": [
                    {"answer": "Defining genomic regions of interest"},
                    {"answer": "Storing patient demographics"},
                    {"answer": "Encrypting data"},
                    {"answer": "Aligning sequences"}
                ],
                "answer": "Defining genomic regions of interest",
                "explanation": "BED files target exomes or specific genes in sequencing."
            },
            {
                "question": "What is 'allele frequency' in a population?",
                "answers": [
                    {"answer": "How common an allele is in a population"},
                    {"answer": "Speed of mutation occurrence"},
                    {"answer": "Data transmission rate"},
                    {"answer": "Error rate in sequencing"}
                ],
                "answer": "How common an allele is in a population",
                "explanation": "Rare alleles may indicate pathogenic variants."
            },
            {
                "question": "What does 'QC' stand for in NGS?",
                "answers": [
                    {"answer": "Quality Control"},
                    {"answer": "Quantitative Comparison"},
                    {"answer": "Quick Clone"},
                    {"answer": "Query Command"}
                ],
                "answer": "Quality Control",
                "explanation": "QC steps ensure sequencing data meets accuracy thresholds."
            },
            {
                "question": "What is 'CRISPR' used for?",
                "answers": [
                    {"answer": "Gene editing"},
                    {"answer": "Data encryption"},
                    {"answer": "Variant annotation"},
                    {"answer": "Lab certification"}
                ],
                "answer": "Gene editing",
                "explanation": "CRISPR enables precise DNA modifications. Not directly used in testing platforms."
            },
            {
                "question": "What is a 'pipeline' in bioinformatics?",
                "answers": [
                    {"answer": "A sequence of data processing steps"},
                    {"answer": "A physical lab instrument"},
                    {"answer": "A type of DNA"},
                    {"answer": "A compliance standard"}
                ],
                "answer": "A sequence of data processing steps",
                "explanation": "Pipelines process raw data (FASTQ) into reports (VCF/PDF)."
            },
            {
                "question": "What is 'plink' used for?",
                "answers": [
                    {"answer": "Genome-wide association studies (GWAS)"},
                    {"answer": "Encrypting data"},
                    {"answer": "Variant annotation"},
                    {"answer": "Lab billing"}
                ],
                "answer": "Genome-wide association studies (GWAS)",
                "explanation": "Plink analyzes genetic associations with traits/diseases."
            },
            {
                "question": "What is 'reference genome GRCh38'?",
                "answers": [
                    {"answer": "A standardized human genome assembly"},
                    {"answer": "A type of RNA"},
                    {"answer": "A lab protocol"},
                    {"answer": "A data encryption method"}
                ],
                "answer": "A standardized human genome assembly",
                "explanation": "Sequencing reads are aligned to GRCh38 for consistency."
            },
            {
                "question": "What is 'Exome Sequencing'?",
                "answers": [
                    {"answer": "Sequencing protein-coding regions"},
                    {"answer": "Sequencing the entire genome"},
                    {"answer": "Sequencing mitochondrial DNA"},
                    {"answer": "Sequencing RNA"}
                ],
                "answer": "Sequencing protein-coding regions",
                "explanation": "Exome sequencing is cost-effective for clinical testing."
            },
            {
                "question": "What is 'Sanger Sequencing'?",
                "answers": [
                    {"answer": "A method for validating NGS variants"},
                    {"answer": "A high-throughput sequencing technology"},
                    {"answer": "A data storage format"},
                    {"answer": "A lab certification"}
                ],
                "answer": "A method for validating NGS variants",
                "explanation": "Sanger confirms critical variants due to its high accuracy."
            },
            {
                "question": "What is 'coverage' in sequencing?",
                "answers": [
                    {"answer": "The average number of reads covering a base"},
                    {"answer": "Data encryption breadth"},
                    {"answer": "Lab insurance policy"},
                    {"answer": "Patient consent form"}
                ],
                "answer": "The average number of reads covering a base",
                "explanation": "30x coverage is standard for clinical whole-genome sequencing."
            },
            {
                "question": "What is 'CNV'?",
                "answers": [
                    {"answer": "Copy Number Variation"},
                    {"answer": "Common Nucleotide Variant"},
                    {"answer": "Clinical NGS Validation"},
                    {"answer": "Consented Non-Variant"}
                ],
                "answer": "Copy Number Variation",
                "explanation": "CNVs are large deletions/duplications detected in cancer tests."
            },
            {
                "question": "What is 'LOINC' used for?",
                "answers": [
                    {"answer": "Standardizing lab test codes"},
                    {"answer": "Encrypting data"},
                    {"answer": "Annotating variants"},
                    {"answer": "Storing sequencing reads"}
                ],
                "answer": "Standardizing lab test codes",
                "explanation": "LOINC codes integrate genetic tests into EHR systems."
            },
            {
                "question": "What should a genetic risk report include?",
                "answers": [
                    {"answer": "Risk score, confidence intervals, and recommendations"},
                    {"answer": "Raw SNP data only"},
                    {"answer": "Lab equipment details"},
                    {"answer": "Patient’s social media history"}
                ],
                "answer": "Risk score, confidence intervals, and recommendations",
                "explanation": "Use visualizations (e.g., risk meters) for patient comprehension."
            },
            {
                "question": "What is a 'dynamic report'?",
                "answers": [
                    {"answer": "A report updating with new scientific data"},
                    {"answer": "A printed PDF"},
                    {"answer": "A lab billing invoice"},
                    {"answer": "A consent form"}
                ],
                "answer": "A report updating with new scientific data",
                "explanation": "Dynamic reports improve value as research evolves."
            },
            {
                "question": "What is 'secondary findings' in genetic testing?",
                "answers": [
                    {"answer": "Unexpected medically actionable results"},
                    {"answer": "Lab billing errors"},
                    {"answer": "Data encryption keys"},
                    {"answer": "Consent form typos"}
                ],
                "answer": "Unexpected medically actionable results",
                "explanation": "Platforms must let users opt-in/out of secondary findings."
            },
            {
                "question": "Which chart is best for displaying ancestry composition?",
                "answers": [
                    {"answer": "Pie chart"},
                    {"answer": "Bar graph"},
                    {"answer": "Scatter plot"},
                    {"answer": "Heatmap"}
                ],
                "answer": "Pie chart",
                "explanation": "Pie charts simplify regional ancestry percentages."
            },
            {
                "question": "What is a 'PDF report watermark' used for?",
                "answers": [
                    {"answer": "Preventing unauthorized sharing"},
                    {"answer": "Adding lab logos"},
                    {"answer": "Encrypting data"},
                    {"answer": "Annotating variants"}
                ],
                "answer": "Preventing unauthorized sharing",
                "explanation": "Watermarks track leaked reports but don’t replace encryption."
            },
            {
                "question": "What is 'BRCA1'?",
                "answers": [
                    {"answer": "A gene linked to breast cancer risk"},
                    {"answer": "A lab instrument"},
                    {"answer": "A data format"},
                    {"answer": "A compliance law"}
                ],
                "answer": "A gene linked to breast cancer risk",
                "explanation": "BRCA1 mutations are reported in hereditary cancer tests."
            },
            {
                "question": "What does 'carrier screening' test for?",
                "answers": [
                    {"answer": "Recessive disease risk in offspring"},
                    {"answer": "Cancer risk"},
                    {"answer": "Drug responses"},
                    {"answer": "Ancestry"}
                ],
                "answer": "Recessive disease risk in offspring",
                "explanation": "Carrier reports guide family planning decisions."
            },
            {
                "question": "What is a 'FHIR Genomics Resource'?",
                "answers": [
                    {"answer": "A standardized way to share genetic data"},
                    {"answer": "A lab tool"},
                    {"answer": "A sequencing method"},
                    {"answer": "A consent form"}
                ],
                "answer": "A standardized way to share genetic data",
                "explanation": "FHIR Genomics integrates data into EHRs for clinicians."
            },
            {
                "question": "What is 'PGx' short for?",
                "answers": [
                    {"answer": "Pharmacogenomics"},
                    {"answer": "Pathogenomics"},
                    {"answer": "Polygenic risk"},
                    {"answer": "Population genetics"}
                ],
                "answer": "Pharmacogenomics",
                "explanation": "PGx reports predict drug metabolism (e.g., warfarin dosing)."
            },
            {
                "question": "What is 'de-identified data'?",
                "answers": [
                    {"answer": "Data stripped of personal identifiers"},
                    {"answer": "Encrypted data"},
                    {"answer": "Raw sequencing data"},
                    {"answer": "Annotated variants"}
                ],
                "answer": "Data stripped of personal identifiers",
                "explanation": "De-identification reduces re-identification risks under HIPAA."
            },
            {
                "question": "What is 'GDPR'?",
                "answers": [
                    {"answer": "EU data privacy regulation"},
                    {"answer": "A lab certification"},
                    {"answer": "A gene database"},
                    {"answer": "A sequencing technology"}
                ],
                "answer": "EU data privacy regulation",
                "explanation": "GDPR requires explicit consent for EU user data processing."
            },
            {
                "question": "What is a 'Data Use Agreement' (DUA)?",
                "answers": [
                    {"answer": "A contract governing data sharing"},
                    {"answer": "A lab report"},
                    {"answer": "A consent form"},
                    {"answer": "A variant classification"}
                ],
                "answer": "A contract governing data sharing",
                "explanation": "DUAs ensure partners use data only for agreed purposes."
            },
            {
                "question": "What is 'ISO 27001'?",
                "answers": [
                    {"answer": "Information security management standard"},
                    {"answer": "Lab equipment standard"},
                    {"answer": "Genetic testing protocol"},
                    {"answer": "Variant annotation tool"}
                ],
                "answer": "Information security management standard",
                "explanation": "ISO 27001 certification strengthens trust in data security."
            },
            {
                "question": "What is 'incidental findings'?",
                "answers": [
                    {"answer": "Unexpected but actionable results"},
                    {"answer": "Lab billing errors"},
                    {"answer": "Data encryption failures"},
                    {"answer": "Consent form oversights"}
                ],
                "answer": "Unexpected but actionable results",
                "explanation": "Platforms must let users opt-in/out of receiving these."
            },
            {
                "question": "What is 'audit logging'?",
                "answers": [
                    {"answer": "Tracking data access/modifications"},
                    {"answer": "Sequencing quality control"},
                    {"answer": "Variant annotation"},
                    {"answer": "Report generation"}
                ],
                "answer": "Tracking data access/modifications",
                "explanation": "Audit logs are critical for HIPAA compliance and breach investigations."
            },
            {
                "question": "What is 'data minimization'?",
                "answers": [
                    {"answer": "Collecting only necessary data"},
                    {"answer": "Encrypting all data"},
                    {"answer": "Deleting old reports"},
                    {"answer": "Anonymizing data"}
                ],
                "answer": "Collecting only necessary data",
                "explanation": "Reduces liability and storage costs under GDPR/HIPAA."
            },
            {
                "question": "What is 'break-the-glass' access?",
                "answers": [
                    {"answer": "Emergency access to restricted data"},
                    {"answer": "Data decryption"},
                    {"answer": "Lab equipment override"},
                    {"answer": "Consent form bypass"}
                ],
                "answer": "Emergency access to restricted data",
                "explanation": "Requires justification and triggers audit alerts."
            },
            {
                "question": "What is 'tokenization'?",
                "answers": [
                    {"answer": "Replacing sensitive data with tokens"},
                    {"answer": "Data encryption"},
                    {"answer": "Variant annotation"},
                    {"answer": "Data deletion"}
                ],
                "answer": "Replacing sensitive data with tokens",
                "explanation": "Tokenization protects data during analysis/sharing."
            }
        ]
    },
    {
        "name": "Genetic Testing Basics Quiz",
        "questions": [
            {
                "question": "What is genetic testing?",
                "answers": [
                    {"answer": "Analyzing DNA to identify changes or mutations"},
                    {"answer": "Testing blood sugar levels"},
                    {"answer": "Measuring vitamin deficiencies"},
                    {"answer": "Studying bacteria in the gut"}
                ],
                "answer": "Analyzing DNA to identify changes or mutations",
                "explanation": "Genetic testing examines DNA to detect mutations linked to health, ancestry, or traits."
            },
            {
                "question": "Which sample is commonly used for at-home DNA tests?",
                "answers": [
                    {"answer": "Saliva"},
                    {"answer": "Blood"},
                    {"answer": "Hair"},
                    {"answer": "Urine"}
                ],
                "answer": "Saliva",
                "explanation": "At-home kits often use saliva collected in a tube. Blood is used in clinical settings."
            },
            {
                "question": "What is the purpose of carrier testing?",
                "answers": [
                    {"answer": "To see if you carry a gene for a recessive disease"},
                    {"answer": "To diagnose cancer"},
                    {"answer": "To test for vitamin deficiencies"},
                    {"answer": "To determine your ancestry"}
                ],
                "answer": "To see if you carry a gene for a recessive disease",
                "explanation": "Carrier testing helps couples understand risks of passing genetic disorders to children."
            },
            {
                "question": "What does 'VUS' mean in genetic test results?",
                "answers": [
                    {"answer": "Variant of Uncertain Significance"},
                    {"answer": "Very Urgent Situation"},
                    {"answer": "Valuable Unique Sample"},
                    {"answer": "Verified Unusual Symptom"}
                ],
                "answer": "Variant of Uncertain Significance",
                "explanation": "A VUS is a DNA change with unknown health impact. More research is needed."
            },
            {
                "question": "What is a genetic counselor?",
                "answers": [
                    {"answer": "A healthcare professional who explains genetic test results"},
                    {"answer": "A scientist who sequences DNA"},
                    {"answer": "A lawyer specializing in genetic privacy"},
                    {"answer": "A lab technician drawing blood"}
                ],
                "answer": "A healthcare professional who explains genetic test results",
                "explanation": "Genetic counselors help patients understand risks, testing options, and results."
            },
            {
                "question": "What does prenatal testing check for?",
                "answers": [
                    {"answer": "Genetic conditions in a fetus"},
                    {"answer": "A parent’s ancestry"},
                    {"answer": "Newborn hearing loss"},
                    {"answer": "Adult cancer risk"}
                ],
                "answer": "Genetic conditions in a fetus",
                "explanation": "Prenatal tests (e.g., amniocentesis) screen for disorders like Down syndrome."
            },
            {
                "question": "What is pharmacogenomic testing?",
                "answers": [
                    {"answer": "Testing how genes affect drug responses"},
                    {"answer": "Testing for inherited cancers"},
                    {"answer": "Testing athletic ability"},
                    {"answer": "Testing vitamin levels"}
                ],
                "answer": "Testing how genes affect drug responses",
                "explanation": "Pharmacogenomics helps doctors prescribe safer, more effective medications."
            },
            {
                "question": "What is newborn screening?",
                "answers": [
                    {"answer": "Testing babies for treatable genetic disorders"},
                    {"answer": "Predicting a baby’s future height"},
                    {"answer": "Testing a mother’s DNA during pregnancy"},
                    {"answer": "Analyzing a baby’s ancestry"}
                ],
                "answer": "Testing babies for treatable genetic disorders",
                "explanation": "Newborn screening detects conditions like PKU early to prevent complications."
            },
            {
                "question": "Which test identifies ancestry?",
                "answers": [
                    {"answer": "Autosomal DNA testing"},
                    {"answer": "Carrier testing"},
                    {"answer": "Newborn screening"},
                    {"answer": "Cholesterol test"}
                ],
                "answer": "Autosomal DNA testing",
                "explanation": "Autosomal tests analyze DNA inherited from both parents to estimate ethnic origins."
            },
            {
                "question": "What is diagnostic genetic testing?",
                "answers": [
                    {"answer": "Confirming a suspected genetic condition"},
                    {"answer": "Predicting future health risks"},
                    {"answer": "Testing for carrier status"},
                    {"answer": "Analyzing drug reactions"}
                ],
                "answer": "Confirming a suspected genetic condition",
                "explanation": "Diagnostic testing identifies disorders like cystic fibrosis in symptomatic patients."
            },
            {
                "question": "What is a buccal swab?",
                "answers": [
                    {"answer": "A cheek cell sample"},
                    {"answer": "A blood test"},
                    {"answer": "A hair sample"},
                    {"answer": "A urine test"}
                ],
                "answer": "A cheek cell sample",
                "explanation": "A buccal swab collects cells from the inside of the cheek for DNA analysis."
            },
            {
                "question": "Why might a blood sample be used for genetic testing?",
                "answers": [
                    {"answer": "To obtain high-quality DNA"},
                    {"answer": "It’s cheaper than saliva"},
                    {"answer": "To test for infections"},
                    {"answer": "To measure hormone levels"}
                ],
                "answer": "To obtain high-quality DNA",
                "explanation": "Blood samples provide reliable DNA but require clinical collection."
            },
            {
                "question": "What does a 'positive' genetic test result mean?",
                "answers": [
                    {"answer": "A disease-causing mutation was found"},
                    {"answer": "No mutations were found"},
                    {"answer": "The test failed"},
                    {"answer": "The result is uncertain"}
                ],
                "answer": "A disease-causing mutation was found",
                "explanation": "A positive result indicates a mutation linked to a specific condition."
            },
            {
                "question": "Can a genetic test predict all future health problems?",
                "answers": [
                    {"answer": "No—it only assesses specific mutations"},
                    {"answer": "Yes, with 100% accuracy"},
                    {"answer": "Only for infectious diseases"},
                    {"answer": "Only for mental health conditions"}
                ],
                "answer": "No—it only assesses specific mutations",
                "explanation": "Most tests analyze predefined genes. Environment and lifestyle also affect health."
            },
            {
                "question": "What is informed consent?",
                "answers": [
                    {"answer": "Agreeing to testing after understanding risks/benefits"},
                    {"answer": "Signing up for a lab newsletter"},
                    {"answer": "Paying for a test online"},
                    {"answer": "Sharing DNA data on social media"}
                ],
                "answer": "Agreeing to testing after understanding risks/benefits",
                "explanation": "Informed consent ensures patients know how results might impact them."
            },
            {
                "question": "What law prohibits genetic discrimination in health insurance?",
                "answers": [
                    {"answer": "GINA (Genetic Information Nondiscrimination Act)"},
                    {"answer": "HIPAA"},
                    {"answer": "FDA"},
                    {"answer": "CLIA"}
                ],
                "answer": "GINA (Genetic Information Nondiscrimination Act)",
                "explanation": "GINA prevents insurers/employers from using genetic data against you."
            },
            {
                "question": "What is DNA?",
                "answers": [
                    {"answer": "A molecule carrying genetic instructions"},
                    {"answer": "A type of protein"},
                    {"answer": "A blood cell"},
                    {"answer": "A vitamin"}
                ],
                "answer": "A molecule carrying genetic instructions",
                "explanation": "DNA contains the code for building and maintaining an organism."
            },
            {
                "question": "What is a mutation?",
                "answers": [
                    {"answer": "A change in DNA sequence"},
                    {"answer": "A type of blood test"},
                    {"answer": "A vitamin deficiency"},
                    {"answer": "A lab error"}
                ],
                "answer": "A change in DNA sequence",
                "explanation": "Mutations can be harmless, beneficial, or cause disease."
            },
            {
                "question": "What is a gene?",
                "answers": [
                    {"answer": "A segment of DNA that codes for a protein"},
                    {"answer": "A type of blood cell"},
                    {"answer": "A laboratory tool"},
                    {"answer": "A vitamin"}
                ],
                "answer": "A segment of DNA that codes for a protein",
                "explanation": "Genes determine traits like eye color and influence disease risk."
            },
            {
                "question": "How many chromosomes do humans have?",
                "answers": [
                    {"answer": "46"},
                    {"answer": "23"},
                    {"answer": "32"},
                    {"answer": "50"}
                ],
                "answer": "46",
                "explanation": "Humans have 23 pairs of chromosomes (46 total) in most cells."
            },
            {
                "question": "What is a chromosome?",
                "answers": [
                    {"answer": "A thread-like structure of DNA and protein"},
                    {"answer": "A type of genetic test"},
                    {"answer": "A blood disorder"},
                    {"answer": "A vitamin"}
                ],
                "answer": "A thread-like structure of DNA and protein",
                "explanation": "Chromosomes package DNA tightly to fit inside cells."
            },
            {
                "question": "What is an allele?",
                "answers": [
                    {"answer": "A version of a gene"},
                    {"answer": "A type of genetic test"},
                    {"answer": "A lab instrument"},
                    {"answer": "A blood sample"}
                ],
                "answer": "A version of a gene",
                "explanation": "Alleles are variations of genes (e.g., blue vs. brown eyes)."
            },
            {
                "question": "What does 'recessive' mean in genetics?",
                "answers": [
                    {"answer": "A trait that only appears with two copies of the allele"},
                    {"answer": "A trait that always appears with one allele"},
                    {"answer": "A type of DNA test"},
                    {"answer": "A lab error"}
                ],
                "answer": "A trait that only appears with two copies of the allele",
                "explanation": "Recessive traits (like cystic fibrosis) need two copies of the mutated gene."
            },
            {
                "question": "What does 'dominant' mean in genetics?",
                "answers": [
                    {"answer": "A trait that appears with one copy of the allele"},
                    {"answer": "A trait that never appears"},
                    {"answer": "A type of blood test"},
                    {"answer": "A lab certification"}
                ],
                "answer": "A trait that appears with one copy of the allele",
                "explanation": "Dominant traits (like Huntington’s disease) require only one mutated gene."
            },
            {
                "question": "What is a genome?",
                "answers": [
                    {"answer": "All the DNA in an organism"},
                    {"answer": "A type of genetic test"},
                    {"answer": "A blood cell"},
                    {"answer": "A vitamin"}
                ],
                "answer": "All the DNA in an organism",
                "explanation": "The genome includes all genes and non-coding DNA."
            },
            {
                "question": "What is a genetic disorder?",
                "answers": [
                    {"answer": "A disease caused by DNA changes"},
                    {"answer": "A lab mistake"},
                    {"answer": "A vitamin deficiency"},
                    {"answer": "A bacterial infection"}
                ],
                "answer": "A disease caused by DNA changes",
                "explanation": "Examples include sickle cell anemia and cystic fibrosis."
            },
            {
                "question": "What is a false positive in genetic testing?",
                "answers": [
                    {"answer": "A result showing a mutation that isn’t there"},
                    {"answer": "A correct result"},
                    {"answer": "A lab equipment error"},
                    {"answer": "A canceled test"}
                ],
                "answer": "A result showing a mutation that isn’t there",
                "explanation": "False positives can cause unnecessary stress and testing."
            },
            {
                "question": "What is a false negative in genetic testing?",
                "answers": [
                    {"answer": "A result missing a mutation that is present"},
                    {"answer": "A correct result"},
                    {"answer": "A lab accident"},
                    {"answer": "A canceled test"}
                ],
                "answer": "A result missing a mutation that is present",
                "explanation": "False negatives may delay needed medical care."
            },
            {
                "question": "What is direct-to-consumer genetic testing?",
                "answers": [
                    {"answer": "Tests sold directly to the public without a doctor"},
                    {"answer": "Tests done in hospitals"},
                    {"answer": "Tests for newborns"},
                    {"answer": "Tests for infectious diseases"}
                ],
                "answer": "Tests sold directly to the public without a doctor",
                "explanation": "Examples include ancestry and wellness tests from companies like 23andMe."
            },
            {
                "question": "What is a BRCA1 gene?",
                "answers": [
                    {"answer": "A gene linked to breast cancer risk"},
                    {"answer": "A gene for eye color"},
                    {"answer": "A gene for vitamin absorption"},
                    {"answer": "A gene for height"}
                ],
                "answer": "A gene linked to breast cancer risk",
                "explanation": "BRCA1 mutations increase the risk of breast and ovarian cancers."
            },
            {
                "question": "What is genetic ancestry?",
                "answers": [
                    {"answer": "Estimating where your ancestors lived"},
                    {"answer": "Testing for diseases"},
                    {"answer": "Analyzing drug reactions"},
                    {"answer": "Studying bacteria"}
                ],
                "answer": "Estimating where your ancestors lived",
                "explanation": "Ancestry tests compare your DNA to global reference populations."
            },
            {
                "question": "What is a genetic trait?",
                "answers": [
                    {"answer": "A characteristic influenced by genes"},
                    {"answer": "A lab tool"},
                    {"answer": "A blood test"},
                    {"answer": "A vitamin"}
                ],
                "answer": "A characteristic influenced by genes",
                "explanation": "Examples include eye color, height, and lactose intolerance."
            },
            {
                "question": "What is a family health history?",
                "answers": [
                    {"answer": "A record of diseases in relatives"},
                    {"answer": "A genetic test"},
                    {"answer": "A lab report"},
                    {"answer": "A DNA sample"}
                ],
                "answer": "A record of diseases in relatives",
                "explanation": "Family history helps assess genetic disease risks."
            },
            {
                "question": "What is a genetic risk score?",
                "answers": [
                    {"answer": "An estimate of disease risk based on DNA"},
                    {"answer": "A lab certification"},
                    {"answer": "A blood pressure reading"},
                    {"answer": "A vitamin level"}
                ],
                "answer": "An estimate of disease risk based on DNA",
                "explanation": "Polygenic risk scores combine multiple genetic variants."
            },
            {
                "question": "What is a DNA match?",
                "answers": [
                    {"answer": "A relative identified through shared DNA"},
                    {"answer": "A lab tool"},
                    {"answer": "A blood type match"},
                    {"answer": "A vitamin compatibility"}
                ],
                "answer": "A relative identified through shared DNA",
                "explanation": "DNA matching helps build family trees in ancestry testing."
            },
            {
                "question": "What is a genetic variant?",
                "answers": [
                    {"answer": "A difference in DNA sequence"},
                    {"answer": "A lab error"},
                    {"answer": "A blood disorder"},
                    {"answer": "A vitamin deficiency"}
                ],
                "answer": "A difference in DNA sequence",
                "explanation": "Variants can be harmless, beneficial, or harmful."
            },
            {
                "question": "What is a DNA profile?",
                "answers": [
                    {"answer": "A unique set of genetic markers"},
                    {"answer": "A lab report"},
                    {"answer": "A blood type"},
                    {"answer": "A vitamin chart"}
                ],
                "answer": "A unique set of genetic markers",
                "explanation": "Used in forensics and paternity testing to identify individuals."
            },
            {
                "question": "What is a genetic marker?",
                "answers": [
                    {"answer": "A DNA sequence with a known location"},
                    {"answer": "A lab tool"},
                    {"answer": "A blood sample"},
                    {"answer": "A vitamin"}
                ],
                "answer": "A DNA sequence with a known location",
                "explanation": "Markers help track genes in families or populations."
            },
            {
                "question": "What is a genetic predisposition?",
                "answers": [
                    {"answer": "Increased risk of a disease due to genes"},
                    {"answer": "Immunity to a disease"},
                    {"answer": "A lab error"},
                    {"answer": "A vitamin deficiency"}
                ],
                "answer": "Increased risk of a disease due to genes",
                "explanation": "A predisposition doesn’t guarantee the disease will develop."
            },
            {
                "question": "What is a spit kit?",
                "answers": [
                    {"answer": "A saliva collection kit for DNA testing"},
                    {"answer": "A blood test kit"},
                    {"answer": "A hair sample kit"},
                    {"answer": "A urine test kit"}
                ],
                "answer": "A saliva collection kit for DNA testing",
                "explanation": "Used in at-home tests to collect DNA from saliva."
            },
            {
                "question": "What is a lab report?",
                "answers": [
                    {"answer": "A document explaining test results"},
                    {"answer": "A blood sample"},
                    {"answer": "A genetic mutation"},
                    {"answer": "A vitamin"}
                ],
                "answer": "A document explaining test results",
                "explanation": "Reports summarize findings and may include recommendations."
            },
            {
                "question": "What is a DNA database?",
                "answers": [
                    {"answer": "A collection of genetic profiles"},
                    {"answer": "A lab tool"},
                    {"answer": "A blood bank"},
                    {"answer": "A vitamin list"}
                ],
                "answer": "A collection of genetic profiles",
                "explanation": "Used in research, forensics, and ancestry services."
            },
            {
                "question": "What is a consent form?",
                "answers": [
                    {"answer": "A document agreeing to testing terms"},
                    {"answer": "A lab report"},
                    {"answer": "A blood sample"},
                    {"answer": "A vitamin"}
                ],
                "answer": "A document agreeing to testing terms",
                "explanation": "Ensures patients understand testing risks/benefits before proceeding."
            },
            {
                "question": "What is de-identified data?",
                "answers": [
                    {"answer": "Data without personal identifiers"},
                    {"answer": "Encrypted data"},
                    {"answer": "Raw DNA data"},
                    {"answer": "A lab tool"}
                ],
                "answer": "Data without personal identifiers",
                "explanation": "Protects privacy by removing names, addresses, etc."
            },
            {
                "question": "What is a genetic testing kit?",
                "answers": [
                    {"answer": "A package to collect and send DNA samples"},
                    {"answer": "A lab instrument"},
                    {"answer": "A blood pressure monitor"},
                    {"answer": "A vitamin bottle"}
                ],
                "answer": "A package to collect and send DNA samples",
                "explanation": "Includes instructions, tubes, and return packaging."
            },
            {
                "question": "What is a raw DNA file?",
                "answers": [
                    {"answer": "A text file of genetic data"},
                    {"answer": "A lab report"},
                    {"answer": "A blood sample"},
                    {"answer": "A vitamin list"}
                ],
                "answer": "A text file of genetic data",
                "explanation": "Users can download this file for third-party analyses."
            },
            {
                "question": "What is a third-party interpretation service?",
                "answers": [
                    {"answer": "A tool to analyze raw DNA data"},
                    {"answer": "A lab certification"},
                    {"answer": "A blood test"},
                    {"answer": "A vitamin supplier"}
                ],
                "answer": "A tool to analyze raw DNA data",
                "explanation": "Services like Promethease provide additional health insights."
            },
            {
                "question": "What is a DNA relative match?",
                "answers": [
                    {"answer": "Identifying genetic relatives through shared DNA"},
                    {"answer": "Matching blood types"},
                    {"answer": "Finding vitamin compatibility"},
                    {"answer": "A lab error"}
                ],
                "answer": "Identifying genetic relatives through shared DNA",
                "explanation": "Common in ancestry testing platforms like AncestryDNA."
            },
            {
                "question": "What is a genetic testing panel?",
                "answers": [
                    {"answer": "A test analyzing multiple genes at once"},
                    {"answer": "A lab tool"},
                    {"answer": "A blood collection method"},
                    {"answer": "A vitamin chart"}
                ],
                "answer": "A test analyzing multiple genes at once",
                "explanation": "Panels screen for conditions like hereditary cancer syndromes."
            },
            {
                "question": "What is whole exome sequencing?",
                "answers": [
                    {"answer": "Sequencing all protein-coding genes"},
                    {"answer": "Sequencing mitochondrial DNA"},
                    {"answer": "A blood test"},
                    {"answer": "A vitamin test"}
                ],
                "answer": "Sequencing all protein-coding genes",
                "explanation": "Exome sequencing focuses on 1-2% of the genome but covers most disease-related genes."
            },
            {
                "question": "What is a genetic testing result 'carrier'?",
                "answers": [
                    {"answer": "Someone with one copy of a recessive mutation"},
                    {"answer": "Someone with two copies of a mutation"},
                    {"answer": "Someone immune to a disease"},
                    {"answer": "A lab technician"}
                ],
                "answer": "Someone with one copy of a recessive mutation",
                "explanation": "Carriers don’t show symptoms but can pass the mutation to children."
            },
            {
                "question": "What is a negative test result?",
                "answers": [
                    {"answer": "No mutations were found in tested genes"},
                    {"answer": "A lab error occurred"},
                    {"answer": "The test was canceled"},
                    {"answer": "A vitamin deficiency was found"}
                ],
                "answer": "No mutations were found in tested genes",
                "explanation": "A negative result reduces but doesn’t eliminate disease risk."
            }
        ]
    },
    {
        "name": "Blueprint Genetics Comprehensive Quiz",
        "questions": [
            {
                "question": "What is Blueprint Genetics' primary focus?",
                "answers": [
                    {"answer": "Diagnostic genetic testing for rare diseases"},
                    {"answer": "Direct-to-consumer wellness reports"},
                    {"answer": "Pharmacogenomic drug development"},
                    {"answer": "Infectious disease diagnostics"}
                ],
                "answer": "Diagnostic genetic testing for rare diseases",
                "explanation": "Blueprint Genetics specializes in clinical exome sequencing and targeted gene panels to diagnose rare inherited disorders, such as cardiomyopathies, metabolic disorders, and neurodevelopmental conditions."
            },
            {
                "question": "Which certifications does Blueprint Genetics hold?",
                "answers": [
                    {"answer": "CLIA and CAP"},
                    {"answer": "FDA and CE-IVD"},
                    {"answer": "ISO 9001 only"},
                    {"answer": "HIPAA and GDPR"}
                ],
                "answer": "CLIA and CAP",
                "explanation": "Their lab is CLIA-certified (Clinical Laboratory Improvement Amendments) and CAP-accredited (College of American Pathologists), ensuring compliance with U.S. clinical testing standards."
            },
            {
                "question": "What technology does Blueprint Genetics primarily use for sequencing?",
                "answers": [
                    {"answer": "Next-Generation Sequencing (NGS)"},
                    {"answer": "Sanger Sequencing"},
                    {"answer": "Microarray analysis"},
                    {"answer": "PCR-based genotyping"}
                ],
                "answer": "Next-Generation Sequencing (NGS)",
                "explanation": "NGS allows high-throughput, cost-effective analysis of hundreds to thousands of genes simultaneously, with high accuracy and coverage."
            },
            {
                "question": "What is the 'Exome+Solution'?",
                "answers": [
                    {"answer": "Whole exome sequencing + CNV analysis"},
                    {"answer": "Single-gene testing"},
                    {"answer": "RNA sequencing"},
                    {"answer": "Microbiome analysis"}
                ],
                "answer": "Whole exome sequencing + CNV analysis",
                "explanation": "Exome+Solution sequences all protein-coding regions (~20,000 genes) and detects copy-number variations (CNVs), providing a comprehensive diagnostic approach."
            },
            {
                "question": "Who can order a Blueprint Genetics test?",
                "answers": [
                    {"answer": "Licensed healthcare providers"},
                    {"answer": "Patients directly"},
                    {"answer": "Pharmacists"},
                    {"answer": "Research scientists"}
                ],
                "answer": "Licensed healthcare providers",
                "explanation": "Tests are clinically validated and require a provider’s order to ensure appropriate use and interpretation."
            },
            {
                "question": "What is the 'Cardio Panel' used for?",
                "answers": [
                    {"answer": "Diagnosing inherited cardiovascular disorders"},
                    {"answer": "Assessing cholesterol levels"},
                    {"answer": "Monitoring blood pressure"},
                    {"answer": "Testing for heart attacks"}
                ],
                "answer": "Diagnosing inherited cardiovascular disorders",
                "explanation": "The Cardio Panel analyzes genes linked to conditions like hypertrophic cardiomyopathy, long QT syndrome, and familial hypercholesterolemia."
            },
            {
                "question": "Which panel would a clinician order for a child with developmental delay?",
                "answers": [
                    {"answer": "Neuro Panel"},
                    {"answer": "Cancer Panel"},
                    {"answer": "Metabolic Panel"},
                    {"answer": "Prenatal Panel"}
                ],
                "answer": "Neuro Panel",
                "explanation": "The Neuro Panel focuses on genes associated with neurodevelopmental disorders, epilepsy, and intellectual disability."
            },
            {
                "question": "What does the 'Rapid Exome' test prioritize?",
                "answers": [
                    {"answer": "Fast turnaround for critically ill patients"},
                    {"answer": "Low-cost sequencing"},
                    {"answer": "Carrier screening"},
                    {"answer": "Ancestry analysis"}
                ],
                "answer": "Fast turnaround for critically ill patients",
                "explanation": "Rapid Exome Sequencing (2-3 weeks) is used in neonatal ICUs or acute care settings to expedite diagnoses."
            },
            {
                "question": "What is the 'Metabolic Panel' designed to detect?",
                "answers": [
                    {"answer": "Inborn errors of metabolism"},
                    {"answer": "Diabetes risk"},
                    {"answer": "Vitamin deficiencies"},
                    {"answer": "Thyroid disorders"}
                ],
                "answer": "Inborn errors of metabolism",
                "explanation": "This panel identifies mutations in genes like *PAH* (phenylketonuria) or *GALT* (galactosemia) to guide dietary or therapeutic interventions."
            },
            {
                "question": "Which test is appropriate for a suspected chromosomal deletion?",
                "answers": [
                    {"answer": "Exome+Solution with CNV analysis"},
                    {"answer": "Single-gene Sanger sequencing"},
                    {"answer": "Carrier screening panel"},
                    {"answer": "Pharmacogenomic testing"}
                ],
                "answer": "Exome+Solution with CNV analysis",
                "explanation": "Exome+Solution includes CNV detection to identify large deletions/duplications missed by gene panels."
            },
            {
                "question": "What does '30x coverage' mean in sequencing?",
                "answers": [
                    {"answer": "Each DNA base is read 30 times on average"},
                    {"answer": "30 genes are analyzed"},
                    {"answer": "The test costs $30"},
                    {"answer": "30-day turnaround time"}
                ],
                "answer": "Each DNA base is read 30 times on average",
                "explanation": "Higher coverage (e.g., 100x) improves accuracy by reducing errors and detecting low-level mosaicism."
            },
            {
                "question": "How does Blueprint Genetics handle pseudogenes?",
                "answers": [
                    {"answer": "Uses probe design to avoid cross-hybridization"},
                    {"answer": "Ignores them during analysis"},
                    {"answer": "Reports them as pathogenic"},
                    {"answer": "Uses Sanger sequencing exclusively"}
                ],
                "answer": "Uses probe design to avoid cross-hybridization",
                "explanation": "Pseudogenes (non-functional gene copies) can cause false positives; specialized probes minimize this risk."
            },
            {
                "question": "What is a 'BAM file'?",
                "answers": [
                    {"answer": "A file storing aligned sequencing reads"},
                    {"answer": "A lab consent form"},
                    {"answer": "A billing document"},
                    {"answer": "A variant classification report"}
                ],
                "answer": "A file storing aligned sequencing reads",
                "explanation": "BAM files map DNA sequences to a reference genome and are used for variant calling and quality control."
            },
            {
                "question": "What does a 'Tier 1' variant classification indicate?",
                "answers": [
                    {"answer": "Pathogenic or likely pathogenic"},
                    {"answer": "Benign"},
                    {"answer": "Variant of Uncertain Significance (VUS)"},
                    {"answer": "Technical artifact"}
                ],
                "answer": "Pathogenic or likely pathogenic",
                "explanation": "Tier 1 variants have strong evidence linking them to disease, per ACMG guidelines."
            },
            {
                "question": "What is a 'VUS'?",
                "answers": [
                    {"answer": "A variant with unclear clinical significance"},
                    {"answer": "A confirmed benign variant"},
                    {"answer": "A lab error"},
                    {"answer": "A novel gene discovery"}
                ],
                "answer": "A variant with unclear clinical significance",
                "explanation": "VUS results require follow-up, such as family studies or periodic reanalysis."
            },
            {
                "question": "When is 'carrier screening' recommended?",
                "answers": [
                    {"answer": "Before or during pregnancy"},
                    {"answer": "After a cancer diagnosis"},
                    {"answer": "For ancestry analysis"},
                    {"answer": "To diagnose infections"}
                ],
                "answer": "Before or during pregnancy",
                "explanation": "Carrier screening identifies recessive mutations (e.g., cystic fibrosis) in prospective parents."
            },
            {
                "question": "What is the clinical utility of the 'Cancer Panel'?",
                "answers": [
                    {"answer": "Identifying hereditary cancer syndromes"},
                    {"answer": "Monitoring chemotherapy response"},
                    {"answer": "Detecting tumor mutations"},
                    {"answer": "Predicting cancer recurrence"}
                ],
                "answer": "Identifying hereditary cancer syndromes",
                "explanation": "This panel tests genes like *BRCA1/2* or *TP53* to assess inherited cancer risks."
            },
            {
                "question": "What does GINA protect against?",
                "answers": [
                    {"answer": "Genetic discrimination in health insurance"},
                    {"answer": "Data breaches"},
                    {"answer": "Lab errors"},
                    {"answer": "Infectious diseases"}
                ],
                "answer": "Genetic discrimination in health insurance",
                "explanation": "The Genetic Information Nondiscrimination Act (GINA) prohibits insurers from using genetic data to deny coverage."
            },
            {
                "question": "What is included in informed consent for genetic testing?",
                "answers": [
                    {"answer": "Risks, benefits, and data usage"},
                    {"answer": "Lab equipment details"},
                    {"answer": "Insurance billing codes"},
                    {"answer": "Pharmaceutical promotions"}
                ],
                "answer": "Risks, benefits, and data usage",
                "explanation": "Patients must understand potential outcomes, privacy policies, and how results may impact family members."
            },
            {
                "question": "A newborn with seizures and developmental delay undergoes Rapid Exome Sequencing. A *SCN1A* variant is found. What is the likely diagnosis?",
                "answers": [
                    {"answer": "Dravet syndrome"},
                    {"answer": "Cystic fibrosis"},
                    {"answer": "Huntington’s disease"},
                    {"answer": "Marfan syndrome"}
                ],
                "answer": "Dravet syndrome",
                "explanation": "*SCN1A* mutations cause Dravet syndrome, a severe epilepsy disorder. Early diagnosis guides treatment with sodium channel blockers."
            }
        ]
    },
    {
        "name": "Genes and DNA Basics Quiz",
        "questions": [
            {
                "question": "What is a gene?",
                "answers": [
                    {"answer": "A specific DNA sequence"},
                    {"answer": "A type of protein"},
                    {"answer": "A blood cell"},
                    {"answer": "A vitamin"}
                ],
                "answer": "A specific DNA sequence",
                "explanation": "A gene is a segment of DNA with a unique sequence of bases (A, T, C, G) that codes for a functional product."
            },
            {
                "question": "What molecules make up the 'rungs' of the DNA ladder?",
                "answers": [
                    {"answer": "A, T, C, G bases"},
                    {"answer": "Proteins"},
                    {"answer": "Sugars"},
                    {"answer": "Lipids"}
                ],
                "answer": "A, T, C, G bases",
                "explanation": "DNA is made of two strands twisted into a double helix, with bases (A-T and C-G) forming the rungs."
            },
            {
                "question": "Where are genes located?",
                "answers": [
                    {"answer": "On chromosomes"},
                    {"answer": "In the cell membrane"},
                    {"answer": "In mitochondria only"},
                    {"answer": "In vitamins"}
                ],
                "answer": "On chromosomes",
                "explanation": "Genes are arranged linearly on chromosomes, which are found in the cell nucleus."
            },
            {
                "question": "Approximately how many genes do humans have?",
                "answers": [
                    {"answer": "~20,000"},
                    {"answer": "~100,000"},
                    {"answer": "~5,000"},
                    {"answer": "~1,000"}
                ],
                "answer": "~20,000",
                "explanation": "Humans have about 20,000 genes, making up only ~1-2% of total DNA."
            },
            {
                "question": "What do genes code for?",
                "answers": [
                    {"answer": "Proteins or RNA molecules"},
                    {"answer": "Carbohydrates"},
                    {"answer": "Hormones"},
                    {"answer": "Vitamins"}
                ],
                "answer": "Proteins or RNA molecules",
                "explanation": "Genes provide instructions to build proteins (e.g., enzymes) or functional RNA (e.g., tRNA)."
            },
            {
                "question": "Which gene is responsible for hemoglobin?",
                "answers": [
                    {"answer": "HBB"},
                    {"answer": "BRCA1"},
                    {"answer": "CFTR"},
                    {"answer": "TP53"}
                ],
                "answer": "HBB",
                "explanation": "The HBB gene codes for part of hemoglobin, the protein that carries oxygen in red blood cells."
            },
            {
                "question": "What happens if the HBB gene is mutated?",
                "answers": [
                    {"answer": "Sickle cell anemia"},
                    {"answer": "Cystic fibrosis"},
                    {"answer": "Huntington’s disease"},
                    {"answer": "Diabetes"}
                ],
                "answer": "Sickle cell anemia",
                "explanation": "A single base change in HBB causes sickle-shaped red blood cells, leading to sickle cell anemia."
            },
            {
                "question": "What is the relationship between a gene and DNA?",
                "answers": [
                    {"answer": "A gene is a functional unit of DNA"},
                    {"answer": "DNA is a type of gene"},
                    {"answer": "Genes are made of RNA"},
                    {"answer": "DNA and genes are unrelated"}
                ],
                "answer": "A gene is a functional unit of DNA",
                "explanation": "DNA is the entire molecule, while genes are specific segments that code for products."
            },
            {
                "question": "What percentage of human DNA codes for genes?",
                "answers": [
                    {"answer": "1-2%"},
                    {"answer": "50%"},
                    {"answer": "25%"},
                    {"answer": "99%"}
                ],
                "answer": "1-2%",
                "explanation": "Most DNA is non-coding and includes regulatory regions or 'junk' DNA."
            },
            {
                "question": "What is the purpose of genes?",
                "answers": [
                    {"answer": "Provide instructions for traits"},
                    {"answer": "Store energy"},
                    {"answer": "Fight infections"},
                    {"answer": "Digest food"}
                ],
                "answer": "Provide instructions for traits",
                "explanation": "Genes determine traits like eye color, height, and disease susceptibility."
            },
            {
                "question": "How many chromosome pairs do humans have?",
                "answers": [
                    {"answer": "23"},
                    {"answer": "46"},
                    {"answer": "10"},
                    {"answer": "32"}
                ],
                "answer": "23",
                "explanation": "Humans have 23 pairs of chromosomes (46 total) in most cells."
            },
            {
                "question": "What is the difference between a gene and a genome?",
                "answers": [
                    {"answer": "A gene is a DNA segment; a genome is all DNA in an organism"},
                    {"answer": "A genome is a type of gene"},
                    {"answer": "Genes are made of RNA; genomes are made of DNA"},
                    {"answer": "There is no difference"}
                ],
                "answer": "A gene is a DNA segment; a genome is all DNA in an organism",
                "explanation": "The genome includes all genes and non-coding DNA in an organism."
            },
            {
                "question": "What role do non-coding DNA regions play?",
                "answers": [
                    {"answer": "Regulate gene activity"},
                    {"answer": "Code for proteins"},
                    {"answer": "Carry oxygen"},
                    {"answer": "Digest food"}
                ],
                "answer": "Regulate gene activity",
                "explanation": "Non-coding DNA controls when and where genes are expressed."
            },
            {
                "question": "True or False: All DNA sequences are genes.",
                "answers": [
                    {"answer": "False"},
                    {"answer": "True"}
                ],
                "answer": "False",
                "explanation": "Only ~1-2% of DNA consists of genes; the rest includes regulatory and non-functional regions."
            },
            {
                "question": "What is a gene best compared to?",
                "answers": [
                    {"answer": "A recipe in a cookbook"},
                    {"answer": "A kitchen appliance"},
                    {"answer": "A chef"},
                    {"answer": "A meal"}
                ],
                "answer": "A recipe in a cookbook",
                "explanation": "A gene provides step-by-step instructions to make a product, like a recipe."
            },
            {
                "question": "Which part of DNA is NOT part of a gene?",
                "answers": [
                    {"answer": "Regulatory regions"},
                    {"answer": "Coding sequence"},
                    {"answer": "Promoter region"},
                    {"answer": "Exons"}
                ],
                "answer": "Regulatory regions",
                "explanation": "Regulatory regions control gene activity but aren’t part of the gene’s coding sequence."
            },
            {
                "question": "What happens if a gene mutates?",
                "answers": [
                    {"answer": "It may alter the protein it codes for"},
                    {"answer": "It becomes part of a chromosome"},
                    {"answer": "It turns into RNA"},
                    {"answer": "Nothing—mutations are always harmless"}
                ],
                "answer": "It may alter the protein it codes for",
                "explanation": "Mutations can disrupt protein function, causing diseases like cystic fibrosis."
            },
            {
                "question": "What is DNA?",
                "answers": [
                    {"answer": "A molecule storing genetic information"},
                    {"answer": "A type of gene"},
                    {"answer": "A protein"},
                    {"answer": "A carbohydrate"}
                ],
                "answer": "A molecule storing genetic information",
                "explanation": "DNA is the molecule that contains all genes and non-coding sequences."
            },
            {
                "question": "What does hemoglobin do?",
                "answers": [
                    {"answer": "Carries oxygen in red blood cells"},
                    {"answer": "Fights infections"},
                    {"answer": "Digests food"},
                    {"answer": "Stores energy"}
                ],
                "answer": "Carries oxygen in red blood cells",
                "explanation": "Hemoglobin, coded by the HBB gene, binds oxygen for transport through the blood."
            },
            {
                "question": "What is the entire set of DNA in an organism called?",
                "answers": [
                    {"answer": "Genome"},
                    {"answer": "Chromosome"},
                    {"answer": "Gene pool"},
                    {"answer": "Proteome"}
                ],
                "answer": "Genome",
                "explanation": "The genome includes all genes and non-coding DNA in an organism."
            }
        ]
    }    
]